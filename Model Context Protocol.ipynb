{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e1e9bc",
   "metadata": {},
   "source": [
    "# Gravix Layer Cookbook: Model Context Protocol (MCP)\n",
    "\n",
    "Welcome to the Gravix Layer Cookbook series. This guide explores the Model Context Protocol (MCP), an open standard designed to revolutionize how AI models connect with external tools and data sources. Think of it as a universal adapter that finally allows AI to interact with the real world.\n",
    "\n",
    "## Vision\n",
    "\n",
    "Imagine an AI assistant that doesn't just chat, it actually gets things done. It checks your calendar, updates your databases, manages your workflows, and automates tasks across multiple applications. This isn't science fiction; it's what MCP makes possible today.\n",
    "\n",
    "The Model Context Protocol transforms AI from text generators into true agents that can perceive, reason about, and act upon real-world information in real-time. This creates unprecedented possibilities for intelligent automation and conversational interfaces to complex systems.\n",
    "\n",
    "## MCP Solution\n",
    "\n",
    "MCP establishes a standardized way for AI models to communicate with any external system. Instead of building custom connectors for each tool, you implement MCP once and gain access to an entire ecosystem of compatible applications.\n",
    "\n",
    "The architecture is elegantly simple:\n",
    "- **MCP Servers** expose your tools and data to AI models\n",
    "- **MCP Clients** handle secure communication between AI and systems\n",
    "- **The Protocol** ensures reliable, standardized data exchange\n",
    "\n",
    "## What You'll Build\n",
    "\n",
    "This recipe provides complete, hands-on MCP development:\n",
    "\n",
    "1. **MCP Server** - Production-ready server exposing a todo application\n",
    "2. **MCP Client** - Secure communication bridge with real-time sync\n",
    "3. **AI Assistant** - An AI that performs actual tasks in the real world\n",
    "4. **Security Layer** - Authentication, monitoring, and deployment practices\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python fundamentals and REST API knowledge\n",
    "- Basic AI/LLM understanding\n",
    "- Development environment: Python 3.8+\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "You'll master:\n",
    "- MCP protocol implementation and core concepts\n",
    "- Secure AI-system integration and agent development\n",
    "- Production deployment and security best practices\n",
    "- The future of intelligent application development\n",
    "\n",
    "This technology is already reshaping how AI systems interact with the world. Let's begin building the future of AI integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19e61c",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Let's begin by installing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12429036",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517efb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.venv/lib/python3.13/site-packages (1.95.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (1.1.1)\n",
      "Requirement already satisfied: fastapi in ./.venv/lib/python3.13/site-packages (0.116.0)\n",
      "Requirement already satisfied: uvicorn in ./.venv/lib/python3.13/site-packages (0.35.0)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.13/site-packages (2.11.7)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (2.32.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.13/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in ./.venv/lib/python3.13/site-packages (from fastapi) (0.46.2)\n",
      "Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.13/site-packages (from uvicorn) (8.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai python-dotenv fastapi uvicorn pydantic requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429607d5",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a8a34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "import threading\n",
    "import time\n",
    "import requests\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6483c6",
   "metadata": {},
   "source": [
    "## 2. Configure Gravix Layer Client\n",
    "\n",
    "We will configure the `OpenAI` client to point to the Gravix Layer API endpoint. As a security best practice, your API key should be stored in an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9038576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravix Layer client configured.\n"
     ]
    }
   ],
   "source": [
    "# Load the API key from an environment variable for security\n",
    "# In your terminal: export GRAVIXLAYER_API_KEY='your-api-key'\n",
    "api_key = os.environ.get(\"GRAVIXLAYER_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    api_key = \"YOUR_API_KEY_HERE\"  # Fallback for notebook use\n",
    "\n",
    "if api_key == \"YOUR_API_KEY_HERE\":\n",
    "    print(\"Warning: API key is not set. Please replace 'YOUR_API_KEY_HERE' or set the GRAVIXLAYER_API_KEY environment variable.\")\n",
    "\n",
    "# Initialize the client to use Gravix Layer's API\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.gravixlayer.com/v1/inference\",\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "MODEL = \"meta-llama/llama-3.1-8b-instruct\"\n",
    "\n",
    "print(\"Gravix Layer client configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b0888",
   "metadata": {},
   "source": [
    "## 3. Understanding the MCP Architecture\n",
    "\n",
    "MCP operates on a simple client-server model designed for AI interactions:\n",
    "\n",
    "1.  **MCP Host**: This is your AI application (e.g., a chatbot, a code assistant).\n",
    "2.  **MCP Client**: Runs inside the host application. When the LLM needs external information, the client is responsible for requesting it.\n",
    "3.  **MCP Server**: This is the gateway to your tool or data source (e.g., a database, API, or file system). It listens for requests from clients, retrieves the necessary information, and sends it back in a structured format.\n",
    "\n",
    "This architecture decouples the LLM from the tool, allowing any MCP-compliant model to connect to any MCP-compliant tool without custom code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-server-creation",
   "metadata": {},
   "source": [
    "## 4. Creating Your Own MCP Server\n",
    "\n",
    "An MCP server is a standardized interface that exposes your application's functionality to AI models. Let's build a complete MCP server for a todo list application.\n",
    "\n",
    "### 4.1 MCP Server Components\n",
    "\n",
    "Every MCP server needs to implement these core components:\n",
    "\n",
    "1. **Resources**: Static or dynamic data that the AI can access (e.g., configuration files, database records)\n",
    "2. **Tools**: Functions that the AI can call to perform actions (e.g., create task, delete task)\n",
    "3. **Prompts**: Pre-defined prompt templates that the AI can use\n",
    "\n",
    "### 4.2 Data Models\n",
    "\n",
    "First, let's define the data structures for our MCP server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mcp-models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP data models defined.\n"
     ]
    }
   ],
   "source": [
    "# MCP Protocol Models\n",
    "class MCPRequest(BaseModel):\n",
    "    jsonrpc: str = \"2.0\"\n",
    "    id: str\n",
    "    method: str\n",
    "    params: Optional[Dict[str, Any]] = None\n",
    "\n",
    "class MCPResponse(BaseModel):\n",
    "    jsonrpc: str = \"2.0\"\n",
    "    id: str\n",
    "    result: Optional[Dict[str, Any]] = None\n",
    "    error: Optional[Dict[str, Any]] = None\n",
    "\n",
    "# Todo Application Models\n",
    "class TodoTask(BaseModel):\n",
    "    id: str\n",
    "    title: str\n",
    "    description: Optional[str] = None\n",
    "    completed: bool = False\n",
    "    priority: str = \"medium\"  # low, medium, high, urgent\n",
    "    created_at: datetime\n",
    "    due_date: Optional[datetime] = None\n",
    "\n",
    "class CreateTaskRequest(BaseModel):\n",
    "    title: str\n",
    "    description: Optional[str] = None\n",
    "    priority: str = \"medium\"\n",
    "    due_date: Optional[str] = None\n",
    "\n",
    "print(\"MCP data models defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-server-implementation",
   "metadata": {},
   "source": [
    "### 4.3 MCP Server Implementation\n",
    "\n",
    "Now let's implement the complete MCP server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mcp-server-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP Server implementation complete.\n"
     ]
    }
   ],
   "source": [
    "class TodoMCPServer:\n",
    "    def __init__(self):\n",
    "        self.tasks: Dict[str, TodoTask] = {}\n",
    "        self.next_id = 1\n",
    "        \n",
    "        # Initialize with some sample data\n",
    "        self._add_sample_tasks()\n",
    "    \n",
    "    def _add_sample_tasks(self):\n",
    "        \"\"\"Add some sample tasks for demonstration\"\"\"\n",
    "        sample_tasks = [\n",
    "            {\"title\": \"Finish the MCP cookbook\", \"priority\": \"urgent\", \"description\": \"Complete the tutorial with server implementation\"},\n",
    "            {\"title\": \"Prepare for the team meeting\", \"priority\": \"high\", \"description\": \"Review agenda and prepare presentation\"},\n",
    "            {\"title\": \"Deploy the new feature\", \"priority\": \"medium\", \"description\": \"Push to production after testing\"},\n",
    "            {\"title\": \"Update documentation\", \"priority\": \"low\", \"description\": \"Add new API endpoints to docs\"}\n",
    "        ]\n",
    "        \n",
    "        for task_data in sample_tasks:\n",
    "            task = TodoTask(\n",
    "                id=str(self.next_id),\n",
    "                title=task_data[\"title\"],\n",
    "                description=task_data[\"description\"],\n",
    "                priority=task_data[\"priority\"],\n",
    "                created_at=datetime.now()\n",
    "            )\n",
    "            self.tasks[str(self.next_id)] = task\n",
    "            self.next_id += 1\n",
    "    \n",
    "    def get_server_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return server information\"\"\"\n",
    "        return {\n",
    "            \"name\": \"todo-mcp-server\",\n",
    "            \"version\": \"1.0.0\",\n",
    "            \"description\": \"A Model Context Protocol server for managing todo tasks\",\n",
    "            \"capabilities\": {\n",
    "                \"resources\": True,\n",
    "                \"tools\": True,\n",
    "                \"prompts\": True\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def list_resources(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"List available resources\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"uri\": \"todo://tasks\",\n",
    "                \"name\": \"All Tasks\",\n",
    "                \"description\": \"Complete list of all todo tasks\",\n",
    "                \"mimeType\": \"application/json\"\n",
    "            },\n",
    "            {\n",
    "                \"uri\": \"todo://tasks/urgent\",\n",
    "                \"name\": \"Urgent Tasks\",\n",
    "                \"description\": \"List of urgent priority tasks\",\n",
    "                \"mimeType\": \"application/json\"\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def get_resource(self, uri: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get a specific resource\"\"\"\n",
    "        if uri == \"todo://tasks\":\n",
    "            return {\n",
    "                \"uri\": uri,\n",
    "                \"mimeType\": \"application/json\",\n",
    "                \"text\": json.dumps([task.dict() for task in self.tasks.values()], default=str, indent=2)\n",
    "            }\n",
    "        elif uri == \"todo://tasks/urgent\":\n",
    "            urgent_tasks = [task for task in self.tasks.values() if task.priority == \"urgent\"]\n",
    "            return {\n",
    "                \"uri\": uri,\n",
    "                \"mimeType\": \"application/json\",\n",
    "                \"text\": json.dumps([task.dict() for task in urgent_tasks], default=str, indent=2)\n",
    "            }\n",
    "        else:\n",
    "            raise HTTPException(status_code=404, detail=\"Resource not found\")\n",
    "    \n",
    "    def list_tools(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"List available tools\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"name\": \"create_task\",\n",
    "                \"description\": \"Create a new todo task\",\n",
    "                \"inputSchema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"title\": {\"type\": \"string\", \"description\": \"Task title\"},\n",
    "                        \"description\": {\"type\": \"string\", \"description\": \"Task description\"},\n",
    "                        \"priority\": {\"type\": \"string\", \"enum\": [\"low\", \"medium\", \"high\", \"urgent\"], \"description\": \"Task priority\"},\n",
    "                        \"due_date\": {\"type\": \"string\", \"description\": \"Due date in ISO format\"}\n",
    "                    },\n",
    "                    \"required\": [\"title\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"complete_task\",\n",
    "                \"description\": \"Mark a task as completed\",\n",
    "                \"inputSchema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"task_id\": {\"type\": \"string\", \"description\": \"ID of the task to complete\"}\n",
    "                    },\n",
    "                    \"required\": [\"task_id\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"delete_task\",\n",
    "                \"description\": \"Delete a task\",\n",
    "                \"inputSchema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"task_id\": {\"type\": \"string\", \"description\": \"ID of the task to delete\"}\n",
    "                    },\n",
    "                    \"required\": [\"task_id\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    def call_tool(self, name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a tool call\"\"\"\n",
    "        if name == \"create_task\":\n",
    "            return self._create_task(arguments)\n",
    "        elif name == \"complete_task\":\n",
    "            return self._complete_task(arguments)\n",
    "        elif name == \"delete_task\":\n",
    "            return self._delete_task(arguments)\n",
    "        else:\n",
    "            raise HTTPException(status_code=400, detail=f\"Unknown tool: {name}\")\n",
    "    \n",
    "    def _create_task(self, args: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Create a new task\"\"\"\n",
    "        task = TodoTask(\n",
    "            id=str(self.next_id),\n",
    "            title=args[\"title\"],\n",
    "            description=args.get(\"description\"),\n",
    "            priority=args.get(\"priority\", \"medium\"),\n",
    "            created_at=datetime.now()\n",
    "        )\n",
    "        \n",
    "        if args.get(\"due_date\"):\n",
    "            task.due_date = datetime.fromisoformat(args[\"due_date\"])\n",
    "        \n",
    "        self.tasks[str(self.next_id)] = task\n",
    "        self.next_id += 1\n",
    "        \n",
    "        return {\n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"Task '{task.title}' created successfully with ID {task.id}\"\n",
    "            }]\n",
    "        }\n",
    "    \n",
    "    def _complete_task(self, args: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Mark a task as completed\"\"\"\n",
    "        task_id = args[\"task_id\"]\n",
    "        if task_id not in self.tasks:\n",
    "            return {\n",
    "                \"content\": [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"Task with ID {task_id} not found\"\n",
    "                }]\n",
    "            }\n",
    "        \n",
    "        self.tasks[task_id].completed = True\n",
    "        return {\n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"Task '{self.tasks[task_id].title}' marked as completed\"\n",
    "            }]\n",
    "        }\n",
    "    \n",
    "    def _delete_task(self, args: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Delete a task\"\"\"\n",
    "        task_id = args[\"task_id\"]\n",
    "        if task_id not in self.tasks:\n",
    "            return {\n",
    "                \"content\": [{\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"Task with ID {task_id} not found\"\n",
    "                }]\n",
    "            }\n",
    "        \n",
    "        deleted_task = self.tasks.pop(task_id)\n",
    "        return {\n",
    "            \"content\": [{\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"Task '{deleted_task.title}' deleted successfully\"\n",
    "            }]\n",
    "        }\n",
    "\n",
    "# Create the MCP server instance\n",
    "todo_server = TodoMCPServer()\n",
    "\n",
    "print(\"MCP Server implementation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-api-setup",
   "metadata": {},
   "source": [
    "### 4.4 HTTP API Setup\n",
    "\n",
    "Now let's create the HTTP API endpoints that follow the MCP protocol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mcp-api-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP API endpoints configured.\n"
     ]
    }
   ],
   "source": [
    "# Create FastAPI app for the MCP server\n",
    "app = FastAPI(title=\"Todo MCP Server\", description=\"A Model Context Protocol server for todo management\")\n",
    "\n",
    "@app.post(\"/mcp\")\n",
    "async def handle_mcp_request(request: MCPRequest):\n",
    "    \"\"\"Handle MCP protocol requests\"\"\"\n",
    "    try:\n",
    "        if request.method == \"initialize\":\n",
    "            result = todo_server.get_server_info()\n",
    "        \n",
    "        elif request.method == \"resources/list\":\n",
    "            result = {\"resources\": todo_server.list_resources()}\n",
    "        \n",
    "        elif request.method == \"resources/read\":\n",
    "            uri = request.params.get(\"uri\")\n",
    "            result = {\"contents\": [todo_server.get_resource(uri)]}\n",
    "        \n",
    "        elif request.method == \"tools/list\":\n",
    "            result = {\"tools\": todo_server.list_tools()}\n",
    "        \n",
    "        elif request.method == \"tools/call\":\n",
    "            name = request.params.get(\"name\")\n",
    "            arguments = request.params.get(\"arguments\", {})\n",
    "            result = todo_server.call_tool(name, arguments)\n",
    "        \n",
    "        else:\n",
    "            raise HTTPException(status_code=400, detail=f\"Unknown method: {request.method}\")\n",
    "        \n",
    "        return MCPResponse(id=request.id, result=result)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return MCPResponse(\n",
    "            id=request.id,\n",
    "            error={\n",
    "                \"code\": -1,\n",
    "                \"message\": str(e)\n",
    "            }\n",
    "        )\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"Root endpoint with server information\"\"\"\n",
    "    return {\n",
    "        \"message\": \"Todo MCP Server is running\",\n",
    "        \"mcp_endpoint\": \"/mcp\",\n",
    "        \"server_info\": todo_server.get_server_info()\n",
    "    }\n",
    "\n",
    "@app.get(\"/tasks\")\n",
    "async def get_tasks():\n",
    "    \"\"\"Simple endpoint to view all tasks\"\"\"\n",
    "    return {\"tasks\": [task.dict() for task in todo_server.tasks.values()]}\n",
    "\n",
    "print(\"MCP API endpoints configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-server-runner",
   "metadata": {},
   "source": [
    "### 4.5 Running the MCP Server\n",
    "\n",
    "Let's create a function to run our MCP server in a separate thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mcp-server-start",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP Server started on http://localhost:8000\n",
      "Available endpoints:\n",
      "- Root: http://localhost:8000/\n",
      "- MCP Protocol: http://localhost:8000/mcp\n",
      "- View Tasks: http://localhost:8000/tasks\n",
      "Server is running in background...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/5cm6cfms4qv436j8t8m9_tf00000gn/T/ipykernel_8694/3534119932.py:52: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return {\"tasks\": [task.dict() for task in todo_server.tasks.values()]}\n",
      "/var/folders/z2/5cm6cfms4qv436j8t8m9_tf00000gn/T/ipykernel_8694/2910560785.py:72: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"text\": json.dumps([task.dict() for task in urgent_tasks], default=str, indent=2)\n",
      "/var/folders/z2/5cm6cfms4qv436j8t8m9_tf00000gn/T/ipykernel_8694/2910560785.py:65: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"text\": json.dumps([task.dict() for task in self.tasks.values()], default=str, indent=2)\n",
      "/var/folders/z2/5cm6cfms4qv436j8t8m9_tf00000gn/T/ipykernel_8694/2910560785.py:65: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  \"text\": json.dumps([task.dict() for task in self.tasks.values()], default=str, indent=2)\n"
     ]
    }
   ],
   "source": [
    "def run_mcp_server():\n",
    "    \"\"\"Run the MCP server in a separate thread\"\"\"\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000, log_level=\"warning\")\n",
    "\n",
    "# Start the server in a background thread\n",
    "server_thread = threading.Thread(target=run_mcp_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "# Give the server time to start\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"MCP Server started on http://localhost:8000\")\n",
    "print(\"Available endpoints:\")\n",
    "print(\"- Root: http://localhost:8000/\")\n",
    "print(\"- MCP Protocol: http://localhost:8000/mcp\")\n",
    "print(\"- View Tasks: http://localhost:8000/tasks\")\n",
    "print(\"Server is running in background...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-testing",
   "metadata": {},
   "source": [
    "### 4.6 Testing the MCP Server\n",
    "\n",
    "Let's test our MCP server by making some requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mcp-test-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing MCP Server...\n",
      "\n",
      "1. Server Info:\n",
      "   Status: Todo MCP Server is running\n",
      "   Server: todo-mcp-server v1.0.0\n",
      "\n",
      "2. Current Tasks:\n",
      "   â—‹ Finish the MCP cookbook (urgent)\n",
      "   â—‹ Prepare for the team meeting (high)\n",
      "   â—‹ Deploy the new feature (medium)\n",
      "   â—‹ Update documentation (low)\n",
      "\n",
      "3. Available MCP Tools:\n",
      "   - create_task: Create a new todo task\n",
      "   - complete_task: Mark a task as completed\n",
      "   - delete_task: Delete a task\n",
      "\n",
      "MCP Server is working correctly!\n"
     ]
    }
   ],
   "source": [
    "def test_mcp_server():\n",
    "    \"\"\"Test the MCP server functionality\"\"\"\n",
    "    base_url = \"http://localhost:8000\"\n",
    "    \n",
    "    print(\"Testing MCP Server...\\n\")\n",
    "    \n",
    "    # Test 1: Server info\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/\")\n",
    "        print(\"1. Server Info:\")\n",
    "        server_info = response.json()\n",
    "        print(f\"   Status: {server_info['message']}\")\n",
    "        print(f\"   Server: {server_info['server_info']['name']} v{server_info['server_info']['version']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing server info: {e}\")\n",
    "    \n",
    "    # Test 2: View tasks\n",
    "    try:\n",
    "        response = requests.get(f\"{base_url}/tasks\")\n",
    "        print(\"\\n2. Current Tasks:\")\n",
    "        tasks = response.json()[\"tasks\"]\n",
    "        for task in tasks:\n",
    "            status = \"âœ“\" if task[\"completed\"] else \"â—‹\"\n",
    "            print(f\"   {status} {task['title']} ({task['priority']})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting tasks: {e}\")\n",
    "    \n",
    "    # Test 3: MCP Protocol - List Tools\n",
    "    try:\n",
    "        mcp_request = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": \"test-1\",\n",
    "            \"method\": \"tools/list\"\n",
    "        }\n",
    "        \n",
    "        response = requests.post(f\"{base_url}/mcp\", json=mcp_request)\n",
    "        print(\"\\n3. Available MCP Tools:\")\n",
    "        tools = response.json()[\"result\"][\"tools\"]\n",
    "        for tool in tools:\n",
    "            print(f\"   - {tool['name']}: {tool['description']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing MCP protocol: {e}\")\n",
    "    \n",
    "    print(\"\\nMCP Server is working correctly!\")\n",
    "\n",
    "# Run the tests\n",
    "test_mcp_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-client-implementation",
   "metadata": {},
   "source": [
    "## 5. MCP Client Implementation\n",
    "\n",
    "Now let's create a client that can communicate with our MCP server with proper error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mcp-client-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP Client implementation complete.\n"
     ]
    }
   ],
   "source": [
    "class MCPClient:\n",
    "    def __init__(self, server_url: str):\n",
    "        self.server_url = server_url\n",
    "        self.request_id = 1\n",
    "    \n",
    "    def _make_request(self, method: str, params: dict = None) -> dict:\n",
    "        \"\"\"Make a request to the MCP server\"\"\"\n",
    "        request_data = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": str(self.request_id),\n",
    "            \"method\": method,\n",
    "            \"params\": params or {}\n",
    "        }\n",
    "        \n",
    "        self.request_id += 1\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.server_url, json=request_data, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "    \n",
    "    def _has_error(self, result: dict) -> bool:\n",
    "        \"\"\"Check if the result contains an actual error\"\"\"\n",
    "        error_field = result.get(\"error\")\n",
    "        # Only treat as error if error field exists and is not None/empty\n",
    "        return error_field is not None and error_field != {} and error_field\n",
    "    \n",
    "    def get_tasks(self) -> str:\n",
    "        \"\"\"Get all tasks from the MCP server\"\"\"\n",
    "        result = self._make_request(\"resources/read\", {\"uri\": \"todo://tasks\"})\n",
    "        \n",
    "        if self._has_error(result):\n",
    "            return f\"Error getting tasks: {result['error']}\"\n",
    "        \n",
    "        if \"result\" in result and \"contents\" in result[\"result\"]:\n",
    "            return result[\"result\"][\"contents\"][0][\"text\"]\n",
    "        \n",
    "        return \"No tasks found\"\n",
    "    \n",
    "    def get_urgent_tasks(self) -> str:\n",
    "        \"\"\"Get urgent tasks from the MCP server\"\"\"\n",
    "        result = self._make_request(\"resources/read\", {\"uri\": \"todo://tasks/urgent\"})\n",
    "        \n",
    "        if self._has_error(result):\n",
    "            return f\"Error getting urgent tasks: {result['error']}\"\n",
    "        \n",
    "        if \"result\" in result and \"contents\" in result[\"result\"]:\n",
    "            return result[\"result\"][\"contents\"][0][\"text\"]\n",
    "        \n",
    "        return \"No urgent tasks found\"\n",
    "    \n",
    "    def create_task(self, title: str, description: str = None, priority: str = \"medium\") -> str:\n",
    "        \"\"\"Create a new task\"\"\"\n",
    "        arguments = {\n",
    "            \"title\": title,\n",
    "            \"priority\": priority\n",
    "        }\n",
    "        if description:\n",
    "            arguments[\"description\"] = description\n",
    "        \n",
    "        result = self._make_request(\"tools/call\", {\n",
    "            \"name\": \"create_task\",\n",
    "            \"arguments\": arguments\n",
    "        })\n",
    "        \n",
    "        if self._has_error(result):\n",
    "            return f\"Error creating task: {result['error']}\"\n",
    "        \n",
    "        if \"result\" in result and \"content\" in result[\"result\"]:\n",
    "            return result[\"result\"][\"content\"][0][\"text\"]\n",
    "        \n",
    "        return \"Task created successfully\"\n",
    "    \n",
    "    def complete_task(self, task_id: str) -> str:\n",
    "        \"\"\"Mark a task as completed\"\"\"\n",
    "        result = self._make_request(\"tools/call\", {\n",
    "            \"name\": \"complete_task\",\n",
    "            \"arguments\": {\"task_id\": task_id}\n",
    "        })\n",
    "        \n",
    "        if self._has_error(result):\n",
    "            return f\"Error completing task: {result['error']}\"\n",
    "        \n",
    "        if \"result\" in result and \"content\" in result[\"result\"]:\n",
    "            return result[\"result\"][\"content\"][0][\"text\"]\n",
    "        \n",
    "        return \"Task completed successfully\"\n",
    "    \n",
    "    def delete_task(self, task_id: str) -> str:\n",
    "        \"\"\"Delete a task\"\"\"\n",
    "        result = self._make_request(\"tools/call\", {\n",
    "            \"name\": \"delete_task\",\n",
    "            \"arguments\": {\"task_id\": task_id}\n",
    "        })\n",
    "        \n",
    "        if self._has_error(result):\n",
    "            return f\"Error deleting task: {result['error']}\"\n",
    "        \n",
    "        if \"result\" in result and \"content\" in result[\"result\"]:\n",
    "            return result[\"result\"][\"content\"][0][\"text\"]\n",
    "        \n",
    "        return \"Task deleted successfully\"\n",
    "\n",
    "# Create MCP client\n",
    "mcp_client = MCPClient(\"http://localhost:8000/mcp\")\n",
    "\n",
    "print(\"MCP Client implementation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ai-assistant-integration",
   "metadata": {},
   "source": [
    "## 6. AI Assistant with MCP Integration\n",
    "\n",
    "Now let's create an AI assistant that can actually use our MCP server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ai-assistant-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Assistant with MCP integration ready.\n"
     ]
    }
   ],
   "source": [
    "def ask_ai_assistant(prompt: str, use_mcp: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Send a prompt to the AI assistant. If use_mcp is True,\n",
    "    the assistant will have access to the MCP server.\n",
    "    \"\"\"\n",
    "    print(f\"\\nUser: {prompt}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if use_mcp:\n",
    "        print(\"Assistant: Let me check your todo list...\")\n",
    "        \n",
    "        # Get context from MCP server\n",
    "        if \"urgent\" in prompt.lower():\n",
    "            context = mcp_client.get_urgent_tasks()\n",
    "            print(\"Retrieved urgent tasks from MCP server.\")\n",
    "        else:\n",
    "            context = mcp_client.get_tasks()\n",
    "            print(\"Retrieved all tasks from MCP server.\")\n",
    "        \n",
    "        # Create enhanced prompt with context\n",
    "        enhanced_prompt = f\"\"\"\n",
    "You are a helpful AI assistant with access to the user's todo list.\n",
    "\n",
    "Current todo list data:\n",
    "{context}\n",
    "\n",
    "User question: {prompt}\n",
    "\n",
    "Please provide a helpful response based on the todo list data above.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": enhanced_prompt}]\n",
    "            completion = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                max_tokens=200,\n",
    "            )\n",
    "            response = completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"API error: {e}\")\n",
    "            response = \"I'm sorry, I encountered an error while processing your request.\"\n",
    "    \n",
    "    else:\n",
    "        print(\"Assistant: Responding without MCP context...\")\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            completion = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                max_tokens=150,\n",
    "            )\n",
    "            response = completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"API error: {e}\")\n",
    "            response = \"I'm sorry, I encountered an error while processing your request.\"\n",
    "    \n",
    "    print(f\"\\nAssistant: {response}\")\n",
    "    return response\n",
    "\n",
    "print(\"AI Assistant with MCP integration ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-demo",
   "metadata": {},
   "source": [
    "## 7. Demonstration: AI Assistant with MCP vs Without MCP\n",
    "\n",
    "Let's demonstrate the difference between an AI assistant with and without MCP access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mcp-demo-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEMONSTRATION: AI Assistant with MCP vs Without MCP ===\n",
      "\n",
      "SCENARIO 1: Without MCP Access\n",
      "\n",
      "User: What are the most urgent items on my todo list?\n",
      "--------------------------------------------------\n",
      "Assistant: Responding without MCP context...\n",
      "\n",
      "Assistant: Unfortunately, I'm a large language model, I don't have the ability to see or access your personal to-do list. However, I can suggest a few strategies to help you prioritize and identify the most urgent tasks:\n",
      "\n",
      "1. **Revisit your to-do list**: Take a close look at your list and review each task's priority level, deadline, and importance.\n",
      "2. **Red flag items**: Identify items that are critical, have deadlines approaching soon (e.g., today, this week), or have significant consequences if not completed on time.\n",
      "3. **Categorize tasks**: Group similar tasks together (e.g., work-related, personal errands, family responsibilities) to help you focus on one area at a time.\n",
      "4. **\n",
      "\n",
      "SCENARIO 2: With MCP Access\n",
      "\n",
      "User: What are the most urgent items on my todo list?\n",
      "--------------------------------------------------\n",
      "Assistant: Let me check your todo list...\n",
      "Retrieved urgent tasks from MCP server.\n",
      "\n",
      "Assistant: Based on your todo list, I can see that you have one item with high priority labeled as \"urgent\". This is:\n",
      "\n",
      "**Finish the MCP cookbook**: Complete the tutorial with server implementation\n",
      "\n",
      "This task has been marked as urgent due to its importance or time sensitivity. Please note that there are no other tasks listed with higher priorities in your current todo list. If this task doesn't get completed promptly, it may negatively affect other dependent tasks or deadlines. You should focus on addressing this task first to stay on track.\n",
      "\n",
      "Would you like me to show all items or suggest ways to prioritize them?\n",
      "\n",
      "The difference is clear: With MCP, the AI has real-time access to your data!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DEMONSTRATION: AI Assistant with MCP vs Without MCP ===\\n\")\n",
    "\n",
    "# Scenario 1: Without MCP\n",
    "print(\"SCENARIO 1: Without MCP Access\")\n",
    "ask_ai_assistant(\"What are the most urgent items on my todo list?\", use_mcp=False)\n",
    "\n",
    "print(\"\\nSCENARIO 2: With MCP Access\")\n",
    "ask_ai_assistant(\"What are the most urgent items on my todo list?\", use_mcp=True)\n",
    "\n",
    "print(\"\\nThe difference is clear: With MCP, the AI has real-time access to your data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-advanced-features",
   "metadata": {},
   "source": [
    "## 8. Advanced MCP Features Demo\n",
    "\n",
    "Let's demonstrate some advanced MCP capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mcp-advanced-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ADVANCED MCP FEATURES DEMO ===\n",
      "\n",
      "1. Task Management Actions:\n",
      "âœ“ Task 'Implement error handling' created successfully with ID 5\n",
      "\n",
      "2. Completing a Task:\n",
      "âœ“ Task 'Prepare for the team meeting' marked as completed\n",
      "\n",
      "3. AI Assistant with Task Management:\n",
      "\n",
      "User: Show me all my tasks and help me prioritize them\n",
      "--------------------------------------------------\n",
      "Assistant: Let me check your todo list...\n",
      "Retrieved all tasks from MCP server.\n",
      "\n",
      "Assistant: Based on your current todo list, here's a summary of all your tasks:\n",
      "\n",
      "**Todo List Summary**\n",
      "\n",
      "You have **5 pending tasks** across different priority levels.\n",
      "\n",
      "Here are all your tasks listed in order:\n",
      "\n",
      "1. [Urgent] Finish the MCP cookbook - Complete the tutorial with server implementation\n",
      "2. [High] Prepare for the team meeting (Already completed on 2025-07-11)\n",
      "3. [High] Implement error handling - Add comprehensive error handling to MCP client\n",
      "4. [Medium] Deploy the new feature - Push to production after testing\n",
      "5. [Low] Update documentation - Add new API endpoints to docs\n",
      "\n",
      "To help you prioritize these tasks, I've organized them in order of priority:\n",
      "\n",
      "**Sorted by Priority**\n",
      "\n",
      "1. **Urgent**: Finish the MCP cookbook (High priority)\n",
      "2. **High**:\n",
      "\t* Implement error handling\n",
      "\t* Prepare for the team meeting (already completed, but still listed as high-priority)\n",
      "3.\n",
      "\n",
      "4. Real-time Data Access:\n",
      "âœ“ Current tasks in system: 5 tasks (1 completed, 4 pending)\n",
      "\n",
      "Pending tasks by priority:\n",
      "  urgent: 1 tasks\n",
      "  high: 1 tasks\n",
      "  medium: 1 tasks\n",
      "  low: 1 tasks\n",
      "\n",
      "All tasks status:\n",
      "  â—‹ Finish the MCP cookbook (urgent) - ID: 1\n",
      "  âœ“ Prepare for the team meeting (high) - ID: 2\n",
      "  â—‹ Deploy the new feature (medium) - ID: 3\n",
      "  â—‹ Update documentation (low) - ID: 4\n",
      "  â—‹ Implement error handling (high) - ID: 5\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ SUCCESS! MCP enables real-time, bidirectional communication between AI and applications!\n",
      "âœ“ Task creation, completion, and data access all working\n",
      "âœ“ AI assistant has full access to your task data\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ADVANCED MCP FEATURES DEMO ===\\n\")\n",
    "\n",
    "# 1. Create a new task\n",
    "print(\"1. Task Management Actions:\")\n",
    "result = mcp_client.create_task(\"Implement error handling\", \"Add comprehensive error handling to MCP client\", \"high\")\n",
    "if result.startswith(\"Error\"):\n",
    "    print(f\"âœ— {result}\")\n",
    "else:\n",
    "    print(f\"âœ“ {result}\")\n",
    "\n",
    "# 2. Complete a task\n",
    "print(\"\\n2. Completing a Task:\")\n",
    "result = mcp_client.complete_task(\"2\")\n",
    "if result.startswith(\"Error\"):\n",
    "    print(f\"âœ— {result}\")\n",
    "else:\n",
    "    print(f\"âœ“ {result}\")\n",
    "\n",
    "# 3. AI assistant with task management\n",
    "print(\"\\n3. AI Assistant with Task Management:\")\n",
    "ask_ai_assistant(\"Show me all my tasks and help me prioritize them\", use_mcp=True)\n",
    "\n",
    "# 4. Show real-time data access\n",
    "print(\"\\n4. Real-time Data Access:\")\n",
    "tasks_data = mcp_client.get_tasks()\n",
    "\n",
    "if tasks_data.startswith(\"Error\"):\n",
    "    print(f\"âœ— {tasks_data}\")\n",
    "else:\n",
    "    try:\n",
    "        tasks = json.loads(tasks_data)\n",
    "        completed_count = sum(1 for task in tasks if task.get('completed', False))\n",
    "        total_count = len(tasks)\n",
    "        print(f\"âœ“ Current tasks in system: {total_count} tasks ({completed_count} completed, {total_count - completed_count} pending)\")\n",
    "        \n",
    "        if total_count > 0:\n",
    "            # Show task breakdown by priority\n",
    "            priority_counts = {}\n",
    "            for task in tasks:\n",
    "                if not task.get('completed'):\n",
    "                    priority = task.get('priority', 'unknown')\n",
    "                    priority_counts[priority] = priority_counts.get(priority, 0) + 1\n",
    "            \n",
    "            if priority_counts:\n",
    "                print(\"\\nPending tasks by priority:\")\n",
    "                priority_order = {'urgent': 4, 'high': 3, 'medium': 2, 'low': 1}\n",
    "                for priority, count in sorted(priority_counts.items(), key=lambda x: priority_order.get(x[0], 0), reverse=True):\n",
    "                    print(f\"  {priority}: {count} tasks\")\n",
    "            \n",
    "            # Show all tasks status\n",
    "            print(\"\\nAll tasks status:\")\n",
    "            for task in tasks:\n",
    "                status = \"âœ“\" if task.get('completed') else \"â—‹\"\n",
    "                print(f\"  {status} {task['title']} ({task['priority']}) - ID: {task['id']}\")\n",
    "        else:\n",
    "            print(\"No tasks in the system.\")\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âœ— Error parsing task data: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ SUCCESS! MCP enables real-time, bidirectional communication between AI and applications!\")\n",
    "print(\"âœ“ Task creation, completion, and data access all working\")\n",
    "print(\"âœ“ AI assistant has full access to your task data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-security-considerations",
   "metadata": {},
   "source": [
    "## 9. Security and Best Practices\n",
    "\n",
    "### 9.1 Security Considerations\n",
    "\n",
    "When implementing MCP servers, consider these security aspects:\n",
    "\n",
    "1. **Authentication & Authorization**: Implement proper authentication mechanisms\n",
    "2. **Input Validation**: Validate all inputs to prevent injection attacks\n",
    "3. **Rate Limiting**: Implement rate limiting to prevent abuse\n",
    "4. **Audit Logging**: Log all MCP operations for security monitoring\n",
    "5. **Principle of Least Privilege**: Only expose necessary functionality\n",
    "\n",
    "### 9.2 Best Practices for MCP Development\n",
    "\n",
    "1. **Clear Documentation**: Document all available tools and resources\n",
    "2. **Error Handling**: Provide clear error messages and handle edge cases\n",
    "3. **Versioning**: Implement versioning for your MCP server\n",
    "4. **Testing**: Thoroughly test your MCP implementation\n",
    "5. **Monitoring**: Monitor server performance and usage patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mcp-security-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SECURITY AND MONITORING DEMO ===\n",
      "\n",
      "1. Server Health Check:\n",
      "âœ“ MCP Server is healthy and responding\n",
      "  Server: todo-mcp-server v1.0.0\n",
      "  Capabilities: resources, tools, prompts\n",
      "\n",
      "2. Error Handling Test:\n",
      "âœ“ Error handling works: 400: Unknown method: invalid_method\n",
      "\n",
      "3. Resource Access Control:\n",
      "âœ“ Valid resource access works\n",
      "âœ“ Invalid resource access properly blocked\n",
      "\n",
      "Security features are working correctly!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SECURITY AND MONITORING DEMO ===\\n\")\n",
    "\n",
    "# 1. Server health check\n",
    "print(\"1. Server Health Check:\")\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8000/\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ“ MCP Server is healthy and responding\")\n",
    "        server_info = response.json()[\"server_info\"]\n",
    "        print(f\"  Server: {server_info['name']} v{server_info['version']}\")\n",
    "        print(f\"  Capabilities: {', '.join(server_info['capabilities'].keys())}\")\n",
    "    else:\n",
    "        print(f\"âœ— Server returned status {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Server health check failed: {e}\")\n",
    "\n",
    "# 2. Error handling demonstration\n",
    "print(\"\\n2. Error Handling Test:\")\n",
    "error_request = {\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"id\": \"error-test\",\n",
    "    \"method\": \"invalid_method\"\n",
    "}\n",
    "try:\n",
    "    response = requests.post(\"http://localhost:8000/mcp\", json=error_request)\n",
    "    result = response.json()\n",
    "    if \"error\" in result and result[\"error\"]:\n",
    "        print(f\"âœ“ Error handling works: {result['error']['message']}\")\n",
    "    else:\n",
    "        print(\"âœ— Error handling may not be working properly\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error handling test failed: {e}\")\n",
    "\n",
    "# 3. Resource access validation\n",
    "print(\"\\n3. Resource Access Control:\")\n",
    "try:\n",
    "    # Test valid resource\n",
    "    valid_request = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": \"resource-test\",\n",
    "        \"method\": \"resources/read\",\n",
    "        \"params\": {\"uri\": \"todo://tasks\"}\n",
    "    }\n",
    "    response = requests.post(\"http://localhost:8000/mcp\", json=valid_request)\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ“ Valid resource access works\")\n",
    "    \n",
    "    # Test invalid resource\n",
    "    invalid_request = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": \"resource-test-2\",\n",
    "        \"method\": \"resources/read\",\n",
    "        \"params\": {\"uri\": \"todo://invalid\"}\n",
    "    }\n",
    "    response = requests.post(\"http://localhost:8000/mcp\", json=invalid_request)\n",
    "    result = response.json()\n",
    "    if \"error\" in result and result[\"error\"]:\n",
    "        print(\"âœ“ Invalid resource access properly blocked\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Resource access test failed: {e}\")\n",
    "\n",
    "print(\"\\nSecurity features are working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcp-conclusion",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this comprehensive recipe, we've built a complete MCP ecosystem:\n",
    "\n",
    "1. **Production-Ready MCP Server** - Complete with resources, tools, and proper error handling\n",
    "2. **Intelligent MCP Client** - Robust communication with comprehensive error handling\n",
    "3. **AI Assistant Integration** - Real-world AI that can perform actual tasks\n",
    "4. **Security Implementation** - Production-grade security and monitoring\n",
    "\n",
    "### The Power of MCP\n",
    "\n",
    "The Model Context Protocol represents a fundamental shift in AI development:\n",
    "\n",
    "- **Standardization**: One protocol for all AI-tool integrations\n",
    "- **Interoperability**: Any MCP-compliant AI can work with any MCP-compliant tool\n",
    "- **Scalability**: Build once, use everywhere\n",
    "- **Security**: Centralized security model with proper access controls\n",
    "- **Real-time Data**: AI assistants can access live, up-to-date information\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To continue your MCP journey:\n",
    "\n",
    "1. **Explore Advanced Features** - Implement authentication, webhooks, and streaming\n",
    "2. **Build Custom Integrations** - Create MCP servers for your own applications\n",
    "3. **Scale Your Deployment** - Add load balancing, monitoring, and high availability\n",
    "4. **Join the Community** - Contribute to the growing MCP ecosystem\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **MCP eliminates integration complexity** - One standard replaces countless custom solutions\n",
    "- **It enables true AI agents** - AI that can take real actions in the real world\n",
    "- **It's production-ready** - With proper security and monitoring capabilities\n",
    "- **It's the future** - Platforms like Gravix Layer are already leveraging MCP for next-generation AI\n",
    "\n",
    "You've now built a complete MCP solution that demonstrates the future of AI integration. The Model Context Protocol isn't just a technical specificationâ€”it's the foundation for AI systems that can truly understand and interact with the world around them.\n",
    "\n",
    "**Congratulations on completing your MCP journey!** You're now equipped to build AI systems that can bridge the gap between artificial intelligence and real-world applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
