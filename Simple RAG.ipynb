{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gravix Layer Cookbook: Simple RAG System\n",
        "Welcome to the GravixLayer Cookbook! This notebook provides a hands-on, step-by-step guide to building a Retrieval-Augmented Generation (RAG) system using GravixLayer's APIs and vector database.\n",
        "\n",
        "**What you'll learn:**\n",
        "- How to set up GravixLayer for semantic search and LLM-powered generation\n",
        "- How to ingest documents and create a knowledge base\n",
        "- How to retrieve relevant context and generate answers using RAG\n",
        "- How to extend, filter, and evaluate your RAG pipeline\n",
        "\n",
        "**Who is this for?**\n",
        "- Developers, data scientists, and AI enthusiasts looking to build practical RAG systems\n",
        "- Anyone exploring GravixLayer's SDK and APIs for real-world applications\n",
        "\n",
        "## Architecture Overview\n",
        "1. **Document Ingestion**: Convert text documents to vectors using embedding models\n",
        "2. **Vector Storage**: Store embeddings in GravixLayer vector database\n",
        "3. **Retrieval**: Search for relevant documents using semantic similarity\n",
        "4. **Generation**: Use retrieved context with LLM to generate responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install gravixlayer requests python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ GravixLayer client initialized successfully\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from typing import List, Dict, Any\n",
        "from gravixlayer import GravixLayer\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Set up API key (make sure to export GRAVIXLAYER_API_KEY in your environment)\n",
        "API_KEY = os.getenv('GRAVIXLAYER_API_KEY')\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"Please set GRAVIXLAYER_API_KEY environment variable\")\n",
        "\n",
        "# Initialize GravixLayer client\n",
        "client = GravixLayer()\n",
        "print(\"‚úÖ GravixLayer client initialized successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAG System Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Configuration:\n",
            "  embedding_model: baai/bge-large-en-v1.5\n",
            "  llm_model: meta-llama/llama-3.1-8b-instruct\n",
            "  vector_dimension: 1024\n",
            "  similarity_metric: cosine\n",
            "  index_name: rag-knowledge-base\n",
            "  top_k_results: 3\n",
            "  base_url: https://api.gravixlayer.com/v1/vectors\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "CONFIG = {\n",
        "    'embedding_model': 'baai/bge-large-en-v1.5',  # 1024 dimensions\n",
        "    'llm_model': 'meta-llama/llama-3.1-8b-instruct',\n",
        "    'vector_dimension': 1024,\n",
        "    'similarity_metric': 'cosine',\n",
        "    'index_name': 'rag-knowledge-base',\n",
        "    'top_k_results': 3,\n",
        "    'base_url': 'https://api.gravixlayer.com/v1/vectors'\n",
        "}\n",
        "\n",
        "print(f\"üìã Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Database Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Vector database client initialized\n"
          ]
        }
      ],
      "source": [
        "# VectorDatabase class for managing GravixLayer vector DB operations\n",
        "class VectorDatabase:\n",
        "    def __init__(self, api_key: str, base_url: str):\n",
        "        \"\"\"Initialize the VectorDatabase client with API key and base URL.\"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url\n",
        "        self.headers = {\n",
        "            'Authorization': f'Bearer {api_key}',\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "        self.index_id = None\n",
        "    \n",
        "    def create_index(self, name: str, dimension: int, metric: str) -> str:\n",
        "        \"\"\"Create a new vector index with the given name, dimension, and metric.\n",
        "        Returns the index ID if successful, else None.\"\"\"\n",
        "        url = f\"{self.base_url}/indexes\"\n",
        "        payload = {\n",
        "            \"name\": name,\n",
        "            \"dimension\": dimension,\n",
        "            \"metric\": metric,\n",
        "            \"vector_type\": \"dense\"\n",
        "        }\n",
        "        \n",
        "        response = requests.post(url, headers=self.headers, json=payload)\n",
        "        \n",
        "        if response.status_code == 201:\n",
        "            result = response.json()\n",
        "            self.index_id = result['id']\n",
        "            print(f\"‚úÖ Index created successfully: {result['id']}\")\n",
        "            return result['id']\n",
        "        else:\n",
        "            print(f\"‚ùå Error creating index: {response.text}\")\n",
        "            return None\n",
        "    \n",
        "    def list_indexes(self) -> List[Dict]:\n",
        "        \"\"\"List all vector indexes available in the database.\n",
        "        Returns a list of index metadata dictionaries.\"\"\"\n",
        "        url = f\"{self.base_url}/indexes\"\n",
        "        response = requests.get(url, headers=self.headers)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            return response.json()['indexes']\n",
        "        return []\n",
        "    \n",
        "    def find_or_create_index(self, name: str, dimension: int, metric: str) -> str:\n",
        "        \"\"\"Find an existing index by name, or create a new one if not found.\n",
        "        Returns the index ID.\"\"\"\n",
        "        indexes = self.list_indexes()\n",
        "        \n",
        "        # Check if index already exists\n",
        "        for index in indexes:\n",
        "            if index['name'] == name:\n",
        "                self.index_id = index['id']\n",
        "                print(f\"üìÅ Using existing index: {index['id']}\")\n",
        "                return index['id']\n",
        "        \n",
        "        # Create new index if not found\n",
        "        return self.create_index(name, dimension, metric)\n",
        "    \n",
        "    def upsert_text_vectors(self, texts_with_metadata: List[Dict]) -> bool:\n",
        "        \"\"\"Upsert (insert/update) text vectors into the database with automatic embedding.\n",
        "        Returns True if successful, else False.\"\"\"\n",
        "        if not self.index_id:\n",
        "            print(\"‚ùå No index selected\")\n",
        "            return False\n",
        "        \n",
        "        url = f\"{self.base_url}/{self.index_id}/text/upsert\"\n",
        "        payload = {\"vectors\": texts_with_metadata}\n",
        "        \n",
        "        response = requests.post(url, headers=self.headers, json=payload)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            print(f\"‚úÖ Upserted {result['upserted_count']} vectors successfully\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Error upserting vectors: {response.text}\")\n",
        "            return False\n",
        "    \n",
        "    def search_text(self, query: str, model: str, top_k: int = 3, filter_dict: Dict = None) -> List[Dict]:\n",
        "        \"\"\"Search for similar vectors using a text query and optional filters.\n",
        "        Returns a list of matching vector hits.\"\"\"\n",
        "        if not self.index_id:\n",
        "            print(\"‚ùå No index selected\")\n",
        "            return []\n",
        "        \n",
        "        url = f\"{self.base_url}/{self.index_id}/search/text\"\n",
        "        payload = {\n",
        "            \"query\": query,\n",
        "            \"model\": model,\n",
        "            \"top_k\": top_k,\n",
        "            \"include_metadata\": True,\n",
        "            \"include_values\": False\n",
        "        }\n",
        "        \n",
        "        if filter_dict:\n",
        "            payload[\"filter\"] = filter_dict\n",
        "        \n",
        "        response = requests.post(url, headers=self.headers, json=payload)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            print(f\"üîç Found {len(result['hits'])} relevant documents (took {result['query_time_ms']}ms)\")\n",
        "            return result['hits']\n",
        "        else:\n",
        "            print(f\"‚ùå Error searching: {response.text}\")\n",
        "            return []\n",
        "\n",
        "# Initialize vector database\n",
        "vector_db = VectorDatabase(API_KEY, CONFIG['base_url'])\n",
        "print(\"üîß Vector database client initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Vector Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Index created successfully: 28702d39-b691-4c91-bbe3-6e8ab10857e1\n",
            "üìä Vector index ready: 28702d39-b691-4c91-bbe3-6e8ab10857e1\n"
          ]
        }
      ],
      "source": [
        "# Create or find vector index\n",
        "index_id = vector_db.find_or_create_index(\n",
        "    name=CONFIG['index_name'],\n",
        "    dimension=CONFIG['vector_dimension'],\n",
        "    metric=CONFIG['similarity_metric']\n",
        ")\n",
        "\n",
        "if index_id:\n",
        "    print(f\"üìä Vector index ready: {index_id}\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to create/find vector index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Knowledge Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Prepared 6 documents for ingestion\n",
            "  - doc_ai_overview: overview\n",
            "  - doc_machine_learning: machine_learning\n",
            "  - doc_deep_learning: deep_learning\n",
            "  - doc_nlp: nlp\n",
            "  - doc_rag: rag\n",
            "  - doc_python: python\n"
          ]
        }
      ],
      "source": [
        "# Sample documents for the knowledge base\n",
        "knowledge_base = [\n",
        "    {\n",
        "        \"id\": \"doc_ai_overview\",\n",
        "        \"text\": \"Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence. AI systems can learn, reason, perceive, and make decisions. Machine learning, deep learning, and neural networks are key components of modern AI.\",\n",
        "        \"model\": CONFIG['embedding_model'],\n",
        "        \"metadata\": {\n",
        "            \"category\": \"AI\",\n",
        "            \"topic\": \"overview\",\n",
        "            \"difficulty\": \"beginner\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_machine_learning\",\n",
        "        \"text\": \"Machine Learning (ML) is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. ML algorithms build mathematical models based on training data to make predictions or decisions. Common types include supervised learning, unsupervised learning, and reinforcement learning.\",\n",
        "        \"model\": CONFIG['embedding_model'],\n",
        "        \"metadata\": {\n",
        "            \"category\": \"AI\",\n",
        "            \"topic\": \"machine_learning\",\n",
        "            \"difficulty\": \"intermediate\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_deep_learning\",\n",
        "        \"text\": \"Deep Learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (hence 'deep') to model and understand complex patterns in data. It's particularly effective for tasks like image recognition, natural language processing, and speech recognition. Popular frameworks include TensorFlow and PyTorch.\",\n",
        "        \"model\": CONFIG['embedding_model'],\n",
        "        \"metadata\": {\n",
        "            \"category\": \"AI\",\n",
        "            \"topic\": \"deep_learning\",\n",
        "            \"difficulty\": \"advanced\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_nlp\",\n",
        "        \"text\": \"Natural Language Processing (NLP) is a field of AI that focuses on enabling computers to understand, interpret, and generate human language. NLP combines computational linguistics with machine learning and deep learning. Applications include chatbots, translation, sentiment analysis, and text summarization.\",\n",
        "        \"model\": CONFIG['embedding_model'],\n",
        "        \"metadata\": {\n",
        "            \"category\": \"AI\",\n",
        "            \"topic\": \"nlp\",\n",
        "            \"difficulty\": \"intermediate\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_rag\",\n",
        "        \"text\": \"Retrieval-Augmented Generation (RAG) is an AI technique that combines information retrieval with text generation. RAG systems first retrieve relevant documents from a knowledge base, then use this context to generate more accurate and informed responses. This approach helps reduce hallucinations and provides more factual answers.\",\n",
        "        \"model\": CONFIG['embedding_model'],\n",
        "        \"metadata\": {\n",
        "            \"category\": \"AI\",\n",
        "            \"topic\": \"rag\",\n",
        "            \"difficulty\": \"advanced\"\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc_python\",\n",
        "        \"text\": \"Python is a high-level, interpreted programming language known for its simplicity and readability. It's widely used in AI and machine learning due to its extensive libraries like NumPy, Pandas, Scikit-learn, TensorFlow, and PyTorch. Python's syntax makes it ideal for rapid prototyping and development.\",\n",
        "        \"model\": CONFIG['embedding_model'],\n",
        "        \"metadata\": {\n",
        "            \"category\": \"Programming\",\n",
        "            \"topic\": \"python\",\n",
        "            \"difficulty\": \"beginner\"\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"üìö Prepared {len(knowledge_base)} documents for ingestion\")\n",
        "for doc in knowledge_base:\n",
        "    print(f\"  - {doc['id']}: {doc['metadata']['topic']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ingest Documents into Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Ingesting documents into vector database...\n",
            "‚úÖ Upserted 6 vectors successfully\n",
            "‚úÖ All documents successfully ingested into vector database\n"
          ]
        }
      ],
      "source": [
        "# Ingest documents into vector database\n",
        "print(\"üì• Ingesting documents into vector database...\")\n",
        "success = vector_db.upsert_text_vectors(knowledge_base)\n",
        "\n",
        "if success:\n",
        "    print(\"‚úÖ All documents successfully ingested into vector database\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to ingest documents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAG System Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ RAG system initialized and ready!\n"
          ]
        }
      ],
      "source": [
        "# SimpleRAG class for RAG pipeline using GravixLayer\n",
        "class SimpleRAG:\n",
        "    def __init__(self, vector_db: VectorDatabase, llm_client: GravixLayer, config: Dict):\n",
        "        \"\"\"Initialize the SimpleRAG system with vector DB, LLM client, and config.\"\"\"\n",
        "        self.vector_db = vector_db\n",
        "        self.llm_client = llm_client\n",
        "        self.config = config\n",
        "    \n",
        "    def retrieve_context(self, query: str, top_k: int = None) -> str:\n",
        "        \"\"\"Retrieve relevant context from the vector database for a given query.\n",
        "        Returns a formatted string of context sources.\"\"\"\n",
        "        if top_k is None:\n",
        "            top_k = self.config['top_k_results']\n",
        "        \n",
        "        # Search for relevant documents\n",
        "        hits = self.vector_db.search_text(\n",
        "            query=query,\n",
        "            model=self.config['embedding_model'],\n",
        "            top_k=top_k\n",
        "        )\n",
        "        \n",
        "        # Extract and format context\n",
        "        context_parts = []\n",
        "        for i, hit in enumerate(hits, 1):\n",
        "            metadata = hit.get('metadata', {})\n",
        "            topic = metadata.get('topic', 'unknown')\n",
        "            category = metadata.get('category', 'unknown')\n",
        "            \n",
        "            # Find the original text from our knowledge base\n",
        "            doc_text = None\n",
        "            for doc in knowledge_base:\n",
        "                if doc['id'] == hit['id']:\n",
        "                    doc_text = doc['text']\n",
        "                    break\n",
        "            \n",
        "            if doc_text:\n",
        "                context_parts.append(\n",
        "                    f\"Source {i} (Score: {hit['score']:.3f}, Topic: {topic}, Category: {category}):\\n{doc_text}\"\n",
        "                )\n",
        "        \n",
        "        return \"\\n\\n\".join(context_parts)\n",
        "    \n",
        "    def generate_response(self, query: str, context: str) -> str:\n",
        "        \"\"\"Generate a response using the LLM, based on the retrieved context and user query.\n",
        "        Returns the generated answer as a string.\"\"\"\n",
        "        prompt = f\"\"\"You are a helpful AI assistant. Use the provided context to answer the user's question accurately and comprehensively.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "1. Base your answer primarily on the provided context\n",
        "2. If the context doesn't contain enough information, say so clearly\n",
        "3. Be concise but thorough\n",
        "4. Cite which sources you're using when relevant\n",
        "\n",
        "Answer:\"\"\"\n",
        "        \n",
        "        try:\n",
        "            response = self.llm_client.chat.completions.create(\n",
        "                model=self.config['llm_model'],\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=500,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            \n",
        "            return response.choices[0].message.content\n",
        "        \n",
        "        except Exception as e:\n",
        "            return f\"Error generating response: {str(e)}\"\n",
        "    \n",
        "    def query(self, question: str, show_context: bool = True) -> Dict[str, Any]:\n",
        "        \"\"\"Main method to run a RAG query: retrieves context and generates a response.\n",
        "        Returns a dictionary with the query, context, and response.\"\"\"\n",
        "        print(f\"ü§î Query: {question}\")\n",
        "        print(\"‚îÄ\" * 80)\n",
        "        \n",
        "        # Step 1: Retrieve relevant context\n",
        "        print(\"üîç Retrieving relevant context...\")\n",
        "        context = self.retrieve_context(question)\n",
        "        \n",
        "        if show_context:\n",
        "            print(\"\\nüìÑ Retrieved Context:\")\n",
        "            print(context)\n",
        "            print(\"\\n\" + \"‚îÄ\" * 80)\n",
        "        \n",
        "        # Step 2: Generate response\n",
        "        print(\"ü§ñ Generating response...\")\n",
        "        response = self.generate_response(question, context)\n",
        "        \n",
        "        print(\"\\nüí° Response:\")\n",
        "        print(response)\n",
        "        print(\"\\n\" + \"‚ïê\" * 80)\n",
        "        \n",
        "        return {\n",
        "            \"query\": question,\n",
        "            \"context\": context,\n",
        "            \"response\": response\n",
        "        }\n",
        "\n",
        "# Initialize RAG system\n",
        "rag_system = SimpleRAG(vector_db, client, CONFIG)\n",
        "print(\"üöÄ RAG system initialized and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the RAG System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§î Query: What is artificial intelligence and how does it work?\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 54ms)\n",
            "\n",
            "üìÑ Retrieved Context:\n",
            "Source 1 (Score: 0.826, Topic: overview, Category: AI):\n",
            "Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence. AI systems can learn, reason, perceive, and make decisions. Machine learning, deep learning, and neural networks are key components of modern AI.\n",
            "\n",
            "Source 2 (Score: 0.660, Topic: machine_learning, Category: AI):\n",
            "Machine Learning (ML) is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. ML algorithms build mathematical models based on training data to make predictions or decisions. Common types include supervised learning, unsupervised learning, and reinforcement learning.\n",
            "\n",
            "Source 3 (Score: 0.653, Topic: deep_learning, Category: AI):\n",
            "Deep Learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (hence 'deep') to model and understand complex patterns in data. It's particularly effective for tasks like image recognition, natural language processing, and speech recognition. Popular frameworks include TensorFlow and PyTorch.\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence [1]. AI systems can learn, reason, perceive, and make decisions.\n",
            "\n",
            "At its core, AI relies on various components, including machine learning, deep learning, and neural networks. These components enable AI systems to improve from experience without being explicitly programmed and to model and understand complex patterns in data [2, 3].\n",
            "\n",
            "In more detail, AI works by:\n",
            "\n",
            "* Using machine learning algorithms that build mathematical models based on training data to make predictions or decisions (Source 2)\n",
            "* Incorporating deep learning techniques that utilize artificial neural networks with multiple layers to analyze complex patterns in data (Source 3)\n",
            "\n",
            "While the provided context provides a good overview of AI and its components, it does not delve into the underlying mechanisms and algorithms that make AI work. For a more comprehensive understanding, additional sources would be necessary.\n",
            "\n",
            "References:\n",
            "[1] Source 1 (Score: 0.826, Topic: overview, Category: AI)\n",
            "[2] Source 2 (Score: 0.660, Topic: machine_learning, Category: AI)\n",
            "[3] Source 3 (Score: 0.653, Topic: deep_learning, Category: AI)\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
          ]
        }
      ],
      "source": [
        "# Test query 1: General AI question\n",
        "result1 = rag_system.query(\"What is artificial intelligence and how does it work?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§î Query: Explain the difference between machine learning and deep learning\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 61ms)\n",
            "\n",
            "üìÑ Retrieved Context:\n",
            "Source 1 (Score: 0.793, Topic: deep_learning, Category: AI):\n",
            "Deep Learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (hence 'deep') to model and understand complex patterns in data. It's particularly effective for tasks like image recognition, natural language processing, and speech recognition. Popular frameworks include TensorFlow and PyTorch.\n",
            "\n",
            "Source 2 (Score: 0.725, Topic: machine_learning, Category: AI):\n",
            "Machine Learning (ML) is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. ML algorithms build mathematical models based on training data to make predictions or decisions. Common types include supervised learning, unsupervised learning, and reinforcement learning.\n",
            "\n",
            "Source 3 (Score: 0.632, Topic: overview, Category: AI):\n",
            "Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence. AI systems can learn, reason, perceive, and make decisions. Machine learning, deep learning, and neural networks are key components of modern AI.\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Machine Learning (ML) and Deep Learning are both subsets of Artificial Intelligence (AI), but they have distinct differences.\n",
            "\n",
            "**Machine Learning (Source 2)** is a broader field that enables computers to learn from experience without being explicitly programmed. It involves building mathematical models based on training data to make predictions or decisions, including supervised learning, unsupervised learning, and reinforcement learning.\n",
            "\n",
            "**Deep Learning (Source 1)** is a specialized subset of Machine Learning that uses artificial neural networks with multiple layers to model complex patterns in data. It's particularly effective for tasks like image recognition, natural language processing, and speech recognition.\n",
            "\n",
            "In other words, all Deep Learning models are Machine Learning models, but not all Machine Learning models are Deep Learning models (Source 2 doesn't specify the use of neural networks). Deep Learning is a more specific technique that leverages complex neural networks to achieve state-of-the-art results in certain tasks.\n",
            "\n",
            "Note: The context provides sufficient information to answer this question.\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
          ]
        }
      ],
      "source": [
        "# Test query 2: Specific topic\n",
        "result2 = rag_system.query(\"Explain the difference between machine learning and deep learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§î Query: What is RAG and how does it help with AI applications?\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 63ms)\n",
            "\n",
            "üìÑ Retrieved Context:\n",
            "Source 1 (Score: 0.797, Topic: rag, Category: AI):\n",
            "Retrieval-Augmented Generation (RAG) is an AI technique that combines information retrieval with text generation. RAG systems first retrieve relevant documents from a knowledge base, then use this context to generate more accurate and informed responses. This approach helps reduce hallucinations and provides more factual answers.\n",
            "\n",
            "Source 2 (Score: 0.644, Topic: overview, Category: AI):\n",
            "Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines capable of performing tasks that typically require human intelligence. AI systems can learn, reason, perceive, and make decisions. Machine learning, deep learning, and neural networks are key components of modern AI.\n",
            "\n",
            "Source 3 (Score: 0.619, Topic: nlp, Category: AI):\n",
            "Natural Language Processing (NLP) is a field of AI that focuses on enabling computers to understand, interpret, and generate human language. NLP combines computational linguistics with machine learning and deep learning. Applications include chatbots, translation, sentiment analysis, and text summarization.\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "RAG stands for Retrieval-Augmented Generation, an AI technique that combines information retrieval with text generation (Source 1). This approach helps to reduce hallucinations and provide more factual answers by first retrieving relevant documents from a knowledge base and then using this context to generate responses.\n",
            "\n",
            "In the context of AI applications, RAG can be used in various tasks such as chatbots, translation, and text summarization, which are all part of Natural Language Processing (NLP) - a field of AI that enables computers to understand, interpret, and generate human language (Source 3).\n",
            "\n",
            "RAG's ability to reduce hallucinations and provide factual answers is particularly useful for applications where accuracy is crucial. This makes it a valuable tool in the broader field of Artificial Intelligence (AI), which aims to create intelligent machines capable of performing tasks that typically require human intelligence (Source 2).\n",
            "\n",
            "Sources:\n",
            "- Source 1: Explanation of RAG\n",
            "- Source 3: NLP as part of AI and potential applications of RAG\n",
            "Note: The context provides sufficient information about RAG, but it does not delve deeper into its technical implementation or specific use cases beyond NLP.\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
          ]
        }
      ],
      "source": [
        "# Test query 3: About RAG itself\n",
        "result3 = rag_system.query(\"What is RAG and how does it help with AI applications?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§î Query: Why is Python popular for machine learning?\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 53ms)\n",
            "\n",
            "üìÑ Retrieved Context:\n",
            "Source 1 (Score: 0.812, Topic: python, Category: Programming):\n",
            "Python is a high-level, interpreted programming language known for its simplicity and readability. It's widely used in AI and machine learning due to its extensive libraries like NumPy, Pandas, Scikit-learn, TensorFlow, and PyTorch. Python's syntax makes it ideal for rapid prototyping and development.\n",
            "\n",
            "Source 2 (Score: 0.715, Topic: machine_learning, Category: AI):\n",
            "Machine Learning (ML) is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. ML algorithms build mathematical models based on training data to make predictions or decisions. Common types include supervised learning, unsupervised learning, and reinforcement learning.\n",
            "\n",
            "Source 3 (Score: 0.675, Topic: deep_learning, Category: AI):\n",
            "Deep Learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (hence 'deep') to model and understand complex patterns in data. It's particularly effective for tasks like image recognition, natural language processing, and speech recognition. Popular frameworks include TensorFlow and PyTorch.\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Python is a popular choice for machine learning due to its extensive libraries such as NumPy, Pandas, Scikit-learn, TensorFlow, and PyTorch (Source 1). These libraries provide efficient data manipulation, analysis, and modeling capabilities that are critical in machine learning. Additionally, Python's syntax makes it ideal for rapid prototyping and development (Source 1), which is particularly useful in the iterative process of machine learning.\n",
            "\n",
            "Machine learning itself is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed (Source 2). However, I couldn't find specific information on why Python's popularity directly relates to its suitability for machine learning. \n",
            "\n",
            "One possible reason may be due to the fact that many popular deep learning frameworks, such as TensorFlow and PyTorch, are built or have strong ties with the Python programming language. Deep Learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (Source 3).\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
          ]
        }
      ],
      "source": [
        "# Test query 4: Programming related\n",
        "result4 = rag_system.query(\"Why is Python popular for machine learning?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced RAG Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing filtered search - AI category only:\n",
            "üîç Searching: 'learning algorithms'\n",
            "üìã Filters: {'category': 'AI'}\n",
            "üîç Found 3 relevant documents (took 47ms)\n",
            "\n",
            "üìä Results:\n",
            "  - doc_machine_learning: Score 0.713 | {'category': 'AI', 'difficulty': 'intermediate', 'topic': 'machine_learning'}\n",
            "  - doc_deep_learning: Score 0.628 | {'category': 'AI', 'difficulty': 'advanced', 'topic': 'deep_learning'}\n",
            "  - doc_ai_overview: Score 0.580 | {'category': 'AI', 'difficulty': 'beginner', 'topic': 'overview'}\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing filtered search - Beginner difficulty only:\n",
            "üîç Searching: 'programming'\n",
            "üìã Filters: {'difficulty': 'beginner'}\n",
            "üîç Found 2 relevant documents (took 46ms)\n",
            "\n",
            "üìä Results:\n",
            "  - doc_python: Score 0.644 | {'category': 'Programming', 'difficulty': 'beginner', 'topic': 'python'}\n",
            "  - doc_ai_overview: Score 0.599 | {'category': 'AI', 'difficulty': 'beginner', 'topic': 'overview'}\n"
          ]
        }
      ],
      "source": [
        "# Function to search with metadata filtering in the vector DB\n",
        "def search_with_filter(query: str, category: str = None, difficulty: str = None):\n",
        "    \"\"\"Search for documents using a query and optional metadata filters (category, difficulty).\n",
        "    Prints results and returns the list of hits.\"\"\"\n",
        "    filter_dict = {}\n",
        "    if category:\n",
        "        filter_dict['category'] = category\n",
        "    if difficulty:\n",
        "        filter_dict['difficulty'] = difficulty\n",
        "    \n",
        "    print(f\"üîç Searching: '{query}'\")\n",
        "    if filter_dict:\n",
        "        print(f\"üìã Filters: {filter_dict}\")\n",
        "    \n",
        "    hits = vector_db.search_text(\n",
        "        query=query,\n",
        "        model=CONFIG['embedding_model'],\n",
        "        top_k=3,\n",
        "        filter_dict=filter_dict if filter_dict else None\n",
        "    )\n",
        "    \n",
        "    print(\"\\nüìä Results:\")\n",
        "    for hit in hits:\n",
        "        metadata = hit.get('metadata', {})\n",
        "        print(f\"  - {hit['id']}: Score {hit['score']:.3f} | {metadata}\")\n",
        "    \n",
        "    return hits\n",
        "\n",
        "# Test filtering by category\n",
        "print(\"Testing filtered search - AI category only:\")\n",
        "ai_results = search_with_filter(\"learning algorithms\", category=\"AI\")\n",
        "\n",
        "print(\"\\n\" + \"‚îÄ\" * 60)\n",
        "print(\"Testing filtered search - Beginner difficulty only:\")\n",
        "beginner_results = search_with_filter(\"programming\", difficulty=\"beginner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive RAG Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive chat interface for the RAG system\n",
        "def interactive_rag_chat():\n",
        "    \"\"\"Start an interactive chat loop for asking questions to the RAG system.\n",
        "    Type 'quit', 'exit', or 'bye' to end the chat.\"\"\"\n",
        "    print(\"ü§ñ Welcome to the RAG Chat System!\")\n",
        "    print(\"Ask questions about AI, machine learning, or programming.\")\n",
        "    print(\"Type 'quit' to exit.\\n\")\n",
        "    \n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"üôã Your question: \").strip()\n",
        "            \n",
        "            if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "                print(\"üëã Goodbye!\")\n",
        "                break\n",
        "            \n",
        "            if not user_input:\n",
        "                print(\"Please enter a question.\")\n",
        "                continue\n",
        "            \n",
        "            # Process the query and print the response\n",
        "            result = rag_system.query(user_input, show_context=False)\n",
        "            \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nüëã Chat interrupted. Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "# Uncomment the line below to start interactive chat\n",
        "# interactive_rag_chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## System Statistics and Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä RAG System Statistics\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "üìÅ Total Indexes: 2\n",
            "\n",
            "üîç Index: rag-knowledge-base\n",
            "  - ID: 28702d39-b691-4c91-bbe3-6e8ab10857e1\n",
            "  - Dimension: 1024\n",
            "  - Metric: cosine\n",
            "  - Status: ready\n",
            "  - Created: 2025-09-19T08:36:47.90609Z\n",
            "\n",
            "üîç Index: product-embeddings\n",
            "  - ID: bf93acdc-dc02-4514-8a6f-292e85fc3450\n",
            "  - Dimension: 1024\n",
            "  - Metric: cosine\n",
            "  - Status: ready\n",
            "  - Created: 2025-09-18T13:02:58.152099Z\n",
            "\n",
            "üìö Knowledge Base: 6 documents\n",
            "ü§ñ LLM Model: meta-llama/llama-3.1-8b-instruct\n",
            "üî§ Embedding Model: baai/bge-large-en-v1.5\n",
            "üìè Vector Dimension: 1024\n",
            "üìê Similarity Metric: cosine\n"
          ]
        }
      ],
      "source": [
        "# Function to display system statistics and configuration\n",
        "def show_system_stats():\n",
        "    \"\"\"Display statistics about the RAG system, indexes, and configuration.\"\"\"\n",
        "    print(\"üìä RAG System Statistics\")\n",
        "    print(\"‚ïê\" * 40)\n",
        "    \n",
        "    # List all indexes\n",
        "    indexes = vector_db.list_indexes()\n",
        "    print(f\"üìÅ Total Indexes: {len(indexes)}\")\n",
        "    \n",
        "    for index in indexes:\n",
        "        print(f\"\\nüîç Index: {index['name']}\")\n",
        "        print(f\"  - ID: {index['id']}\")\n",
        "        print(f\"  - Dimension: {index['dimension']}\")\n",
        "        print(f\"  - Metric: {index['metric']}\")\n",
        "        print(f\"  - Status: {index['status']}\")\n",
        "        print(f\"  - Created: {index['created_at']}\")\n",
        "    \n",
        "    print(f\"\\nüìö Knowledge Base: {len(knowledge_base)} documents\")\n",
        "    print(f\"ü§ñ LLM Model: {CONFIG['llm_model']}\")\n",
        "    print(f\"üî§ Embedding Model: {CONFIG['embedding_model']}\")\n",
        "    print(f\"üìè Vector Dimension: {CONFIG['vector_dimension']}\")\n",
        "    print(f\"üìê Similarity Metric: {CONFIG['similarity_metric']}\")\n",
        "\n",
        "show_system_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding New Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Upserted 1 vectors successfully\n",
            "‚úÖ Document 'doc_transformers' added successfully\n",
            "\n",
            "Testing with new document:\n",
            "ü§î Query: What are transformers in machine learning?\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 51ms)\n",
            "\n",
            "üìÑ Retrieved Context:\n",
            "Source 1 (Score: 0.828, Topic: transformers, Category: AI):\n",
            "Transformers are a type of neural network architecture that has revolutionized natural language processing. Introduced in the 'Attention is All You Need' paper, transformers use self-attention mechanisms to process sequences of data. They form the basis of large language models like GPT, BERT, and T5.\n",
            "\n",
            "Source 2 (Score: 0.709, Topic: machine_learning, Category: AI):\n",
            "Machine Learning (ML) is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. ML algorithms build mathematical models based on training data to make predictions or decisions. Common types include supervised learning, unsupervised learning, and reinforcement learning.\n",
            "\n",
            "Source 3 (Score: 0.677, Topic: deep_learning, Category: AI):\n",
            "Deep Learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (hence 'deep') to model and understand complex patterns in data. It's particularly effective for tasks like image recognition, natural language processing, and speech recognition. Popular frameworks include TensorFlow and PyTorch.\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Based on Source 1, transformers are a type of neural network architecture that has revolutionized natural language processing (NLP). They use self-attention mechanisms to process sequences of data and form the basis of large language models like GPT, BERT, and T5.\n",
            "\n",
            "To answer the question more broadly, we can relate this information to machine learning. According to Source 2, machine learning is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. Deep Learning (Source 3) is a specialized subset of machine learning that uses artificial neural networks with multiple layers to model complex patterns in data.\n",
            "\n",
            "Transformers are actually a type of deep learning architecture, which falls under the broader category of machine learning. They are particularly effective for NLP tasks due to their ability to process sequences of data using self-attention mechanisms.\n",
            "\n",
            "So, in summary: transformers are a specific type of neural network architecture that uses self-attention mechanisms to revolutionize natural language processing, and they fall under the categories of both deep learning and machine learning.\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n"
          ]
        }
      ],
      "source": [
        "# Function to add a new document to the knowledge base and vector DB\n",
        "def add_document(doc_id: str, text: str, category: str, topic: str, difficulty: str = \"intermediate\"):\n",
        "    \"\"\"Add a new document to the knowledge base and upsert it into the vector database.\n",
        "    Returns True if successful, else False.\"\"\"\n",
        "    new_doc = {\n",
        "        \"id\": doc_id,\n",
        "        \"text\": text,\n",
        "        \"model\": CONFIG['embedding_model'],\n",
        "        \"metadata\": {\n",
        "            \"category\": category,\n",
        "            \"topic\": topic,\n",
        "            \"difficulty\": difficulty\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Add to vector database\n",
        "    success = vector_db.upsert_text_vectors([new_doc])\n",
        "    \n",
        "    if success:\n",
        "        # Add to local knowledge base for reference\n",
        "        knowledge_base.append(new_doc)\n",
        "        print(f\"‚úÖ Document '{doc_id}' added successfully\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"‚ùå Failed to add document '{doc_id}'\")\n",
        "        return False\n",
        "\n",
        "# Example: Add a new document about transformers\n",
        "add_document(\n",
        "    doc_id=\"doc_transformers\",\n",
        "    text=\"Transformers are a type of neural network architecture that has revolutionized natural language processing. Introduced in the 'Attention is All You Need' paper, transformers use self-attention mechanisms to process sequences of data. They form the basis of large language models like GPT, BERT, and T5.\",\n",
        "    category=\"AI\",\n",
        "    topic=\"transformers\",\n",
        "    difficulty=\"advanced\"\n",
        "    )\n",
        "\n",
        "# Test the new document\n",
        "print(\"\\nTesting with new document:\")\n",
        "result_new = rag_system.query(\"What are transformers in machine learning?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¨ Evaluating RAG System Performance\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "\n",
            "Test 1/5: What is the difference between AI and machine learning?\n",
            "ü§î Query: What is the difference between AI and machine learning?\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 53ms)\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Based on the provided context, I'd be happy to explain the difference between AI and machine learning.\n",
            "\n",
            "AI (Artificial Intelligence) is a broader field that aims to create intelligent machines capable of performing tasks that typically require human intelligence [Source 2]. It encompasses various subfields, including machine learning. In other words, all machine learning falls under the umbrella of AI, but not all AI involves machine learning.\n",
            "\n",
            "Machine Learning (ML), on the other hand, is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed [Source 1]. It uses algorithms to build mathematical models based on training data to make predictions or decisions. In essence, ML is a key component of modern AI, but it's not the only aspect of AI.\n",
            "\n",
            "To illustrate this relationship, consider this hierarchy:\n",
            "AI (broader field) ‚Üí Machine Learning (subset of AI)\n",
            "\n",
            "In summary, AI is a more comprehensive term that includes machine learning as one of its subfields.\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚è±Ô∏è  Response time: 11.30s\n",
            "üìù Response length: 1018 characters\n",
            "\n",
            "Test 2/5: How do neural networks work?\n",
            "ü§î Query: How do neural networks work?\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 52ms)\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Neural networks are a fundamental concept in deep learning and machine learning (Source 1). They work by mimicking the structure of the human brain, with multiple layers that process and transmit information (Source 1).\n",
            "\n",
            "At their core, neural networks consist of artificial neurons, also known as nodes or units, which receive inputs from previous layers, perform computations on these inputs, and then send outputs to subsequent layers (Source 3). This layer-by-layer processing allows the network to learn complex patterns in data.\n",
            "\n",
            "In deep learning specifically, neural networks have multiple hidden layers that enable them to analyze and understand intricate relationships between data points (Source 1).\n",
            "\n",
            "It's worth noting that while the context provides a general understanding of neural networks, it doesn't delve into the specifics of how they are trained or optimized. For more detailed information on these topics, external sources would be necessary.\n",
            "\n",
            "Sources:\n",
            "- Source 1: Deep Learning is a specialized subset of machine learning that uses artificial neural networks with multiple layers (hence 'deep') to model and understand complex patterns in data.\n",
            "- Source 3: Machine Learning (ML) is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. ML algorithms build mathematical models based on training data to make predictions or decisions. Common types include supervised learning, unsupervised learning, and reinforcement learning.\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚è±Ô∏è  Response time: 14.88s\n",
            "üìù Response length: 1503 characters\n",
            "\n",
            "Test 3/5: What are the applications of natural language processing?\n",
            "ü§î Query: What are the applications of natural language processing?\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 53ms)\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Based on the provided context, the applications of Natural Language Processing (NLP) include:\n",
            "\n",
            "* Chatbots [Source 1]\n",
            "* Translation\n",
            "* Sentiment analysis [Source 1]\n",
            "* Text summarization [Source 1]\n",
            "\n",
            "It's worth noting that while the context mentions other tasks like image recognition and speech recognition as being relevant to deep learning, it does not explicitly mention them as applications of NLP. If you would like more information on these tasks or how they relate to NLP, I can try to provide additional guidance.\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚è±Ô∏è  Response time: 7.45s\n",
            "üìù Response length: 518 characters\n",
            "\n",
            "Test 4/5: Why is Python good for data science?\n",
            "ü§î Query: Why is Python good for data science?\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 53ms)\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Python is well-suited for data science due to its simplicity and readability (Source 1). Additionally, Python's extensive libraries like NumPy, Pandas, Scikit-learn, TensorFlow, and PyTorch make it ideal for tasks in AI and machine learning, including deep learning (Source 1, Source 3). These libraries enable rapid prototyping and development, which is particularly valuable in data science.\n",
            "\n",
            "Note: The provided context does not explicitly state why Python is good for data science, but based on the information about its suitability for AI and machine learning tasks, we can infer that it's a suitable choice for data science as well.\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚è±Ô∏è  Response time: 8.50s\n",
            "üìù Response length: 637 characters\n",
            "\n",
            "Test 5/5: Explain transformers in deep learning\n",
            "ü§î Query: Explain transformers in deep learning\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîç Retrieving relevant context...\n",
            "üîç Found 3 relevant documents (took 53ms)\n",
            "ü§ñ Generating response...\n",
            "\n",
            "üí° Response:\n",
            "Transformers are a type of neural network architecture that has been particularly influential in natural language processing (Source 1). They use self-attention mechanisms to process sequences of data, making them well-suited for tasks like language modeling and text generation.\n",
            "\n",
            "In the context of deep learning, transformers can be seen as one of the key components or architectures used within it. As Source 2 mentions, deep learning is a subset of machine learning that utilizes artificial neural networks with multiple layers to model complex patterns in data (Source 2).\n",
            "\n",
            "Given this, we can conclude that transformers are indeed part of deep learning, specifically a type of neural network architecture used in natural language processing and other sequence-based tasks.\n",
            "\n",
            "Note: Sources 1 and 3 were not directly relevant in answering the question about transformers in the context of deep learning.\n",
            "\n",
            "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
            "‚è±Ô∏è  Response time: 9.80s\n",
            "üìù Response length: 904 characters\n",
            "\n",
            "üìä Performance Summary:\n",
            "  - Total queries: 5\n",
            "  - Total time: 51.93s\n",
            "  - Average time per query: 10.39s\n",
            "  - Average response length: 916 characters\n"
          ]
        }
      ],
      "source": [
        "# Function to evaluate RAG system performance on test queries\n",
        "import time\n",
        "\n",
        "def evaluate_rag_performance(test_queries: List[str]):\n",
        "    \"\"\"Evaluate the RAG system's performance on a list of test queries.\n",
        "    Prints response time and length for each query, and returns summary statistics.\"\"\"\n",
        "    print(\"üî¨ Evaluating RAG System Performance\")\n",
        "    print(\"‚ïê\" * 50)\n",
        "    \n",
        "    total_time = 0\n",
        "    results = []\n",
        "    \n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        print(f\"\\nTest {i}/{len(test_queries)}: {query}\")\n",
        "        \n",
        "        start_time = time.time()\n",
        "        result = rag_system.query(query, show_context=False)\n",
        "        end_time = time.time()\n",
        "        \n",
        "        query_time = end_time - start_time\n",
        "        total_time += query_time\n",
        "        \n",
        "        results.append({\n",
        "            'query': query,\n",
        "            'time': query_time,\n",
        "            'response_length': len(result['response'])\n",
        "        })\n",
        "        \n",
        "        print(f\"‚è±Ô∏è  Response time: {query_time:.2f}s\")\n",
        "        print(f\"üìù Response length: {len(result['response'])} characters\")\n",
        "    \n",
        "    # Summary statistics\n",
        "    avg_time = total_time / len(test_queries)\n",
        "    avg_length = sum(r['response_length'] for r in results) / len(results)\n",
        "    \n",
        "    print(\"\\nüìä Performance Summary:\")\n",
        "    print(f\"  - Total queries: {len(test_queries)}\")\n",
        "    print(f\"  - Total time: {total_time:.2f}s\")\n",
        "    print(f\"  - Average time per query: {avg_time:.2f}s\")\n",
        "    print(f\"  - Average response length: {avg_length:.0f} characters\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test queries for evaluation\n",
        "test_queries = [\n",
        "    \"What is the difference between AI and machine learning?\",\n",
        "    \"How do neural networks work?\",\n",
        "    \"What are the applications of natural language processing?\",\n",
        "    \"Why is Python good for data science?\",\n",
        "    \"Explain transformers in deep learning\"\n",
        "    ]\n",
        "\n",
        "# Run performance evaluation\n",
        "performance_results = evaluate_rag_performance(test_queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup and Resource Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è  This will delete all indexes and vectors. Set confirm=True to proceed.\n"
          ]
        }
      ],
      "source": [
        "# Function to clean up vector database resources (indexes and vectors)\n",
        "def cleanup_resources(confirm: bool = False):\n",
        "    \"\"\"Clean up all vector database resources (indexes and vectors).\n",
        "    Set confirm=True to actually delete resources. Prints what would be deleted otherwise.\"\"\"\n",
        "    if not confirm:\n",
        "        print(\"‚ö†Ô∏è  This will delete all indexes and vectors. Set confirm=True to proceed.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üßπ Cleaning up resources...\")\n",
        "    \n",
        "    # List and optionally delete indexes\n",
        "    indexes = vector_db.list_indexes()\n",
        "    for index in indexes:\n",
        "        print(f\"üóëÔ∏è  Would delete index: {index['name']} ({index['id']})\")\n",
        "        # Uncomment to actually delete:\n",
        "        # vector_db.delete_index(index['id'])\n",
        "    \n",
        "    print(\"‚úÖ Cleanup complete\")\n",
        "\n",
        "# Show what would be cleaned up (don't actually delete)\n",
        "cleanup_resources(confirm=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "**Congratulations!** You have successfully built a complete RAG system using GravixLayer!\n",
        "\n",
        "### What you've accomplished:\n",
        "\n",
        "1. **Set up the environment** with GravixLayer APIs\n",
        "2. **Created a vector database** for semantic search\n",
        "3. **Ingested documents** with automatic text embedding\n",
        "4. **Implemented retrieval** using semantic similarity search\n",
        "5. **Built generation** using the LLM with retrieved context\n",
        "6. **Created a complete RAG pipeline** that combines both components\n",
        "7. **Added advanced features** like filtering and performance evaluation\n",
        "\n",
        "### Key Features of this RAG System:\n",
        "\n",
        "- **Semantic Search**: Uses embedding models to find contextually relevant documents\n",
        "- **Flexible Filtering**: Supports metadata-based filtering for precise retrieval\n",
        "- **Scalable Architecture**: Built on GravixLayer's vector database infrastructure\n",
        "- **Easy Extension**: Simple methods to add new documents to the knowledge base\n",
        "- **Performance Monitoring**: Built-in evaluation and timing capabilities\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Expand the knowledge base** with your own documents\n",
        "2. **Experiment with different embedding models** and dimensions\n",
        "3. **Tune the retrieval parameters** (top_k, similarity thresholds)\n",
        "4. **Add more sophisticated filtering** based on your use case\n",
        "5. **Implement conversation memory** for multi-turn interactions\n",
        "6. **Add document preprocessing** for better text chunking\n",
        "\n",
        "### Resources:\n",
        "\n",
        "- [Gravix Layer Documentation](https://docs.gravixlayer.com)\n",
        "- [Vector Database Best Practices](https://docs.gravixlayer.com/docs/vector)\n",
        "\n",
        "Happy building! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gravix_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
