{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Agentic RAG: Detailed Guide\n",
        "\n",
        "This notebook provides a compact, production-minded example of a Agentic Retrieval-Augmented Generation (RAG) pipeline focused on PDF documents. It follows a clear three-agent separation:\n",
        "- IngestionAgent: Extracts text from PDFs, creates overlapping chunks, and stores both the raw chunks in a local `knowledge_base` and their embeddings in a vector index.\n",
        "- RetrievalAgent: Performs semantic search against the vector index and assembles human-readable context from the best hits (with a robust fallback to the local `knowledge_base`).\n",
        "- GenerationAgent: Builds a prompt from the retrieved context and calls an LLM to produce concise, sourced answers.\n",
        "\n",
        "Quick Start\n",
        "1. Set `GRAVIXLAYER_API_KEY` in your environment or a `.env` file (the notebook loads `.env`).\n",
        "2. Update `PDF_PATH` to point to your PDF file or run the sample-data branch in the same cell to populate the demo data.\n",
        "3. Run the cells top-to-bottom: configuration â†’ vector DB init â†’ ingestion (or sample load) â†’ query examples.\n",
        "4. Ask questions with `pdf_rag_system.query('Your question here')` â€” set `show_context=True` to see retrieved snippets.\n",
        "\n",
        "Whatâ€™s included\n",
        "- `VectorDatabase`: Minimal wrapper for GravixLayer vector index operations (create/list/find, upsert, text search).\n",
        "- `PDFIngestionAgent`: PDF extraction, sentence-aware chunking with overlap, and preparation of payloads for the vector DB and local `knowledge_base`.\n",
        "- `RetrievalAgent`: Runs text search and assembles readable context; falls back to local `knowledge_base` if the vector search is unavailable or returns limited metadata.\n",
        "- `GenerationAgent`: Simple LLM prompt wrapper that calls `client.chat.completions.create` and returns a concise answer with source citations when possible.\n",
        "\n",
        "![PDF RAG Flowchart](images/Agentic_Rag_Flowchart.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install gravixlayer requests python-dotenv PyPDF2 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GravixLayer client initialized successfully\n",
            "Configuration:\n",
            "  embedding_model: baai/bge-large-en-v1.5\n",
            "  llm_model: meta-llama/llama-3.1-8b-instruct\n",
            "  vector_dimension: 1024\n",
            "  similarity_metric: cosine\n",
            "  index_name: pdf-rag\n",
            "  top_k_results: 3\n",
            "  base_url: https://api.gravixlayer.com/v1/vectors\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import requests\n",
        "import PyPDF2\n",
        "from typing import List, Dict, Any, Optional\n",
        "from gravixlayer import GravixLayer\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Set up API key\n",
        "API_KEY = os.getenv('GRAVIXLAYER_API_KEY')\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"Please set GRAVIXLAYER_API_KEY environment variable\")\n",
        "\n",
        "# Initialize GravixLayer client\n",
        "client = GravixLayer()\n",
        "print(\"GravixLayer client initialized successfully\")\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    'embedding_model': 'baai/bge-large-en-v1.5',\n",
        "    'llm_model': 'meta-llama/llama-3.1-8b-instruct',\n",
        "    'vector_dimension': 1024,\n",
        "    'similarity_metric': 'cosine',\n",
        "    'index_name': 'pdf-rag',\n",
        "    'top_k_results': 3,\n",
        "    'base_url': 'https://api.gravixlayer.com/v1/vectors'\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector database client initialized\n"
          ]
        }
      ],
      "source": [
        "# VectorDatabase class - corrected implementation\n",
        "class VectorDatabase:\n",
        "    def __init__(self, api_key: str, base_url: str):\n",
        "        \"\"\"Initialize the VectorDatabase client with API key and base URL.\"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.headers = {\n",
        "            'Authorization': f'Bearer {api_key}',\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "        self.index_id = None\n",
        "\n",
        "    def create_index(self, name: str, dimension: int, metric: str) -> Optional[str]:\n",
        "        \"\"\"Create a vector index and return its ID if successful.\"\"\"\n",
        "        url = f\"{self.base_url}/indexes\"\n",
        "        payload = {\"name\": name, \"dimension\": dimension, \"metric\": metric, \"vector_type\": \"dense\"}\n",
        "        resp = requests.post(url, headers=self.headers, json=payload)\n",
        "        if resp.status_code in (200, 201):\n",
        "            data = resp.json()\n",
        "            idx = data.get('id') or data.get('index_id')\n",
        "            self.index_id = idx\n",
        "            print(f\"Index created: {idx}\")\n",
        "            return idx\n",
        "        else:\n",
        "            print(f\"Error creating index ({resp.status_code}): {resp.text}\")\n",
        "            return None\n",
        "\n",
        "    def list_indexes(self) -> list:\n",
        "        \"\"\"Return list of indexes (may be empty).\"\"\"\n",
        "        url = f\"{self.base_url}/indexes\"\n",
        "        resp = requests.get(url, headers=self.headers)\n",
        "        if resp.status_code == 200:\n",
        "            return resp.json().get('indexes', [])\n",
        "        return []\n",
        "\n",
        "    def find_or_create_index(self, name: str, dimension: int, metric: str) -> Optional[str]:\n",
        "        \"\"\"Return existing index id by name or create a new one.\"\"\"\n",
        "        indexes = self.list_indexes()\n",
        "        for idx in indexes:\n",
        "            if idx.get('name') == name:\n",
        "                self.index_id = idx.get('id')\n",
        "                print(f\"Using existing index: {self.index_id}\")\n",
        "                return self.index_id\n",
        "        return self.create_index(name, dimension, metric)\n",
        "\n",
        "    def upsert_text_vectors(self, texts_with_metadata: List[Dict]) -> bool:\n",
        "        \"\"\"Upsert text vectors into the index. If a 400 occurs persist payload for inspection.\"\"\"\n",
        "        if not self.index_id:\n",
        "            print(\"No index selected\")\n",
        "            return False\n",
        "        url = f\"{self.base_url}/{self.index_id}/text/upsert\"\n",
        "        payload = {\"vectors\": texts_with_metadata}\n",
        "        resp = requests.post(url, headers=self.headers, json=payload)\n",
        "        if resp.status_code in (200, 201):\n",
        "            data = resp.json()\n",
        "            print(f\"Upsert successful: {data.get('upserted_count', 'unknown')} vectors\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Upsert failed ({resp.status_code}): {resp.text}\")\n",
        "            if resp.status_code == 400:\n",
        "                # Save payload for offline inspection\n",
        "                try:\n",
        "                    dump_path = os.path.join(os.getcwd(), 'failed_upsert_payload.json')\n",
        "                    with open(dump_path, 'w') as f:\n",
        "                        json.dump({'url': url, 'payload': payload, 'response': resp.text}, f, indent=2)\n",
        "                    print(f\"Saved failing payload to: {dump_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to save payload: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def search_text(self, query: str, model: str, top_k: int = 3, filter_dict: Dict = None) -> List[Dict]:\n",
        "        \"\"\"Search the index using a text query and return hits.\"\"\"\n",
        "        if not self.index_id:\n",
        "            print(\"No index selected\")\n",
        "            return []\n",
        "        url = f\"{self.base_url}/{self.index_id}/search/text\"\n",
        "        payload = {\"query\": query, \"model\": model, \"top_k\": top_k, \"include_metadata\": True, \"include_values\": False}\n",
        "        if filter_dict:\n",
        "            payload['filter'] = filter_dict\n",
        "        resp = requests.post(url, headers=self.headers, json=payload)\n",
        "        if resp.status_code == 200:\n",
        "            data = resp.json()\n",
        "            hits = data.get('hits', [])\n",
        "            print(f\"Found {len(hits)} relevant documents (took {data.get('query_time_ms', 'N/A')}ms)\")\n",
        "            return hits\n",
        "        else:\n",
        "            print(f\"Error searching ({resp.status_code}): {resp.text}\")\n",
        "            return []\n",
        "\n",
        "# Initialize vector database\n",
        "vector_db = VectorDatabase(API_KEY, CONFIG['base_url'])\n",
        "print(\"Vector database client initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Knowledge Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Knowledge base initialized\n"
          ]
        }
      ],
      "source": [
        "# Global knowledge base\n",
        "knowledge_base = []  # This will store PDF chunks for retrieval\n",
        "\n",
        "print(\"Knowledge base initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. PDF Processing Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDF Ingestion Agent ready\n"
          ]
        }
      ],
      "source": [
        "# PDF Ingestion Agent\n",
        "class PDFIngestionAgent:\n",
        "    def __init__(self, vector_db: VectorDatabase, config: Dict):\n",
        "        self.vector_db = vector_db\n",
        "        self.config = config\n",
        "        \n",
        "    def ingest_pdf(self, pdf_path: str, custom_name: Optional[str] = None) -> bool:\n",
        "        \"\"\"Ingest PDF and add to both vector DB and knowledge base\"\"\"\n",
        "        global knowledge_base  # Use the global knowledge_base like your working RAG\n",
        "        \n",
        "        if not os.path.exists(pdf_path):\n",
        "            print(f\"PDF file not found: {pdf_path}\")\n",
        "            return False\n",
        "        \n",
        "        if not pdf_path.lower().endswith('.pdf'):\n",
        "            print(f\"File is not a PDF: {pdf_path}\")\n",
        "            return False\n",
        "        \n",
        "        source_name = custom_name or os.path.basename(pdf_path)\n",
        "        display(Markdown(f\"### Ingesting PDF: `{source_name}`\"))\n",
        "        \n",
        "        try:\n",
        "            # Extract text from PDF\n",
        "            print(\"Extracting text from PDF...\")\n",
        "            text = self._extract_pdf_text(pdf_path)\n",
        "            \n",
        "            if not text:\n",
        "                print(\"No text extracted from PDF\")\n",
        "                return False\n",
        "            \n",
        "            print(f\"Extracted {len(text)} characters\")\n",
        "            \n",
        "            # Create chunks\n",
        "            print(\"Creating text chunks...\")\n",
        "            chunks = self._create_chunks(text)\n",
        "            \n",
        "            if not chunks:\n",
        "                print(\"No valid chunks created\")\n",
        "                return False\n",
        "            \n",
        "            print(f\"Created {len(chunks)} chunks\")\n",
        "            \n",
        "            # Prepare for vector database\n",
        "            vectors_for_db = []\n",
        "            new_knowledge_entries = []\n",
        "            \n",
        "            for i, chunk in enumerate(chunks):\n",
        "                chunk_id = f\"{source_name}-chunk-{i}\"\n",
        "                \n",
        "                # For vector database\n",
        "                vector_entry = {\n",
        "                    \"id\": chunk_id,\n",
        "                    \"text\": chunk,\n",
        "                    \"model\": self.config['embedding_model'],\n",
        "                    \"metadata\": {\n",
        "                        \"source\": source_name,\n",
        "                        \"chunk_number\": i,\n",
        "                        \"document_type\": \"pdf\"\n",
        "                    }\n",
        "                }\n",
        "                vectors_for_db.append(vector_entry)\n",
        "                \n",
        "                # For knowledge base\n",
        "                knowledge_entry = {\n",
        "                    \"id\": chunk_id,\n",
        "                    \"text\": chunk,\n",
        "                    \"model\": self.config['embedding_model'],\n",
        "                    \"metadata\": {\n",
        "                        \"source\": source_name,\n",
        "                        \"chunk_number\": i,\n",
        "                        \"document_type\": \"pdf\"\n",
        "                    }\n",
        "                }\n",
        "                new_knowledge_entries.append(knowledge_entry)\n",
        "            \n",
        "            # Store in vector database\n",
        "            print(\"Storing in vector database...\")\n",
        "            success = self.vector_db.upsert_text_vectors(vectors_for_db)\n",
        "            \n",
        "            if success:\n",
        "                # Add to knowledge base\n",
        "                knowledge_base.extend(new_knowledge_entries)\n",
        "                print(f\"Added {len(new_knowledge_entries)} chunks to knowledge base\")\n",
        "                print(f\"Total knowledge base size: {len(knowledge_base)} documents\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"Failed to store in vector database\")\n",
        "                return False\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing PDF: {str(e)}\")\n",
        "            return False\n",
        "    \n",
        "    def _extract_pdf_text(self, pdf_path: str) -> str:\n",
        "        \"\"\"Extract text from PDF file\"\"\"\n",
        "        text = \"\"\n",
        "        \n",
        "        try:\n",
        "            with open(pdf_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                total_pages = len(pdf_reader.pages)\n",
        "                print(f\"PDF has {total_pages} pages\")\n",
        "                \n",
        "                for i, page in enumerate(pdf_reader.pages, 1):\n",
        "                    try:\n",
        "                        page_text = page.extract_text()\n",
        "                        if page_text.strip():\n",
        "                            cleaned_text = re.sub(r'\\s+', ' ', page_text.strip())\n",
        "                            text += cleaned_text + \" \"\n",
        "                            print(f\"  Page {i}: {len(cleaned_text)} characters\")\n",
        "                        else:\n",
        "                            print(f\"  Page {i}: No readable text\")\n",
        "                    except Exception as page_error:\n",
        "                        print(f\"  Error on page {i}: {str(page_error)}\")\n",
        "                        continue\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Error reading PDF: {str(e)}\")\n",
        "            return \"\"\n",
        "        \n",
        "        return text.strip()\n",
        "    \n",
        "    def _create_chunks(self, text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:\n",
        "        \"\"\"Create text chunks with overlap\"\"\"\n",
        "        if len(text) < 50:\n",
        "            return [text] if text.strip() else []\n",
        "        \n",
        "        # Split by sentences\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "        \n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "        \n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if not sentence:\n",
        "                continue\n",
        "            \n",
        "            if len(current_chunk) + len(sentence) + 1 > chunk_size and current_chunk:\n",
        "                if len(current_chunk) >= 50:\n",
        "                    chunks.append(current_chunk.strip())\n",
        "                \n",
        "                # Create overlap\n",
        "                words = current_chunk.split()\n",
        "                overlap_words = words[-overlap//10:] if len(words) > overlap//10 else []\n",
        "                current_chunk = \" \".join(overlap_words) + \" \" + sentence if overlap_words else sentence\n",
        "            else:\n",
        "                current_chunk += (\" \" + sentence) if current_chunk else sentence\n",
        "        \n",
        "        # Add final chunk\n",
        "        if current_chunk.strip() and len(current_chunk) >= 50:\n",
        "            chunks.append(current_chunk.strip())\n",
        "        \n",
        "        return [chunk for chunk in chunks if len(chunk) >= 50 and len(chunk.split()) >= 5]\n",
        "\n",
        "print(\"PDF Ingestion Agent ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RetrievalAgent and GenerationAgent defined\n"
          ]
        }
      ],
      "source": [
        "# RetrievalAgent and GenerationAgent for 3-agent RAG pattern\n",
        "class RetrievalAgent:\n",
        "    def __init__(self, vector_db, knowledge_base, config):\n",
        "        self.vector_db = vector_db\n",
        "        self.knowledge_base = knowledge_base\n",
        "        self.config = config\n",
        "\n",
        "    def retrieve(self, query: str, top_k: int = None, filter_dict: dict = None):\n",
        "        \"\"\"Run vector search and assemble a context string from hits.\n",
        "\n",
        "        Returns a tuple: (hits, context_str)\n",
        "        \"\"\"\n",
        "        if top_k is None:\n",
        "            top_k = self.config.get('top_k_results', 3)\n",
        "\n",
        "        hits = self.vector_db.search_text(\n",
        "            query=query,\n",
        "            model=self.config['embedding_model'],\n",
        "            top_k=top_k,\n",
        "            filter_dict=filter_dict,\n",
        "        )\n",
        "\n",
        "        context_parts = []\n",
        "        for i, hit in enumerate(hits, 1):\n",
        "            metadata = hit.get('metadata', {}) or {}\n",
        "            # Try to find the full text in the local knowledge base\n",
        "            doc_text = None\n",
        "            for doc in self.knowledge_base:\n",
        "                if doc.get('id') == hit.get('id'):\n",
        "                    doc_text = doc.get('text')\n",
        "                    break\n",
        "\n",
        "            # Fall back to any text in metadata\n",
        "            if not doc_text:\n",
        "                doc_text = metadata.get('text') or metadata.get('snippet') or ''\n",
        "\n",
        "            if doc_text:\n",
        "                source = metadata.get('source', 'unknown')\n",
        "                chunk_num = metadata.get('chunk_number', 'unknown')\n",
        "                context_parts.append(\n",
        "                    f\"Source {i} (Score: {hit.get('score', 0):.3f}, File: {source}, Chunk: {chunk_num}):\\n{doc_text}\"\n",
        "                )\n",
        "\n",
        "        context = \"\\n\\n\".join(context_parts)\n",
        "        return hits, context\n",
        "\n",
        "\n",
        "class GenerationAgent:\n",
        "    def __init__(self, llm_client, config: dict):\n",
        "        self.llm_client = llm_client\n",
        "        self.config = config\n",
        "\n",
        "    def generate(self, query: str, context: str) -> str:\n",
        "        \"\"\"Generate an answer using the LLM client and provided context.\"\"\"\n",
        "        prompt = f\"\"\"You are a helpful AI assistant. Use the provided context to answer the user's question accurately and comprehensively.\n",
        "\n",
        "Context:\\n{context}\\n\\nUser Question: {query}\\n\\nInstructions:\\n1. Base your answer primarily on the provided context\\n2. If the context doesn't contain enough information, say so clearly\\n3. Be concise but thorough\\n4. Cite which sources you're using when relevant\\n\\nAnswer:\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.llm_client.chat.completions.create(\n",
        "                model=self.config['llm_model'],\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=500,\n",
        "                temperature=0.0,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "print(\"âœ… RetrievalAgent and GenerationAgent defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… PDF RAG System refactored to 3-agent pattern\n"
          ]
        }
      ],
      "source": [
        "# PDF RAG System - orchestrates Ingestion, Retrieval, and Generation agents\n",
        "class PDFRAGSystem:\n",
        "    def __init__(self, ingestion_agent: PDFIngestionAgent, retrieval_agent: RetrievalAgent, generation_agent: GenerationAgent, config: Dict):\n",
        "        \"\"\"Initialize the PDF RAG system using three agents.\"\"\"\n",
        "        self.ingestion_agent = ingestion_agent\n",
        "        self.retrieval_agent = retrieval_agent\n",
        "        self.generation_agent = generation_agent\n",
        "        self.config = config\n",
        "\n",
        "    def retrieve_context(self, query: str, top_k: int = None, filter_dict: dict = None) -> str:\n",
        "        \"\"\"Delegate retrieval to the RetrievalAgent and return context string.\"\"\"\n",
        "        _, context = self.retrieval_agent.retrieve(query=query, top_k=top_k, filter_dict=filter_dict)\n",
        "        return context\n",
        "\n",
        "    def generate_response(self, query: str, context: str) -> str:\n",
        "        \"\"\"Delegate generation to the GenerationAgent.\"\"\"\n",
        "        return self.generation_agent.generate(query=query, context=context)\n",
        "\n",
        "    def query(self, question: str, show_context: bool = True, top_k: int = None, filter_dict: dict = None) -> Dict[str, Any]:\n",
        "        \"\"\"High-level method: retrieve context then generate an answer.\"\"\"\n",
        "        display(Markdown(f\"### ğŸ¤” Query: {question}\"))\n",
        "        print(\"â”€\" * 80)\n",
        "\n",
        "        print(\"ğŸ” Retrieving relevant context...\")\n",
        "        context = self.retrieve_context(question, top_k=top_k, filter_dict=filter_dict)\n",
        "\n",
        "        if show_context:\n",
        "            display(Markdown(\"#### ğŸ“„ Retrieved Context:\"))\n",
        "            print(context)\n",
        "            print(\"â”€\" * 80)\n",
        "\n",
        "        print(\"ğŸ¤– Generating response...\")\n",
        "        response = self.generate_response(question, context)\n",
        "\n",
        "        display(Markdown(\"### ğŸ’¡ Response:\"))\n",
        "        print(response)\n",
        "        print(\"â•\" * 80)\n",
        "\n",
        "        return {\n",
        "            'query': question,\n",
        "            'context': context,\n",
        "            'response': response\n",
        "        }\n",
        "\n",
        "print(\"âœ… PDF RAG System refactored to 3-agent pattern\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. System Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index created: 1390b66f-6cc2-46ec-8d40-8953412091dc\n",
            "ğŸ“Š Vector index ready: 1390b66f-6cc2-46ec-8d40-8953412091dc\n",
            "âœ… PDF RAG System initialized (3-agent pattern)\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "---\n",
              "### ğŸš€ System Ready!"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create or find vector index\n",
        "index_id = vector_db.find_or_create_index(\n",
        "    name=CONFIG['index_name'],\n",
        "    dimension=CONFIG['vector_dimension'],\n",
        "    metric=CONFIG['similarity_metric']\n",
        ")\n",
        "\n",
        "if index_id:\n",
        "    print(f\"ğŸ“Š Vector index ready: {index_id}\")\n",
        "else:\n",
        "    print(\"âŒ Failed to create/find vector index\")\n",
        "\n",
        "# Initialize agents\n",
        "pdf_ingestion = PDFIngestionAgent(vector_db, CONFIG)\n",
        "retrieval_agent = RetrievalAgent(vector_db, knowledge_base, CONFIG)\n",
        "# GenerationAgent expects the GravixLayer client; use `client` defined earlier\n",
        "generation_agent = GenerationAgent(client, CONFIG)\n",
        "\n",
        "# Create the 3-agent RAG system\n",
        "pdf_rag_system = PDFRAGSystem(pdf_ingestion, retrieval_agent, generation_agent, CONFIG)\n",
        "\n",
        "print(\"âœ… PDF RAG System initialized (3-agent pattern)\")\n",
        "display(Markdown(\"---\\n### ğŸš€ System Ready!\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. PDF Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¥ Ingesting PDF...\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### Ingesting PDF: `Test.pdf`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting text from PDF...\n",
            "PDF has 44 pages\n",
            "  Page 1: 167 characters\n",
            "  Page 2: 1191 characters\n",
            "  Page 3: 2338 characters\n",
            "  Page 4: 2058 characters\n",
            "  Page 5: 3257 characters\n",
            "  Page 6: 2854 characters\n",
            "  Page 7: 2306 characters\n",
            "  Page 8: 1771 characters\n",
            "  Page 9: 3483 characters\n",
            "  Page 10: 1650 characters\n",
            "  Page 11: 3067 characters\n",
            "  Page 12: 2263 characters\n",
            "  Page 13: 3034 characters\n",
            "  Page 14: 2539 characters\n",
            "  Page 15: 2514 characters\n",
            "  Page 16: 3259 characters\n",
            "  Page 17: 2135 characters\n",
            "  Page 18: 2648 characters\n",
            "  Page 19: 2761 characters\n",
            "  Page 20: 2029 characters\n",
            "  Page 21: 995 characters\n",
            "  Page 22: 3336 characters\n",
            "  Page 23: 1780 characters\n",
            "  Page 24: 2540 characters\n",
            "  Page 25: 1932 characters\n",
            "  Page 26: 2319 characters\n",
            "  Page 27: 2101 characters\n",
            "  Page 28: 2969 characters\n",
            "  Page 29: 1152 characters\n",
            "  Page 30: 113 characters\n",
            "  Page 31: 3647 characters\n",
            "  Page 32: 1087 characters\n",
            "  Page 33: 4096 characters\n",
            "  Page 34: 1887 characters\n",
            "  Page 35: 2455 characters\n",
            "  Page 36: 2814 characters\n",
            "  Page 37: 3092 characters\n",
            "  Page 38: 1182 characters\n",
            "  Page 39: 3023 characters\n",
            "  Page 40: 287 characters\n",
            "  Page 41: 1190 characters\n",
            "  Page 42: 3927 characters\n",
            "  Page 43: 1375 characters\n",
            "  Page 44: 1347 characters\n",
            "Extracted 98013 characters\n",
            "Creating text chunks...\n",
            "Created 155 chunks\n",
            "Storing in vector database...\n",
            "  Page 31: 3647 characters\n",
            "  Page 32: 1087 characters\n",
            "  Page 33: 4096 characters\n",
            "  Page 34: 1887 characters\n",
            "  Page 35: 2455 characters\n",
            "  Page 36: 2814 characters\n",
            "  Page 37: 3092 characters\n",
            "  Page 38: 1182 characters\n",
            "  Page 39: 3023 characters\n",
            "  Page 40: 287 characters\n",
            "  Page 41: 1190 characters\n",
            "  Page 42: 3927 characters\n",
            "  Page 43: 1375 characters\n",
            "  Page 44: 1347 characters\n",
            "Extracted 98013 characters\n",
            "Creating text chunks...\n",
            "Created 155 chunks\n",
            "Storing in vector database...\n",
            "Upsert successful: 155 vectors\n",
            "Added 155 chunks to knowledge base\n",
            "Total knowledge base size: 155 documents\n",
            "\n",
            "ğŸ‰ PDF ingested successfully!\n",
            "ğŸ“š Knowledge base now has 155 documents\n",
            "Upsert successful: 155 vectors\n",
            "Added 155 chunks to knowledge base\n",
            "Total knowledge base size: 155 documents\n",
            "\n",
            "ğŸ‰ PDF ingested successfully!\n",
            "ğŸ“š Knowledge base now has 155 documents\n"
          ]
        }
      ],
      "source": [
        "# PDF Ingestion\n",
        "PDF_PATH = \"/Users/rupinajay/Downloads/Test.pdf\"  # ğŸ“ UPDATE THIS PATH\n",
        "\n",
        "if os.path.exists(PDF_PATH):\n",
        "    print(\"ğŸ“¥ Ingesting PDF...\")\n",
        "    success = pdf_ingestion.ingest_pdf(PDF_PATH)\n",
        "    \n",
        "    if success:\n",
        "        print(f\"\\nğŸ‰ PDF ingested successfully!\")\n",
        "        print(f\"ğŸ“š Knowledge base now has {len(knowledge_base)} documents\")\n",
        "    else:\n",
        "        print(\"\\nâŒ PDF ingestion failed\")\n",
        "else:\n",
        "    print(f\"âš ï¸ PDF not found: {PDF_PATH}\")\n",
        "    print(\"Creating sample data for testing...\")\n",
        "    \n",
        "    # Create sample data for testing\n",
        "    sample_data = [\n",
        "        {\n",
        "            \"id\": \"sample-pdf-chunk-0\",\n",
        "            \"text\": \"This sample PDF document covers artificial intelligence fundamentals, including machine learning algorithms, neural networks, and deep learning techniques. It explains how AI systems learn from data and make predictions based on patterns in training data.\",\n",
        "            \"model\": CONFIG['embedding_model'],\n",
        "            \"metadata\": {\n",
        "                \"source\": \"sample.pdf\",\n",
        "                \"chunk_number\": 0,\n",
        "                \"document_type\": \"pdf\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"sample-pdf-chunk-1\",\n",
        "            \"text\": \"The document discusses practical AI applications across industries such as healthcare, finance, and transportation. It covers computer vision for image recognition, natural language processing for text analysis, and robotics for automation tasks.\",\n",
        "            \"model\": CONFIG['embedding_model'],\n",
        "            \"metadata\": {\n",
        "                \"source\": \"sample.pdf\",\n",
        "                \"chunk_number\": 1,\n",
        "                \"document_type\": \"pdf\"\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    # Store in vector database\n",
        "    success = vector_db.upsert_text_vectors(sample_data)\n",
        "    \n",
        "    if success:\n",
        "        # Add to knowledge base\n",
        "        knowledge_base.extend(sample_data)\n",
        "        print(f\"Sample data loaded. Knowledge base has {len(knowledge_base)} documents\")\n",
        "    else:\n",
        "        print(\"Failed to load sample data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Query Your PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### ğŸ¤” Query: What is the main topic of the PDF document?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ” Retrieving relevant context...\n",
            "Found 3 relevant documents (took 54ms)\n",
            "Found 3 relevant documents (took 54ms)\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "#### ğŸ“„ Retrieved Context:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source 1 (Score: 0.574, File: Test.pdf, Chunk: 105):\n",
            "conversational way).Add a column including the month they were published. AIReport Title Description Month Published Economic Impact ResearchThis report provides an in -depth analysis of the economic impact of the travel and tourism industry, both globally and in individual countries.\n",
            "\n",
            "Source 2 (Score: 0.570, File: Test.pdf, Chunk: 152):\n",
            "Â© World Travel & Tourism Council: Introduction to AI 2024. All rights reserved. The copyright laws of the United Kingdom allow certain uses of this content without our (i.e. the copyright ownerâ€™s) permission. You are permitted to use limited extracts of this content, provided such use is fair and when such use is for non-commercial research, private study, review or news reporting. The following acknowledgment must also be used, whenever our content is used relying on this â€œfair dealingâ€ exception: â€œSource: World Travel and Tourism Council: Introduction to AI 2024.\n",
            "\n",
            "Source 3 (Score: 0.563, File: Test.pdf, Chunk: 100):\n",
            "in 2022 and include a short description of each report. Report Title Description Economic Impact ResearchThis report provides an in -depth analysis of the economic impact of the travel and tourism industry, both globally and in individual countries. It also provides forecasts for the future of the industry. Digital Travel Portals This report provides guidance on how governments can implement a digital travel portal to facilitate safe and seamless travel. Codes to ResilienceThis report identifies the key factors that will determine the resilience of the travel and tourism industry in the face of future shocks. Destination 2030This report assesses the readiness of global cities to achieve sustainable tourism growth by 2030.\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ¤– Generating response...\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### ğŸ’¡ Response:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, it appears that the main topic of the PDF document is related to the travel and tourism industry, specifically economic impact research and analysis.\n",
            "\n",
            "From Source 1 (Score: 0.574), we can see that the report provides an \"in-depth analysis of the economic impact of the travel and tourism industry\" (Source 1).\n",
            "\n",
            "Similarly, from Source 3 (Score: 0.563) and Source 2 does not mention a main topic but rather provides context for permitted uses of the content, it is clear that the PDF document discusses various topics related to the travel and tourism industry, including economic impact research.\n",
            "\n",
            "Therefore, I can conclude that the main topic of the PDF document is likely \"Travel and Tourism Industry Analysis\" with a focus on economic impact. \n",
            "\n",
            "Sources used:\n",
            "- Source 1: Score: 0.574\n",
            "- Source 2 does not provide information but mentions context for permitted uses.\n",
            "- Source 3\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
          ]
        }
      ],
      "source": [
        "# Test Query 1\n",
        "result1 = pdf_rag_system.query(\"What is the main topic of the PDF document?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### ğŸ¤” Query: What AI applications are mentioned?"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ” Retrieving relevant context...\n",
            "Found 3 relevant documents (took 61ms)\n",
            "Found 3 relevant documents (took 61ms)\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "#### ğŸ“„ Retrieved Context:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source 1 (Score: 0.704, File: Test.pdf, Chunk: 79):\n",
            "to classify an AI system is based on its functionality. For many years this involved an AI solution either being considered as an Expert System, or as Predictive AI, but now also includes a relatively new field of artificial intelligence functionality called Generative AI. An AI Expert System is a smart computer program that uses AI to simulate the expertise of humans in a specific area, such as for travel planning, medical diagnosis or financial advice. Expert systems contain a knowledge base of rules and facts about a specific domain, which are combined with AI (in a system called an â€˜inference engineâ€™) to reason through problems and provide advice, or recommendations. For example a travel AI expert system could help travellers to plan and book their trips.\n",
            "\n",
            "Source 2 (Score: 0.701, File: Test.pdf, Chunk: 52):\n",
            "products, content, or services tailored to an individual user. 6. Natural Language Processing (NLP): NLP models, such as AI powered chatbots, virtual assistants and language translation systems, benefit from diverse and extensive language data, such as books, articles and social media posts. This allows an AI NLP model to understand and generate realistic human-like language very effectively. 7. Real-Time Decision Making: as the â€˜velocityâ€™ of big data accelerates, in areas such as banking transactions, AI systems can process and analyse this data in (near) real time to provide instant recommendations, or decisions, for functions such as fraud detection.\n",
            "\n",
            "Source 3 (Score: 0.698, File: Test.pdf, Chunk: 94):\n",
            "the AI in a process called natural language processing (NLP). This natural, conversational way of providing instructions to an AI system is the same way that instructions are provided to â€˜home smart speakersâ€™ and is a new, exciting and innovative way for humans to interact with computers. INTRODUCTION TO AI World Travel & Tourism Council26 < Contents |A simple example of a text prompt and response from a LLM could be: Sophisticated AI chatbots, powered by LLMâ€™s, are also able to remember the details and context of a conversation and reply as part of a free flowing discussion.\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ¤– Generating response...\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### ğŸ’¡ Response:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Several AI applications are mentioned in the provided context:\n",
            "\n",
            "1. **Expert Systems** (Source 1): These are AI systems that simulate human expertise in specific areas such as travel planning, medical diagnosis, or financial advice.\n",
            "2. **Predictive AI** (Source 1): Although not explicitly described in detail, it is mentioned as a category of AI functionality separate from Expert Systems and Generative AI.\n",
            "3. **Generative AI** (Source 1): A relatively new field that refers to AI functionality where the system can generate novel content or outputs.\n",
            "4. **Natural Language Processing (NLP) models**: These include AI powered chatbots, virtual assistants, and language translation systems that benefit from diverse language data (Source 2).\n",
            "5. **Real-Time Decision Making** (Source 2): This refers to AI systems that can process and analyze big data in real-time to provide instant recommendations or decisions.\n",
            "6. **AI NLP models for understanding and generating human-like language** (Source 2): These allow AI systems to understand and generate realistic human-like language effectively.\n",
            "7. **LLM (Large Language Model) powered AI chatbots**: These are sophisticated chatbots that can remember conversation details and context, and reply as part of a free-flowing discussion (Source 3).\n",
            "\n",
            "Note: There is no information provided on other potential AI applications such as computer vision or robotics.\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
          ]
        }
      ],
      "source": [
        "# Test Query 2\n",
        "result2 = pdf_rag_system.query(\"What AI applications are mentioned?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### ğŸ¤” Query: Summarize the key points from the document"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ” Retrieving relevant context...\n",
            "Found 3 relevant documents (took 54ms)\n",
            "Found 3 relevant documents (took 54ms)\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "#### ğŸ“„ Retrieved Context:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source 1 (Score: 0.550, File: Test.pdf, Chunk: 2):\n",
            "Global Digital Divide & AI Skills Gap 31 QUIZ ....................................................................................................................... 34 ANNEX : AI TERMINOLOGY .......................................................................... 35 QUIZ ANSWER ................................................................................................... 40 ACKNOWLEDGEMENTS ................................................................................. 41 ENDNOTES ..........................................................................................................\n",
            "\n",
            "Source 2 (Score: 0.550, File: Test.pdf, Chunk: 105):\n",
            "conversational way).Add a column including the month they were published. AIReport Title Description Month Published Economic Impact ResearchThis report provides an in -depth analysis of the economic impact of the travel and tourism industry, both globally and in individual countries.\n",
            "\n",
            "Source 3 (Score: 0.545, File: Test.pdf, Chunk: 1):\n",
            "Council2 < Contents | CONTENTS FOREWORD ........................................................................................................... 3 INTRODUCTION .................................................................................................. 4 Brief history of Artificial Intelligence (AI) 4 What is Artificial Intelligence & Why There is Global Interest Now 7 Algorithms : The Brains of AI 8 Data : The Fuel That Drives AI 12 Computing Power : The Machines Behind AI 16 Types of Artificial Intelligence 21 Generative AI 24 Global Digital Divide & AI Skills Gap 31 QUIZ .......................................................................................................................\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ¤– Generating response...\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### ğŸ’¡ Response:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, here's a summary of the key points:\n",
            "\n",
            "The document appears to be related to Artificial Intelligence (AI), but it doesn't provide a clear and comprehensive overview. However, we can extract some information from the snippets.\n",
            "\n",
            "* The document mentions a \"Global Digital Divide & AI Skills Gap\" which suggests that there is a gap in skills related to AI (Source 1) [0].\n",
            "* It also includes a report on the \"Economic Impact of Travel and Tourism Industry\" with details on analysis by countries (Source 2).\n",
            "* Another snippet provides an introduction to Artificial Intelligence, including its history, types, and what drives it (Source 3).\n",
            "\n",
            "Unfortunately, there isn't enough information in the provided context to provide a more detailed or insightful summary. However, based on the snippets, these appear to be key points.\n",
            "\n",
            "Sources used:\n",
            "\n",
            "[0] Source 1: Global Digital Divide & AI Skills Gap\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
          ]
        }
      ],
      "source": [
        "# Test Query 3\n",
        "result3 = pdf_rag_system.query(\"Summarize the key points from the document\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "### ğŸ¤” Query: Explain machine learning concepts in the doc"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ” Retrieving relevant context...\n",
            "Found 3 relevant documents (took 61ms)\n",
            "Found 3 relevant documents (took 61ms)\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "#### ğŸ“„ Retrieved Context:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source 1 (Score: 0.670, File: Test.pdf, Chunk: 33):\n",
            "and to turn a â€˜black boxâ€™ into a â€˜glass boxâ€™). The â€˜digital doctorâ€™ example nicely illustrates why â€˜explainable AIâ€™ is so important (in this case for both the patient and the doctor) to understand why an AI system has made a decision and believes a patient has breast cancer before sending them for intrusive cancer treatment. When considering how an AI system is constructed, there are two primary methods for how an AI system â€˜learnsâ€™ to perform a task, which are machine learning and deep learning. â€¢ Machine Learning : Machine Learning (ML) systems can learn from huge amounts of data and continuously improve their performance over time when provided with more and/or better quality training data.\n",
            "\n",
            "Source 2 (Score: 0.651, File: Test.pdf, Chunk: 131):\n",
            "could do, such as carry guestsâ€™ luggage to their room. Machine LearningMachine learning is a type of AI that involves training algorithms with large amounts of data, so that a computer is capable of making predictions, or decisions.An email spam filter can be an example of an AI system using machine learning. By training an AI algorithm on a dataset of known spam and non-spam emails, it can learn to distinguish between the two and is then able to automatically detect and filter out new spam messages, even though it has never seen them before. Deep LearningDeep learning is a type of advanced machine learning, which uses complex mathematical structures inspired by the human brain called â€˜neural networksâ€™.\n",
            "\n",
            "Source 3 (Score: 0.651, File: Test.pdf, Chunk: 1):\n",
            "Council2 < Contents | CONTENTS FOREWORD ........................................................................................................... 3 INTRODUCTION .................................................................................................. 4 Brief history of Artificial Intelligence (AI) 4 What is Artificial Intelligence & Why There is Global Interest Now 7 Algorithms : The Brains of AI 8 Data : The Fuel That Drives AI 12 Computing Power : The Machines Behind AI 16 Types of Artificial Intelligence 21 Generative AI 24 Global Digital Divide & AI Skills Gap 31 QUIZ .......................................................................................................................\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ğŸ¤– Generating response...\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "### ğŸ’¡ Response:"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "According to the provided context, Machine Learning (ML) is a type of AI that involves training algorithms with large amounts of data, allowing a computer to make predictions or decisions [Source 1 & Source 2]. The key concepts mentioned in the context are:\n",
            "\n",
            "* **Learning from huge amounts of data**: ML systems can improve their performance over time when provided with more and/or better quality training data [Source 1].\n",
            "* **Training algorithms**: Machine Learning involves training algorithms on a dataset, so that they can learn to make predictions or decisions [Source 2].\n",
            "* **Examples of machine learning applications**: Email spam filters [Source 2] are an example of machine learning in action.\n",
            "\n",
            "Note: The provided context does not go into detail about the underlying mechanics or math behind Machine Learning. For more information on this topic, you may need to consult additional sources.\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
          ]
        }
      ],
      "source": [
        "# Test Query 4 - Without showing context\n",
        "result4 = pdf_rag_system.query(\"Explain machine learning concepts in the doc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. System Status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š System Status:\n",
            "  - Vector Database: âœ… Connected\n",
            "  - Knowledge Base Size: 155 documents\n",
            "  - Index ID: 1390b66f-6cc2-46ec-8d40-8953412091dc\n",
            "\n",
            "ğŸ“š Knowledge Base Contents:\n",
            "  1. Test.pdf (Chunk 0): INTRODUCTION TO AI World Travel & Tourism Council< Contents | 1 INTRODUCTION TO ARTIFICIAL INTELLIGE...\n",
            "  2. Test.pdf (Chunk 1): Council2 < Contents | CONTENTS FOREWORD ...............................................................\n",
            "  3. Test.pdf (Chunk 2): Global Digital Divide & AI Skills Gap 31 QUIZ .........................................................\n",
            "  ... and 152 more documents\n"
          ]
        }
      ],
      "source": [
        "# Show system status\n",
        "print(f\"ğŸ“Š System Status:\")\n",
        "print(f\"  - Vector Database: {'âœ… Connected' if vector_db.index_id else 'âŒ Not connected'}\")\n",
        "print(f\"  - Knowledge Base Size: {len(knowledge_base)} documents\")\n",
        "print(f\"  - Index ID: {vector_db.index_id}\")\n",
        "\n",
        "if knowledge_base:\n",
        "    print(f\"\\nğŸ“š Knowledge Base Contents:\")\n",
        "    for i, doc in enumerate(knowledge_base[:3]):  # Show first 3\n",
        "        source = doc['metadata']['source']\n",
        "        chunk_num = doc['metadata']['chunk_number']\n",
        "        text_preview = doc['text'][:100] + '...' if len(doc['text']) > 100 else doc['text']\n",
        "        print(f\"  {i+1}. {source} (Chunk {chunk_num}): {text_preview}\")\n",
        "    \n",
        "    if len(knowledge_base) > 3:\n",
        "        print(f\"  ... and {len(knowledge_base) - 3} more documents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gravix_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
