{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gravix Layer Cookbook: Full Stack AI Data Analyst Workflow\n",
        "This notebook provides a comprehensive guide to building a complete **AI-powered data analysis workflow** using the **Gravix Layer** SDK for both LLM inference and secure code execution. You will learn how to create an intelligent system that generates, executes, and visualizes data analysis code automatically using advanced language models and containerized execution environments.\n",
        "\n",
        "### What is Full Stack AI Data Analysis?\n",
        "Full Stack AI Data Analysis combines the power of large language models with secure code execution to create autonomous data analysis workflows. Instead of manually writing analysis code, the system uses AI to understand your requirements, generate appropriate Python code, execute it safely in a sandbox environment, and return meaningful results with visualizations.\n",
        "\n",
        "### In this notebook, you will learn to:\n",
        "1. **Set up** the Gravix Layer environment with both chat and sandbox capabilities.\n",
        "2. **Configure** intelligent code generation prompts for robust data analysis.\n",
        "3. **Execute** AI-generated Python code in secure, isolated sandbox environments.\n",
        "4. **Process** and display results including charts, plots, and statistical outputs.\n",
        "5. **Handle** errors gracefully with automatic retry and fallback mechanisms.\n",
        "6. **Integrate** multiple data sources and analysis techniques seamlessly.\n",
        "\n",
        "### Key Features:\n",
        "- **Intelligent Code Generation**: LLM-powered Python code creation for complex data analysis tasks\n",
        "- **Secure Execution Environment**: Containerized sandbox execution with full dependency management\n",
        "- **Automatic Visualization**: Generated charts and plots with base64 encoding for display\n",
        "- **Error Handling**: Robust exception handling and debugging capabilities\n",
        "- **Multi-format Output**: Support for various data formats and visualization types\n",
        "\n",
        "### Use Cases:\n",
        "- Automated exploratory data analysis and statistical modeling\n",
        "- Dynamic report generation with custom visualizations\n",
        "- Interactive data science workflows and hypothesis testing\n",
        "- Educational data analysis demonstrations and tutorials\n",
        "- Rapid prototyping of machine learning and statistical models\n",
        "\n",
        "### Disclaimer\n",
        "**This notebook demonstrates AI-powered code generation and execution for educational and development purposes. Always review generated code before production use. The sandbox environment provides isolation, but ensure your data handling complies with security and privacy requirements. Generated code may have limitations in understanding complex domain-specific requirements.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gravixlayer in ./gravix_test/lib/python3.12/site-packages (0.0.43)\n",
            "Requirement already satisfied: IPython in ./gravix_test/lib/python3.12/site-packages (9.5.0)\n",
            "Requirement already satisfied: requests>=2.25.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (2.32.5)\n",
            "Requirement already satisfied: python-dotenv>=0.19.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (1.0.0)\n",
            "Requirement already satisfied: decorator in ./gravix_test/lib/python3.12/site-packages (from IPython) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in ./gravix_test/lib/python3.12/site-packages (from IPython) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./gravix_test/lib/python3.12/site-packages (from IPython) (0.19.2)\n",
            "Requirement already satisfied: matplotlib-inline in ./gravix_test/lib/python3.12/site-packages (from IPython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in ./gravix_test/lib/python3.12/site-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./gravix_test/lib/python3.12/site-packages (from IPython) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./gravix_test/lib/python3.12/site-packages (from IPython) (2.19.2)\n",
            "Requirement already satisfied: stack_data in ./gravix_test/lib/python3.12/site-packages (from IPython) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in ./gravix_test/lib/python3.12/site-packages (from IPython) (5.14.3)\n",
            "Requirement already satisfied: wcwidth in ./gravix_test/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./gravix_test/lib/python3.12/site-packages (from jedi>=0.16->IPython) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./gravix_test/lib/python3.12/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (2025.8.3)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./gravix_test/lib/python3.12/site-packages (from stack_data->IPython) (2.2.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./gravix_test/lib/python3.12/site-packages (from stack_data->IPython) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in ./gravix_test/lib/python3.12/site-packages (from stack_data->IPython) (0.2.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install gravixlayer IPython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Setup and Configuration\n",
        "\n",
        "First, let's import the required libraries and set up our AI-powered data analysis environment.\n",
        "\n",
        "### Required Dependencies:\n",
        "- **GravixLayer**: Both LLM client for code generation and Sandbox for secure execution\n",
        "- **IPython**: Rich display capabilities for charts and visualizations\n",
        "- **Base64**: Image encoding for plot display and transfer\n",
        "\n",
        "### Security Notes:\n",
        "- API keys should be stored securely in environment variables for production\n",
        "- Sandbox execution provides isolation from your local environment\n",
        "- All code execution happens in containerized environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from gravixlayer import GravixLayer, Sandbox\n",
        "from IPython.display import Image, display\n",
        "import base64 # Import for base64 handling\n",
        "\n",
        "os.environ[\"GRAVIXLAYER_API_KEY\"] = GRAVIXLAYER_API_KEY\n",
        "\n",
        "# Choose a powerful model for code generation (supported by GravixLayer)\n",
        "MODEL_NAME = \"qwen/qwen3-4b-instruct-2507\"\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are an expert Python data scientist. Your goal is to generate clean, robust, and working Python code.\n",
        "\n",
        "**TASK CONTEXT**\n",
        "- You will be given a task, typically for data analysis and visualization.\n",
        "- The dataset is located at `/home/user/data.csv`.\n",
        "- Key columns: 'GDP per capita (current US$)', 'Life expectancy at birth, total (years)'.\n",
        "\n",
        "**CORE RULES**\n",
        "1.  **Code Only:** Respond *ONLY* with a single Python code block. Do not add any text before or after the ```python block.\n",
        "2.  **Save Plot:** You MUST save any generated plot to `/home/user/chart.png`.\n",
        "3.  **Critical Output:** After saving, you MUST read the plot file, base64-encode it, and print the *exact* line: `print(f'PLOT_BASE64:<base64_string_here>')`. This is how the system finds your plot.\n",
        "4.  **Robust Code:** Include error handling (`try...except`) and print statements to show progress (e.g., `df.shape`, `df_clean.shape`).\n",
        "\n",
        "**EXAMPLE OF A PERFECT RESPONSE**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import sys\n",
        "import traceback\n",
        "import base64\n",
        "\n",
        "try:\n",
        "    # Load and clean data\n",
        "    df = pd.read_csv('/home/user/data.csv')\n",
        "    print(f\"Original data shape: {df.shape}\")\n",
        "\n",
        "    # Define key columns\n",
        "    gdp_col = 'GDP per capita (current US$)'\n",
        "    life_exp_col = 'Life expectancy at birth, total (years)'\n",
        "    \n",
        "    df_clean = df[[gdp_col, life_exp_col]].dropna()\n",
        "\n",
        "    # Convert to numeric, handling potential errors\n",
        "    df_clean[gdp_col] = pd.to_numeric(df_clean[gdp_col], errors='coerce')\n",
        "    df_clean[life_exp_col] = pd.to_numeric(df_clean[life_exp_col], errors='coerce')\n",
        "    \n",
        "    # Drop rows that failed conversion\n",
        "    df_clean = df_clean.dropna()\n",
        "    print(f\"Clean data shape: {df_clean.shape}\")\n",
        "\n",
        "    if df_clean.empty:\n",
        "        print(\"Error: No data left after cleaning.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Prepare features and target\n",
        "    X = df_clean[gdp_col].values.reshape(-1, 1)\n",
        "    y = df_clean[life_exp_col].values\n",
        "\n",
        "    # Fit linear regression model\n",
        "    model = LinearRegression().fit(X, y)\n",
        "    print(\"Model fitted successfully.\")\n",
        "\n",
        "    # Create scatter plot with regression line\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(X, y, alpha=0.6, color='blue', label='Data points')\n",
        "    \n",
        "    # Create line\n",
        "    X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
        "    plt.plot(X_line, model.predict(X_line), color='red', linewidth=2, label='Regression line')\n",
        "    \n",
        "    plt.xlabel('GDP per capita (current US$)')\n",
        "    plt.ylabel('Life expectancy at birth, total (years)')\n",
        "    plt.title('GDP per capita vs Life Expectancy')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Save the plot\n",
        "    plot_path = '/home/user/chart.png'\n",
        "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"Plot saved to {plot_path}\")\n",
        "\n",
        "    # Read the saved image, encode it, and print the base64 string\n",
        "    with open(plot_path, 'rb') as f:\n",
        "        image_bytes = f.read()\n",
        "        base64_string = base64.b64encode(image_bytes).decode('utf-8')\n",
        "        # This is the most important line:\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🛠️ AI Code Execution Utilities\n",
        "\n",
        "These utility functions handle the complex task of executing AI-generated code in secure sandbox environments. The system manages:\n",
        "- **Secure Execution**: All code runs in isolated containers\n",
        "- **Output Parsing**: Extracting results, plots, and error messages\n",
        "- **Base64 Handling**: Converting generated plots for display\n",
        "- **Error Recovery**: Graceful handling of execution failures\n",
        "\n",
        "### Key Functions:\n",
        "1. **`code_interpret()`**: Execute code in Gravix Layer sandbox with output capture\n",
        "2. **`chat_with_llm()`**: Generate and execute data analysis code using LLM\n",
        "3. **`upload_dataset()`**: Securely transfer data files to sandbox environment\n",
        "4. **Plot extraction helpers**: Parse base64-encoded visualizations from output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def code_interpret(gravix_sandbox, code):\n",
        "    print(\"\\n--- Running Code in Gravix Layer Sandbox ---\")\n",
        "    result = gravix_sandbox.run_code(code)\n",
        "    \n",
        "    # Safely get stdout, stderr, and error\n",
        "    stdout = getattr(result, 'stdout', '')\n",
        "    stderr = getattr(result, 'stderr', '')\n",
        "    error = getattr(result, 'error', None)\n",
        "    \n",
        "    if stdout:\n",
        "        print(\"[Sandbox STDOUT]:\")\n",
        "        print(stdout)\n",
        "    else:\n",
        "        print(\"[Sandbox STDOUT]: (No stdout)\")\n",
        "\n",
        "    if stderr:\n",
        "        print(\"\\n[Sandbox STDERR]:\")\n",
        "        print(stderr)\n",
        "    \n",
        "    if error:\n",
        "        print(\"\\n[Sandbox Execution Error]:\")\n",
        "        print(error)\n",
        "        \n",
        "    print(\"--- End Sandbox Run ---\")\n",
        "    \n",
        "    # Return stdout for parsing, as it contains the print() statements\n",
        "    return stdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    client = GravixLayer()\n",
        "except Exception as e:\n",
        "    print(f\"Failed to initialize GravixLayer client: {e}\")\n",
        "    client = None\n",
        "\n",
        "pattern = re.compile(r\"```python\\n(.*?)\\n```\", re.DOTALL)\n",
        "\n",
        "def match_code_blocks(llm_response):\n",
        "    match = pattern.search(llm_response)\n",
        "    if match:\n",
        "        code = match.group(1)\n",
        "        print(\"Generated code:\")\n",
        "        print(code)\n",
        "        return code\n",
        "    return \"\"\n",
        "\n",
        "def chat_with_llm(gravix_sandbox, user_message):\n",
        "    if not client:\n",
        "        print(\"GravixLayer client is not initialized.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n{'='*50}\\nUser message: {user_message}\\n{'='*50}\")\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "    ]\n",
        "\n",
        "    print(\"Gravix AI is thinking...\")\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL_NAME,\n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    response_message = response.choices[0].message\n",
        "    python_code = match_code_blocks(response_message.content)\n",
        "    \n",
        "    plot_base64 = None\n",
        "    if python_code:\n",
        "        # code_output_string is the full stdout from the sandbox\n",
        "        code_output_string = code_interpret(gravix_sandbox, python_code)\n",
        "        \n",
        "        if code_output_string:\n",
        "            # Search for the plot path within the entire stdout string, line by line\n",
        "            for line in code_output_string.splitlines():\n",
        "                if line and \"PLOT_BASE64:\" in line:\n",
        "                    plot_base64 = line.split(\"PLOT_BASE64:\", 1)[1].strip()\n",
        "                    break # Found it\n",
        "        return plot_base64\n",
        "    else:\n",
        "        print(f\"No Python code found in response: {response_message.content}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upload_dataset(gravix_sandbox):\n",
        "    print(\"Uploading dataset to Gravix Layer sandbox...\")\n",
        "    local_path = \"./data.csv\"\n",
        "    remote_path = \"/home/user/data.csv\"\n",
        "\n",
        "    if not os.path.exists(local_path):\n",
        "        print(f\"Dataset file not found at {local_path}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(local_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        gravix_sandbox.write_file(remote_path, content)\n",
        "        print(\"Uploaded at\", remote_path)\n",
        "        return remote_path\n",
        "    except Exception as error:\n",
        "        print(\"Error during file upload:\", error)\n",
        "        raise error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete AI Data Analysis Workflow\n",
        "\n",
        "Now let's run the complete AI-powered data analysis workflow. This will:\n",
        "\n",
        "1. **Initialize** secure sandbox environment with dependency installation\n",
        "2. **Upload** dataset to the isolated execution environment  \n",
        "3. **Generate** Python code using advanced language models\n",
        "4. **Execute** code safely in containerized sandbox\n",
        "5. **Extract** and display generated visualizations\n",
        "\n",
        "### Expected Output:\n",
        "- **Code Generation**: AI-generated Python code for data analysis\n",
        "- **Execution Logs**: Real-time output from sandbox execution\n",
        "- **Visualization**: Generated chart displayed inline in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading dataset to Gravix Layer sandbox...\n",
            "Uploaded at /home/user/data.csv\n",
            "\n",
            "--- Installing Dependencies in Sandbox via APK ---\n",
            "This may take a few minutes...\n",
            "Running: apk add py3-pandas py3-matplotlib py3-scikit-learn\n",
            "[apk STDOUT]:\n",
            " fetch https://dl-cdn.alpinelinux.org/alpine/v3.19/main/x86_64/APKINDEX.tar.gz\n",
            "fetch https://dl-cdn.alpinelinux.org/alpine/v3.19/community/x86_64/APKINDEX.tar.gz\n",
            "(1/131) Installing py3-cairo-pyc (1.25.1-r0)\n",
            "(2/131) Installing py3-certifi (2024.2.2-r0)\n",
            "(3/131) Installing py3-certifi-pyc (2024.2.2-r0)\n",
            "(4/131) Installing libquadmath (13.2.1_git20231014-r0)\n",
            "(5/131) Installing libgfortran (13.2.1_git20231014-r0)\n",
            "(6/131) Installing openblas (0.3.25-r0)\n",
            "(7/131) Installing py3-numpy (1.25.2-r0)\n",
            "(8/131) Installing py3-numpy-pyc (1.25.2-r0)\n",
            "(9/131) Installing py3-contourpy (1.2.0-r0)\n",
            "(10/131) Installing py3-contourpy-pyc (1.2.0-r0)\n",
            "(11/131) Installing py3-cycler (0.12.1-r0)\n",
            "(12/131) Installing py3-cycler-pyc (0.12.1-r0)\n",
            "(13/131) Installing py3-six (1.16.0-r8)\n",
            "(14/131) Installing py3-six-pyc (1.16.0-r8)\n",
            "(15/131) Installing py3-dateutil (2.8.2-r4)\n",
            "(16/131) Installing py3-dateutil-pyc (2.8.2-r4)\n",
            "(17/131) Installing py3-fonttools (4.46.0-r0)\n",
            "(18/131) Installing py3-fonttools-pyc (4.46.0-r0)\n",
            "(19/131) Installing py3-kiwisolver (1.4.5-r0)\n",
            "(20/131) Installing py3-kiwisolver-pyc (1.4.5-r0)\n",
            "(21/131) Installing brotli-libs (1.1.0-r1)\n",
            "(22/131) Installing libpng (1.6.44-r0)\n",
            "(23/131) Installing freetype (2.13.2-r0)\n",
            "(24/131) Installing libimagequant (4.2.2-r0)\n",
            "(25/131) Installing libjpeg-turbo (3.0.1-r0)\n",
            "(26/131) Installing lcms2 (2.15-r4)\n",
            "(27/131) Installing openjpeg (2.5.0-r3)\n",
            "(28/131) Installing libsharpyuv (1.3.2-r0)\n",
            "(29/131) Installing libwebp (1.3.2-r0)\n",
            "(30/131) Installing zstd-libs (1.5.5-r8)\n",
            "(31/131) Installing tiff (4.6.0-r0)\n",
            "(32/131) Installing libwebpdemux (1.3.2-r0)\n",
            "(33/131) Installing libwebpmux (1.3.2-r0)\n",
            "(34/131) Installing libxau (1.0.11-r3)\n",
            "(35/131) Installing libmd (1.1.0-r0)\n",
            "(36/131) Installing libbsd (0.11.7-r3)\n",
            "(37/131) Installing libxdmcp (1.1.4-r3)\n",
            "(38/131) Installing libxcb (1.16-r0)\n",
            "(39/131) Installing py3-pillow (10.3.0-r0)\n",
            "(40/131) Installing py3-pillow-pyc (10.3.0-r0)\n",
            "(41/131) Installing py3-tz (2023.3-r1)\n",
            "(42/131) Installing py3-tz-pyc (2023.3-r1)\n",
            "(43/131) Installing tzdata (2025b-r0)\n",
            "(44/131) Installing tcl (8.6.13-r1)\n",
            "(45/131) Installing libx11 (1.8.7-r0)\n",
            "(46/131) Installing libxrender (0.9.11-r4)\n",
            "(47/131) Installing fontconfig (2.14.2-r4)\n",
            "(48/131) Installing libxft (2.3.8-r2)\n",
            "(49/131) Installing tk (8.6.13-r2)\n",
            "(50/131) Installing python3-tkinter (3.11.14-r0)\n",
            "(51/131) Installing python3-tkinter-pyc (3.11.14-r0)\n",
            "(52/131) Installing py3-matplotlib-pyc (3.7.3-r0)\n",
            "(53/131) Installing libxext (1.3.5-r3)\n",
            "(54/131) Installing pixman (0.42.2-r2)\n",
            "(55/131) Installing cairo (1.18.4-r0)\n",
            "(56/131) Installing py3-cairo (1.25.1-r0)\n",
            "(57/131) Installing qhull (2020.2-r3)\n",
            "(58/131) Installing py3-matplotlib (3.7.3-r0)\n",
            "(59/131) Installing py3-pandas (2.0.3-r0)\n",
            "(60/131) Installing py3-pandas-pyc (2.0.3-r0)\n",
            "(61/131) Installing py3-cloudpickle (3.0.0-r0)\n",
            "(62/131) Installing py3-cloudpickle-pyc (3.0.0-r0)\n",
            "(63/131) Installing py3-click (8.1.7-r0)\n",
            "(64/131) Installing py3-click-pyc (8.1.7-r0)\n",
            "(65/131) Installing py3-fsspec (2023.12.0-r0)\n",
            "(66/131) Installing py3-fsspec-pyc (2023.12.0-r0)\n",
            "(67/131) Installing py3-zipp (3.17.0-r0)\n",
            "(68/131) Installing py3-zipp-pyc (3.17.0-r0)\n",
            "(69/131) Installing py3-importlib-metadata (7.0.0-r0)\n",
            "(70/131) Installing py3-importlib-metadata-pyc (7.0.0-r0)\n",
            "(71/131) Installing py3-locket (1.0.0-r2)\n",
            "(72/131) Installing py3-locket-pyc (1.0.0-r2)\n",
            "(73/131) Installing libsodium (1.0.19-r0)\n",
            "(74/131) Installing libzmq (4.3.5-r2)\n",
            "(75/131) Installing py3-pyzmq (23.2.1-r3)\n",
            "(76/131) Installing py3-pyzmq-pyc (23.2.1-r3)\n",
            "(77/131) Installing py3-toolz (0.12.0-r2)\n",
            "(78/131) Installing py3-toolz-pyc (0.12.0-r2)\n",
            "(79/131) Installing py3-partd (1.4.1-r0)\n",
            "(80/131) Installing py3-partd-pyc (1.4.1-r0)\n",
            "(81/131) Installing yaml (0.2.5-r2)\n",
            "(82/131) Installing py3-yaml (6.0.1-r1)\n",
            "(83/131) Installing py3-yaml-pyc (6.0.1-r1)\n",
            "(84/131) Installing py3-dask (2023.12.0-r0)\n",
            "(85/131) Installing py3-dask-pyc (2023.12.0-r0)\n",
            "(86/131) Installing py3-markupsafe (2.1.3-r0)\n",
            "(87/131) Installing py3-markupsafe-pyc (2.1.3-r0)\n",
            "(88/131) Installing py3-jinja2 (3.1.6-r0)\n",
            "(89/131) Installing py3-jinja2-pyc (3.1.6-r0)\n",
            "(90/131) Installing py3-msgpack (1.0.7-r0)\n",
            "(91/131) Installing py3-msgpack-pyc (1.0.7-r0)\n",
            "(92/131) Installing py3-psutil (5.9.6-r0)\n",
            "(93/131) Installing py3-psutil-pyc (5.9.6-r0)\n",
            "(94/131) Installing py3-sortedcontainers (2.4.0-r4)\n",
            "(95/131) Installing py3-sortedcontainers-pyc (2.4.0-r4)\n",
            "(96/131) Installing py3-tblib (2.0.0-r0)\n",
            "(97/131) Installing py3-tblib-pyc (2.0.0-r0)\n",
            "(98/131) Installing py3-tornado (6.4-r0)\n",
            "(99/131) Installing py3-tornado-pyc (6.4-r0)\n",
            "(100/131) Installing py3-urllib3 (1.26.18-r0)\n",
            "(101/131) Installing py3-urllib3-pyc (1.26.18-r0)\n",
            "(102/131) Installing py3-heapdict (1.0.1-r4)\n",
            "(103/131) Installing py3-heapdict-pyc (1.0.1-r4)\n",
            "(104/131) Installing lmdb (0.9.31-r0)\n",
            "(105/131) Installing py3-lmdb (1.2.1-r4)\n",
            "(106/131) Installing py3-lmdb-pyc (1.2.1-r4)\n",
            "(107/131) Installing py3-zict (3.0.0-r0)\n",
            "(108/131) Installing py3-zict-pyc (3.0.0-r0)\n",
            "(109/131) Installing py3-distributed (2023.11.0-r0)\n",
            "(110/131) Installing py3-distributed-pyc (2023.11.0-r0)\n",
            "(111/131) Installing py3-loky (3.4.1-r0)\n",
            "(112/131) Installing py3-loky-pyc (3.4.1-r0)\n",
            "(113/131) Installing py3-joblib (1.3.2-r0)\n",
            "(114/131) Installing py3-joblib-pyc (1.3.2-r0)\n",
            "(115/131) Installing py3-platformdirs (4.0.0-r0)\n",
            "(116/131) Installing py3-platformdirs-pyc (4.0.0-r0)\n",
            "(117/131) Installing py3-charset-normalizer (3.3.2-r0)\n",
            "(118/131) Installing py3-charset-normalizer-pyc (3.3.2-r0)\n",
            "(119/131) Installing py3-idna (3.7-r0)\n",
            "(120/131) Installing py3-idna-pyc (3.7-r0)\n",
            "(121/131) Installing py3-requests (2.32.4-r0)\n",
            "(122/131) Installing py3-requests-pyc (2.32.4-r0)\n",
            "(123/131) Installing py3-pooch (1.8.0-r0)\n",
            "(124/131) Installing py3-pooch-pyc (1.8.0-r0)\n",
            "(125/131) Installing py3-scipy (1.11.4-r0)\n",
            "(126/131) Installing py3-scipy-pyc (1.11.4-r0)\n",
            "(127/131) Installing py3-threadpoolctl (3.2.0-r0)\n",
            "(128/131) Installing py3-threadpoolctl-pyc (3.2.0-r0)\n",
            "(129/131) Installing libgomp (13.2.1_git20231014-r0)\n",
            "(130/131) Installing py3-scikit-learn (1.3.2-r0)\n",
            "(131/131) Installing py3-scikit-learn-pyc (1.3.2-r0)\n",
            "Executing busybox-1.36.1-r15.trigger\n",
            "OK: 407 MiB in 181 packages\n",
            "\n",
            "--- Dependency Installation Complete ---\n",
            "\n",
            "==================================================\n",
            "User message: Create a linear regression chart: GDP per capita vs life expectancy. Clean data, show scatter + regression line.\n",
            "==================================================\n",
            "Gravix AI is thinking...\n",
            "Generated code:\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "from sklearn.linear_model import LinearRegression\n",
            "import numpy as np\n",
            "import sys\n",
            "import traceback\n",
            "import base64\n",
            "\n",
            "try:\n",
            "    # Load and clean data\n",
            "    df = pd.read_csv('/home/user/data.csv')\n",
            "    print(f\"Original data shape: {df.shape}\")\n",
            "\n",
            "    # Define key columns\n",
            "    gdp_col = 'GDP per capita (current US$)'\n",
            "    life_exp_col = 'Life expectancy at birth, total (years)'\n",
            "\n",
            "    df_clean = df[[gdp_col, life_exp_col]].dropna()\n",
            "\n",
            "    # Convert to numeric, handling potential errors\n",
            "    df_clean[gdp_col] = pd.to_numeric(df_clean[gdp_col], errors='coerce')\n",
            "    df_clean[life_exp_col] = pd.to_numeric(df_clean[life_exp_col], errors='coerce')\n",
            "\n",
            "    # Drop rows that failed conversion\n",
            "    df_clean = df_clean.dropna()\n",
            "    print(f\"Clean data shape: {df_clean.shape}\")\n",
            "\n",
            "    if df_clean.empty:\n",
            "        print(\"Error: No data left after cleaning.\")\n",
            "        sys.exit(1)\n",
            "\n",
            "    # Prepare features and target\n",
            "    X = df_clean[gdp_col].values.reshape(-1, 1)\n",
            "    y = df_clean[life_exp_col].values\n",
            "\n",
            "    # Fit linear regression model\n",
            "    model = LinearRegression().fit(X, y)\n",
            "    print(\"Model fitted successfully.\")\n",
            "\n",
            "    # Create scatter plot with regression line\n",
            "    plt.figure(figsize=(10, 6))\n",
            "    plt.scatter(X, y, alpha=0.6, color='blue', label='Data points')\n",
            "\n",
            "    # Create line\n",
            "    X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
            "    plt.plot(X_line, model.predict(X_line), color='red', linewidth=2, label='Regression line')\n",
            "\n",
            "    plt.xlabel('GDP per capita (current US$)')\n",
            "    plt.ylabel('Life expectancy at birth, total (years)')\n",
            "    plt.title('GDP per capita vs Life Expectancy')\n",
            "    plt.legend()\n",
            "    plt.grid(True, alpha=0.3)\n",
            "\n",
            "    # Save the plot\n",
            "    plot_path = '/home/user/chart.png'\n",
            "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
            "    print(f\"Plot saved to {plot_path}\")\n",
            "\n",
            "    # Read the saved image, encode it, and print the base64 string\n",
            "    with open(plot_path, 'rb') as f:\n",
            "        image_bytes = f.read()\n",
            "        base64_string = base64.b64encode(image_bytes).decode('utf-8')\n",
            "        print(f'PLOT_BASE64:{base64_string}')\n",
            "\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred: {e}\")\n",
            "    traceback.print_exc()\n",
            "\n",
            "--- Running Code in Gravix Layer Sandbox ---\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    with Sandbox.create() as sandbox:\n",
        "        if not upload_dataset(sandbox):\n",
        "            raise Exception(\"Dataset upload failed. Aborting.\")\n",
        "\n",
        "        # --- NEW STEP: Install dependencies ---\n",
        "        print(\"\\n--- Installing Dependencies in Sandbox via APK ---\")\n",
        "        print(\"This may take a few minutes...\")\n",
        "        \n",
        "        # Install pre-compiled Python libraries from Alpine's package manager\n",
        "        # This is much faster and more reliable than using pip to build from source\n",
        "        print(\"Running: apk add py3-pandas py3-matplotlib py3-scikit-learn\")\n",
        "        install_result = sandbox.run_command(\"apk\", [\"add\", \"py3-pandas\", \"py3-matplotlib\", \"py3-scikit-learn\"], timeout=300)\n",
        "        \n",
        "        if install_result.stdout:\n",
        "            print(\"[apk STDOUT]:\\n\", install_result.stdout)\n",
        "        if install_result.stderr:\n",
        "            print(\"[apk STDERR]:\\n\", install_result.stderr)\n",
        "            \n",
        "        if install_result.exit_code == 0:\n",
        "            print(\"--- Dependency Installation Complete ---\")\n",
        "        else:\n",
        "            print(\"[apk ERROR]:\", getattr(install_result, 'error', 'No error attribute'))\n",
        "            raise Exception(\"System library installation (apk) failed. Aborting.\")\n",
        "        # --- End New Step ---\n",
        "\n",
        "        # This prompt is clear and maps to the system prompt's example\n",
        "        user_task = \"Create a linear regression chart: GDP per capita vs life expectancy. Clean data, show scatter + regression line.\"\n",
        "        \n",
        "        plot_base64_data = chat_with_llm(\n",
        "            sandbox,\n",
        "            user_task,\n",
        "        )\n",
        "        \n",
        "        if plot_base64_data:\n",
        "            print(f\"\\n--- Decoding and displaying plot ---\")\n",
        "            try:\n",
        "                # *** FIX HERE ***\n",
        "                # Decode the base64 string (str) back into bytes\n",
        "                image_bytes = base64.b64decode(plot_base64_data)\n",
        "                # Pass the raw bytes to Image()\n",
        "                display(Image(data=image_bytes))\n",
        "            except Exception as e:\n",
        "                print(f\"\\nError displaying base64 image: {e}\")\n",
        "        else:\n",
        "            print(\"\\n--- No plot was generated by the AI (base64 string not found in output) ---\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- An error occurred during the sandbox operation --- \")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Please ensure your GRAVIXLAYER_API_KEY is valid and data.csv exists.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "### What We've Accomplished\n",
        "\n",
        "In this comprehensive cookbook, we've built a complete AI-powered data analysis ecosystem:\n",
        "\n",
        "1. **Intelligent Code Generation** - LLM-powered Python code creation for complex data analysis\n",
        "2. **Secure Execution Environment** - Containerized sandbox execution with full isolation\n",
        "3. **Automated Visualization** - AI-generated charts and plots with seamless display\n",
        "4. **End-to-End Workflow** - From data upload to final visualization in one pipeline\n",
        "\n",
        "### The Power of AI-Driven Data Analysis\n",
        "\n",
        "This approach represents a fundamental shift in data science workflows:\n",
        "\n",
        "- **Accessibility**: Makes advanced data analysis available to non-programmers\n",
        "- **Efficiency**: Eliminates manual coding for routine analysis tasks\n",
        "- **Safety**: Sandbox execution prevents code from affecting local environment\n",
        "- **Scalability**: Can handle multiple datasets and analysis types simultaneously\n",
        "- **Reproducibility**: Generated code can be saved and reused for similar analyses\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "To extend your AI data analysis capabilities:\n",
        "\n",
        "1. **Custom Prompts** - Develop specialized prompts for domain-specific analyses\n",
        "2. **Multi-Dataset Analysis** - Extend to handle multiple data sources simultaneously\n",
        "3. **Advanced Models** - Experiment with different LLMs for specialized tasks\n",
        "4. **Production Deployment** - Add monitoring, logging, and enterprise security features\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- **AI code generation enables rapid prototyping** - From idea to visualization in minutes\n",
        "- **Sandbox execution ensures safety** - No risk to local environment or data\n",
        "- **Structured prompts improve results** - Clear instructions lead to better generated code\n",
        "- **Base64 encoding enables seamless visualization** - Charts display directly in notebooks"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gravix_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
