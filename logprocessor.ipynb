{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GravixLayer Sandbox – Command Execution + AI Log Summary\n",
        "\n",
        "This notebook demonstrates a full **log analysis workflow** using:\n",
        "\n",
        "1. **Command Execution in a sandbox** (via `Sandbox.run_command`)\n",
        "2. **AI LLM summarization** using `GravixLayer` chat completions\n",
        "3. **Saving the AI summary** to a local file (`log_ai_summary.txt`) so it can be downloaded\n",
        "\n",
        "### What we will do\n",
        "\n",
        "1. Create a sandbox using `Sandbox.create()`\n",
        "2. Generate a sample `app.log` file (with `INFO` and `ERROR` lines) using shell commands\n",
        "3. Use commands like `grep`, `wc`, and `cat` to:\n",
        "   - Extract all `ERROR` lines\n",
        "   - Count how many errors occurred\n",
        "4. Send the log data to an **AI model** to get a human-readable summary\n",
        "5. Save the AI summary to `log_ai_summary.txt` locally, so it can be downloaded from the notebook environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install and Import GravixLayer\n",
        "\n",
        "We install the GravixLayer SDK if needed and import:\n",
        "\n",
        "- `Sandbox` for command execution inside an isolated environment\n",
        "- `GravixLayer` client to call the AI LLM\n",
        "\n",
        "Make sure you have the environment variable `GRAVIXLAYER_API_KEY` set before running this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gravixlayer in ./gravix_test/lib/python3.12/site-packages (0.0.50)\n",
            "Requirement already satisfied: requests>=2.25.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (2.32.5)\n",
            "Requirement already satisfied: python-dotenv>=0.19.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (1.0.0)\n",
            "Requirement already satisfied: httpx>=0.24.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (0.28.1)\n",
            "Requirement already satisfied: anyio in ./gravix_test/lib/python3.12/site-packages (from httpx>=0.24.0->gravixlayer) (4.11.0)\n",
            "Requirement already satisfied: certifi in ./gravix_test/lib/python3.12/site-packages (from httpx>=0.24.0->gravixlayer) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in ./gravix_test/lib/python3.12/site-packages (from httpx>=0.24.0->gravixlayer) (1.0.9)\n",
            "Requirement already satisfied: idna in ./gravix_test/lib/python3.12/site-packages (from httpx>=0.24.0->gravixlayer) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in ./gravix_test/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.24.0->gravixlayer) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./gravix_test/lib/python3.12/site-packages (from anyio->httpx>=0.24.0->gravixlayer) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in ./gravix_test/lib/python3.12/site-packages (from anyio->httpx>=0.24.0->gravixlayer) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Install GravixLayer SDK if it's not already installed\n",
        "!pip install gravixlayer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GravixLayer SDK imported. Sandbox and AI client are ready.\n"
          ]
        }
      ],
      "source": [
        "from gravixlayer import Sandbox, GravixLayer\n",
        "from textwrap import indent\n",
        "\n",
        "# Initialize the GravixLayer client for AI calls\n",
        "client = GravixLayer()\n",
        "\n",
        "# Choose an AI model\n",
        "MODEL_NAME = \"meta-llama/llama-3.1-8b-instruct\"\n",
        "\n",
        "print(\"GravixLayer SDK imported. Sandbox and AI client are ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Run Log Processing Commands Inside a Sandbox\n",
        "\n",
        "In this step, we:\n",
        "\n",
        "1. Create a sandbox with `Sandbox.create()`\n",
        "2. Generate a sample `app.log` with `INFO` and `ERROR` lines using a shell command\n",
        "3. Use `grep` to extract all `ERROR` lines\n",
        "4. Use `grep -c` to count how many errors occurred\n",
        "5. Capture the full log and error lines in Python variables for AI\n",
        "\n",
        "All file operations here are done via **commands inside the sandbox**, not direct Python file I/O."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sandbox created. Running log processing commands...\n",
            "\n",
            "[Step 1] Creating app.log with sample log lines...\n",
            "\n",
            "Create log exit code: 0\n",
            "\n",
            "[Step 2] Preview full app.log:\n",
            "\n",
            "     INFO Server started INFO Health check OK ERROR Database connection failed INFO Retrying connection ERROR Timeout while querying service INFO Request completed ERROR Invalid API key INFO Background job scheduled ERROR Disk space critically low \n",
            "\n",
            "[Step 3] Extracting ERROR lines with grep...\n",
            "\n",
            "ERROR lines found:\n",
            "\n",
            "     INFO Server started INFO Health check OK ERROR Database connection failed INFO Retrying connection ERROR Timeout while querying service INFO Request completed ERROR Invalid API key INFO Background job scheduled ERROR Disk space critically low \n",
            "\n",
            "[Step 4] Counting number of ERROR entries...\n",
            "\n",
            "Total ERROR count: 1\n",
            "\n",
            "[Step 5] Files in sandbox (ls -la):\n",
            "\n",
            "    total 3312\n",
            "    drwxr-xr-x   21 root     root          4096 Dec 10 08:33 .\n",
            "    drwxr-xr-x   21 root     root          4096 Dec 10 08:33 ..\n",
            "    -rw-r--r--    1 root     root       3285663 Dec  7  2023 alpine.tar.gz\n",
            "    -rw-r--r--    1 root     root           245 Dec 10 08:33 app.log\n",
            "    drwxr-xr-x    2 root     root          4096 Oct 28 21:08 bin\n",
            "    drwxr-xr-x    2 root     root          4096 Oct 28 21:08 dev\n",
            "    drwxr-xr-x   24 root     root          4096 Oct 28 21:08 etc\n",
            "    drwxr-xr-x    3 root     root          4096 Oct 28 21:08 home\n",
            "    drwxr-xr-x    7 root     root          4096 Dec  7  2023 lib\n",
            "    drwx------    2 root     root         16384 Oct 28 21:08 lost+found\n",
            "    drwxr-xr-x    5 root     root          4096 Dec  7  2023 media\n",
            "    drwxr-xr-x    2 root     root          4096 Dec  7  2023 mnt\n",
            "    drwxr-xr-x    3 root     root          4096 Oct 28 21:08 opt\n",
            "    dr-xr-xr-x    2 root     root          4096 Dec  7  2023 proc\n",
            "    drwx------    3 root     root          4096 Oct 28 21:08 root\n",
            "    drwxr-xr-x    2 root     root          4096 Dec  7  2023 run\n",
            "    drwxr-xr-x    2 root     root          4096 Dec  7  2023 sbin\n",
            "    drwxr-xr-x    2 root     root          4096 Dec  7  2023 srv\n",
            "    drwxr-xr-x    2 root     root          4096 Dec  7  2023 sys\n",
            "    drwxrwxrwt    2 root     root          4096 Oct 28 21:08 tmp\n",
            "    drwxr-xr-x    8 root     root          4096 Oct 28 21:08 usr\n",
            "    drwxr-xr-x   12 root     root          4096 Dec  7  2023 var\n",
            "    drwxr-xr-x    2 sandbox  sandbox       4096 Oct 28 21:08 workspace\n",
            "\n",
            "\n",
            "Log processing inside sandbox is complete. Sandbox will be cleaned up after this block.\n"
          ]
        }
      ],
      "source": [
        "# These variables will hold data we want to send to the AI later\n",
        "full_log_text = \"\"\n",
        "error_lines_text = \"\"\n",
        "error_count_value = None\n",
        "\n",
        "with Sandbox.create() as sandbox:\n",
        "    print(\"Sandbox created. Running log processing commands...\\n\")\n",
        "\n",
        "    # 2.1 – Create a sample log file using shell commands\n",
        "    log_data = \"\"\"\n",
        "INFO Server started\n",
        "INFO Health check OK\n",
        "ERROR Database connection failed\n",
        "INFO Retrying connection\n",
        "ERROR Timeout while querying service\n",
        "INFO Request completed\n",
        "ERROR Invalid API key\n",
        "INFO Background job scheduled\n",
        "ERROR Disk space critically low\n",
        "\"\"\"\n",
        "\n",
        "    print(\"[Step 1] Creating app.log with sample log lines...\\n\")\n",
        "    create_log_result = sandbox.run_command(\n",
        "        \"sh\",\n",
        "        [\"-c\", f\"echo '{log_data}' > app.log\"]\n",
        "    )\n",
        "    print(\"Create log exit code:\", create_log_result.exit_code)\n",
        "\n",
        "    # 2.2 – Preview the full log file\n",
        "    print(\"\\n[Step 2] Preview full app.log:\\n\")\n",
        "    preview_result = sandbox.run_command(\"cat\", [\"app.log\"])\n",
        "    full_log_text = preview_result.stdout\n",
        "    print(indent(full_log_text, \"    \"))\n",
        "\n",
        "    # 2.3 – Find all ERROR lines using grep\n",
        "    print(\"[Step 3] Extracting ERROR lines with grep...\\n\")\n",
        "    error_lines_result = sandbox.run_command(\"grep\", [\"ERROR\", \"app.log\"])\n",
        "    error_lines_text = error_lines_result.stdout\n",
        "    print(\"ERROR lines found:\\n\")\n",
        "    print(indent(error_lines_text, \"    \"))\n",
        "\n",
        "    # 2.4 – Count number of ERROR entries\n",
        "    print(\"[Step 4] Counting number of ERROR entries...\\n\")\n",
        "    error_count_result = sandbox.run_command(\"grep\", [\"-c\", \"ERROR\", \"app.log\"])\n",
        "    error_count_value = error_count_result.stdout.strip()\n",
        "    print(f\"Total ERROR count: {error_count_value}\\n\")\n",
        "\n",
        "    # 2.5 – Show final files in the sandbox directory\n",
        "    print(\"[Step 5] Files in sandbox (ls -la):\\n\")\n",
        "    ls_result = sandbox.run_command(\"ls\", [\"-la\"])\n",
        "    print(indent(ls_result.stdout, \"    \"))\n",
        "\n",
        "    print(\"\\nLog processing inside sandbox is complete. Sandbox will be cleaned up after this block.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Use AI to Summarize the Logs\n",
        "\n",
        "Now that we have:\n",
        "\n",
        "- `full_log_text` – the entire log file\n",
        "- `error_lines_text` – only lines with `ERROR`\n",
        "- `error_count_value` – how many errors occurred\n",
        "\n",
        "We send this to an **AI model** through GravixLayer to generate a concise, human-readable summary. This demonstrates how you can plug AI on top of sandbox-generated data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calling AI model to summarize logs...\n",
            "\n",
            "AI Log Summary:\n",
            "\n",
            "**Summary:**\n",
            "\n",
            "The system is experiencing several errors, indicating that it is not functioning as expected. The errors are related to database connectivity, service queries, API key validation, and disk space. These issues may be causing the system to malfunction or fail to provide services.\n",
            "\n",
            "**Likely Root Causes:**\n",
            "\n",
            "1. **Database Connectivity Issues**: The system is unable to connect to the database, which may be due to network issues, incorrect database credentials, or database server downtime.\n",
            "2. **Service Query Timeout**: The system is taking too long to query a service, which may be due to slow service response times, high service load, or incorrect query parameters.\n",
            "3. **Invalid API Key**: The system is unable to validate the API key provided, which may be due to incorrect API key configuration, expired or invalid API keys, or API key validation issues.\n",
            "4. **Low Disk Space**: The system is running out of disk space, which may be due to high storage usage, slow disk performance, or incorrect disk space allocation.\n",
            "\n",
            "**Suggested Next Steps for Engineer Investigation:**\n",
            "\n",
            "1. **Database Connectivity Issues**:\n",
            "\t* Check database server status and logs for any issues.\n",
            "\t* Verify database credentials and connection settings.\n",
            "\t* Investigate network connectivity between the system and database server.\n",
            "2. **Service Query Timeout**:\n",
            "\t* Check service response times and load to identify potential bottlenecks.\n",
            "\t* Review query parameters and optimize queries for better performance.\n",
            "\t* Investigate service configuration and settings for any issues.\n",
            "3. **Invalid API Key**:\n",
            "\t* Review API key configuration and settings for any issues.\n",
            "\t* Investigate API key validation logic for any errors.\n",
            "\t* Check API key usage and expiration dates.\n",
            "4. **Low Disk Space**:\n",
            "\t* Investigate disk usage and identify the cause of high storage usage.\n",
            "\t* Review disk performance and configuration for any issues.\n",
            "\t* Plan disk space optimization and cleanup.\n",
            "\n",
            "**Additional Recommendations:**\n",
            "\n",
            "* Implement monitoring and logging to detect and alert on errors and performance issues.\n",
            "* Develop a incident response plan to quickly respond to errors and minimize downtime.\n",
            "* Regularly review and optimize system configuration, settings, and performance to prevent similar issues in the future.\n"
          ]
        }
      ],
      "source": [
        "if not full_log_text:\n",
        "    raise RuntimeError(\"full_log_text is empty. Make sure the sandbox cell above ran successfully.\")\n",
        "\n",
        "print(\"Calling AI model to summarize logs...\\n\")\n",
        "\n",
        "prompt_for_ai = f\"\"\"\n",
        "You are a log analysis assistant.\n",
        "\n",
        "Here is the full application log:\n",
        "--------------------\n",
        "{full_log_text}\n",
        "--------------------\n",
        "\n",
        "Here are only the lines that contain the word ERROR:\n",
        "--------------------\n",
        "{error_lines_text}\n",
        "--------------------\n",
        "\n",
        "The total number of ERROR entries detected is: {error_count_value}.\n",
        "\n",
        "Please provide:\n",
        "1. A brief summary of what is going wrong in this system\n",
        "2. The likely root causes based on the errors\n",
        "3. Suggested next steps for an engineer to investigate\n",
        "\"\"\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant for analyzing server logs.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_for_ai},\n",
        "    ],\n",
        ")\n",
        "\n",
        "ai_summary = completion.choices[0].message.content\n",
        "\n",
        "print(\"AI Log Summary:\\n\")\n",
        "print(ai_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save the AI Summary to a Local File\n",
        "\n",
        "To show **file handling and download** from the notebook environment, we will:\n",
        "\n",
        "1. Save the AI-generated summary into a local file named `log_ai_summary.txt`\n",
        "2. You can then download this file from your notebook / IDE file browser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI summary saved to local file: log_ai_summary.txt\n",
            "You can now download 'log_ai_summary.txt' from the notebook file browser.\n"
          ]
        }
      ],
      "source": [
        "local_filename = \"log_ai_summary.txt\"\n",
        "\n",
        "with open(local_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"AI Summary for app.log\\n\")\n",
        "    f.write(\"========================\\n\\n\")\n",
        "    f.write(ai_summary)\n",
        "\n",
        "print(f\"AI summary saved to local file: {local_filename}\")\n",
        "print(\"You can now download 'log_ai_summary.txt' from the notebook file browser.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. What This Example Demonstrates\n",
        "\n",
        "This notebook combines **Sandbox Command Execution** and **AI LLM** usage in a single workflow:\n",
        "\n",
        "- ✅ Running system commands inside an isolated GravixLayer sandbox\n",
        "- ✅ Creating and inspecting log files via `sh`, `cat`, `grep`, and `ls`\n",
        "- ✅ Extracting metrics (error counts) using CLI tools\n",
        "- ✅ Sending sandbox-generated data to an AI model for analysis\n",
        "- ✅ Saving the AI output into a local text file for download\n",
        "\n",
        "You can adapt this pattern for:\n",
        "\n",
        "- Automated log triage and summarization\n",
        "- Error trend analysis pipelines\n",
        "- Health checks with AI-generated human-readable reports\n",
        "- Any workflow where **sandboxed commands produce data** and **AI explains or enriches it**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22da2d49",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gravix_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
