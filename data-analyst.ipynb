{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gravix Layer Cookbook: AI Data Analyst\n",
    "\n",
    "Welcome to the Gravix Layer Cookbook series. This guide demonstrates building an intelligent data analysis workflow that generates, executes, and visualizes Python code automatically using advanced language models and secure sandbox environments.\n",
    "\n",
    "## Vision\n",
    "\n",
    "Imagine having an AI assistant that can understand your data analysis requests in natural language, generate robust Python code, execute it safely in isolated environments, and return meaningful insights with professional visualizations - all without you writing a single line of code.\n",
    "\n",
    "## Solution\n",
    "\n",
    "This system combines two powerful Gravix Layer capabilities:\n",
    "- **LLM Inference**: Advanced language models generate clean, robust Python code for data analysis tasks\n",
    "- **Secure Sandbox Execution**: Code runs in isolated, containerized environments with full dependency management\n",
    "- **Automatic Visualization**: Generated charts and plots with base64 encoding for seamless display\n",
    "- **Error Handling**: Robust exception handling and debugging capabilities\n",
    "\n",
    "## What You'll Build\n",
    "\n",
    "This recipe provides a production-ready AI data analyst system:\n",
    "- Intelligent code generation for complex data analysis workflows\n",
    "- Secure execution environment with automatic dependency installation\n",
    "- Interactive analysis interface with real-time results\n",
    "- Professional visualization output with charts and statistical insights\n",
    "- Comprehensive error handling and recovery mechanisms\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Basic understanding of data analysis concepts\n",
    "- Gravix Layer API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLxqUGV5_wnv",
    "outputId": "a14f6c98-6a10-4583-c398-be1672ed0d5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gravixlayer in ./gravix_test/lib/python3.12/site-packages (0.0.43)\n",
      "Requirement already satisfied: IPython in ./gravix_test/lib/python3.12/site-packages (9.5.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (2.32.5)\n",
      "Requirement already satisfied: python-dotenv>=0.19.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (1.0.0)\n",
      "Requirement already satisfied: decorator in ./gravix_test/lib/python3.12/site-packages (from IPython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./gravix_test/lib/python3.12/site-packages (from IPython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./gravix_test/lib/python3.12/site-packages (from IPython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./gravix_test/lib/python3.12/site-packages (from IPython) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./gravix_test/lib/python3.12/site-packages (from IPython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./gravix_test/lib/python3.12/site-packages (from IPython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./gravix_test/lib/python3.12/site-packages (from IPython) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./gravix_test/lib/python3.12/site-packages (from IPython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./gravix_test/lib/python3.12/site-packages (from IPython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./gravix_test/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./gravix_test/lib/python3.12/site-packages (from jedi>=0.16->IPython) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./gravix_test/lib/python3.12/site-packages (from pexpect>4.3->IPython) (0.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (2025.8.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./gravix_test/lib/python3.12/site-packages (from stack_data->IPython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./gravix_test/lib/python3.12/site-packages (from stack_data->IPython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./gravix_test/lib/python3.12/site-packages (from stack_data->IPython) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gravixlayer IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NYAAAS_kFD87"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from gravixlayer import GravixLayer, Sandbox\n",
    "from IPython.display import Image, display\n",
    "import base64 # Import for base64 handling\n",
    "\n",
    "os.environ[\"GRAVIXLAYER_API_KEY\"] = GRAVIXLAYER_API_KEY\n",
    "\n",
    "# Choose a powerful model for code generation (supported by GravixLayer)\n",
    "MODEL_NAME = \"qwen/qwen3-4b-instruct-2507\"\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert Python data scientist. Your goal is to generate clean, robust, and working Python code.\n",
    "\n",
    "**TASK CONTEXT**\n",
    "- You will be given a task, typically for data analysis and visualization.\n",
    "- The dataset is located at `/home/user/data.csv`.\n",
    "- Key columns: 'GDP per capita (current US$)', 'Life expectancy at birth, total (years)'.\n",
    "\n",
    "**CORE RULES**\n",
    "1.  **Code Only:** Respond *ONLY* with a single Python code block. Do not add any text before or after the ```python block.\n",
    "2.  **Save Plot:** You MUST save any generated plot to `/home/user/chart.png`.\n",
    "3.  **Critical Output:** After saving, you MUST read the plot file, base64-encode it, and print the *exact* line: `print(f'PLOT_BASE64:<base64_string_here>')`. This is how the system finds your plot.\n",
    "4.  **Robust Code:** Include error handling (`try...except`) and print statements to show progress (e.g., `df.shape`, `df_clean.shape`).\n",
    "\n",
    "**EXAMPLE OF A PERFECT RESPONSE**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import sys\n",
    "import traceback\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    # Load and clean data\n",
    "    df = pd.read_csv('/home/user/data.csv')\n",
    "    print(f\"Original data shape: {df.shape}\")\n",
    "\n",
    "    # Define key columns\n",
    "    gdp_col = 'GDP per capita (current US$)'\n",
    "    life_exp_col = 'Life expectancy at birth, total (years)'\n",
    "    \n",
    "    df_clean = df[[gdp_col, life_exp_col]].dropna()\n",
    "\n",
    "    # Convert to numeric, handling potential errors\n",
    "    df_clean[gdp_col] = pd.to_numeric(df_clean[gdp_col], errors='coerce')\n",
    "    df_clean[life_exp_col] = pd.to_numeric(df_clean[life_exp_col], errors='coerce')\n",
    "    \n",
    "    # Drop rows that failed conversion\n",
    "    df_clean = df_clean.dropna()\n",
    "    print(f\"Clean data shape: {df_clean.shape}\")\n",
    "\n",
    "    if df_clean.empty:\n",
    "        print(\"Error: No data left after cleaning.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Prepare features and target\n",
    "    X = df_clean[gdp_col].values.reshape(-1, 1)\n",
    "    y = df_clean[life_exp_col].values\n",
    "\n",
    "    # Fit linear regression model\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    print(\"Model fitted successfully.\")\n",
    "\n",
    "    # Create scatter plot with regression line\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X, y, alpha=0.6, color='blue', label='Data points')\n",
    "    \n",
    "    # Create line\n",
    "    X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "    plt.plot(X_line, model.predict(X_line), color='red', linewidth=2, label='Regression line')\n",
    "    \n",
    "    plt.xlabel('GDP per capita (current US$)')\n",
    "    plt.ylabel('Life expectancy at birth, total (years)')\n",
    "    plt.title('GDP per capita vs Life Expectancy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = '/home/user/chart.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved to {plot_path}\")\n",
    "\n",
    "    # Read the saved image, encode it, and print the base64 string\n",
    "    with open(plot_path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "        base64_string = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        # This is the most important line:\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BpiwOkTqEeBh"
   },
   "outputs": [],
   "source": [
    "def code_interpret(gravix_sandbox, code):\n",
    "    print(\"\\n--- Running Code in Gravix Layer Sandbox ---\")\n",
    "    result = gravix_sandbox.run_code(code)\n",
    "    \n",
    "    # Safely get stdout, stderr, and error\n",
    "    stdout = getattr(result, 'stdout', '')\n",
    "    stderr = getattr(result, 'stderr', '')\n",
    "    error = getattr(result, 'error', None)\n",
    "    \n",
    "    if stdout:\n",
    "        print(\"[Sandbox STDOUT]:\")\n",
    "        print(stdout)\n",
    "    else:\n",
    "        print(\"[Sandbox STDOUT]: (No stdout)\")\n",
    "\n",
    "    if stderr:\n",
    "        print(\"\\n[Sandbox STDERR]:\")\n",
    "        print(stderr)\n",
    "    \n",
    "    if error:\n",
    "        print(\"\\n[Sandbox Execution Error]:\")\n",
    "        print(error)\n",
    "        \n",
    "    print(\"--- End Sandbox Run ---\")\n",
    "    \n",
    "    # Return stdout for parsing, as it contains the print() statements\n",
    "    return stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IsLjFlRW_TAR"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    client = GravixLayer()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize GravixLayer client: {e}\")\n",
    "    client = None\n",
    "\n",
    "pattern = re.compile(r\"```python\\n(.*?)\\n```\", re.DOTALL)\n",
    "\n",
    "def match_code_blocks(llm_response):\n",
    "    match = pattern.search(llm_response)\n",
    "    if match:\n",
    "        code = match.group(1)\n",
    "        print(\"Generated code:\")\n",
    "        print(code)\n",
    "        return code\n",
    "    return \"\"\n",
    "\n",
    "def chat_with_llm(gravix_sandbox, user_message):\n",
    "    if not client:\n",
    "        print(\"GravixLayer client is not initialized.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\n{'='*50}\\nUser message: {user_message}\\n{'='*50}\")\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    "\n",
    "    print(\"Gravix AI is thinking...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    python_code = match_code_blocks(response_message.content)\n",
    "    \n",
    "    plot_base64 = None\n",
    "    if python_code:\n",
    "        # code_output_string is the full stdout from the sandbox\n",
    "        code_output_string = code_interpret(gravix_sandbox, python_code)\n",
    "        \n",
    "        if code_output_string:\n",
    "            # Search for the plot path within the entire stdout string, line by line\n",
    "            for line in code_output_string.splitlines():\n",
    "                if line and \"PLOT_BASE64:\" in line:\n",
    "                    plot_base64 = line.split(\"PLOT_BASE64:\", 1)[1].strip()\n",
    "                    break # Found it\n",
    "        return plot_base64\n",
    "    else:\n",
    "        print(f\"No Python code found in response: {response_message.content}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataset(gravix_sandbox):\n",
    "    print(\"Uploading dataset to Gravix Layer sandbox...\")\n",
    "    local_path = \"./data.csv\"\n",
    "    remote_path = \"/home/user/data.csv\"\n",
    "\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"Dataset file not found at {local_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(local_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        gravix_sandbox.write_file(remote_path, content)\n",
    "        print(\"Uploaded at\", remote_path)\n",
    "        return remote_path\n",
    "    except Exception as error:\n",
    "        print(\"Error during file upload:\", error)\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wKSWobclENIq",
    "outputId": "65ab42e7-6559-4e36-fb5a-d8e57fc455c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading dataset to Gravix Layer sandbox...\n",
      "Uploaded at /home/user/data.csv\n",
      "\n",
      "--- Installing Dependencies in Sandbox via APK ---\n",
      "This may take a few minutes...\n",
      "Running: apk add py3-pandas py3-matplotlib py3-scikit-learn\n",
      "[apk STDOUT]:\n",
      " fetch https://dl-cdn.alpinelinux.org/alpine/v3.19/main/x86_64/APKINDEX.tar.gz\n",
      "fetch https://dl-cdn.alpinelinux.org/alpine/v3.19/community/x86_64/APKINDEX.tar.gz\n",
      "(1/131) Installing py3-cairo-pyc (1.25.1-r0)\n",
      "(2/131) Installing py3-certifi (2024.2.2-r0)\n",
      "(3/131) Installing py3-certifi-pyc (2024.2.2-r0)\n",
      "(4/131) Installing libquadmath (13.2.1_git20231014-r0)\n",
      "(5/131) Installing libgfortran (13.2.1_git20231014-r0)\n",
      "(6/131) Installing openblas (0.3.25-r0)\n",
      "(7/131) Installing py3-numpy (1.25.2-r0)\n",
      "(8/131) Installing py3-numpy-pyc (1.25.2-r0)\n",
      "(9/131) Installing py3-contourpy (1.2.0-r0)\n",
      "(10/131) Installing py3-contourpy-pyc (1.2.0-r0)\n",
      "(11/131) Installing py3-cycler (0.12.1-r0)\n",
      "(12/131) Installing py3-cycler-pyc (0.12.1-r0)\n",
      "(13/131) Installing py3-six (1.16.0-r8)\n",
      "(14/131) Installing py3-six-pyc (1.16.0-r8)\n",
      "(15/131) Installing py3-dateutil (2.8.2-r4)\n",
      "(16/131) Installing py3-dateutil-pyc (2.8.2-r4)\n",
      "(17/131) Installing py3-fonttools (4.46.0-r0)\n",
      "(18/131) Installing py3-fonttools-pyc (4.46.0-r0)\n",
      "(19/131) Installing py3-kiwisolver (1.4.5-r0)\n",
      "(20/131) Installing py3-kiwisolver-pyc (1.4.5-r0)\n",
      "(21/131) Installing brotli-libs (1.1.0-r1)\n",
      "(22/131) Installing libpng (1.6.44-r0)\n",
      "(23/131) Installing freetype (2.13.2-r0)\n",
      "(24/131) Installing libimagequant (4.2.2-r0)\n",
      "(25/131) Installing libjpeg-turbo (3.0.1-r0)\n",
      "(26/131) Installing lcms2 (2.15-r4)\n",
      "(27/131) Installing openjpeg (2.5.0-r3)\n",
      "(28/131) Installing libsharpyuv (1.3.2-r0)\n",
      "(29/131) Installing libwebp (1.3.2-r0)\n",
      "(30/131) Installing zstd-libs (1.5.5-r8)\n",
      "(31/131) Installing tiff (4.6.0-r0)\n",
      "(32/131) Installing libwebpdemux (1.3.2-r0)\n",
      "(33/131) Installing libwebpmux (1.3.2-r0)\n",
      "(34/131) Installing libxau (1.0.11-r3)\n",
      "(35/131) Installing libmd (1.1.0-r0)\n",
      "(36/131) Installing libbsd (0.11.7-r3)\n",
      "(37/131) Installing libxdmcp (1.1.4-r3)\n",
      "(38/131) Installing libxcb (1.16-r0)\n",
      "(39/131) Installing py3-pillow (10.3.0-r0)\n",
      "(40/131) Installing py3-pillow-pyc (10.3.0-r0)\n",
      "(41/131) Installing py3-tz (2023.3-r1)\n",
      "(42/131) Installing py3-tz-pyc (2023.3-r1)\n",
      "(43/131) Installing tzdata (2025b-r0)\n",
      "(44/131) Installing tcl (8.6.13-r1)\n",
      "(45/131) Installing libx11 (1.8.7-r0)\n",
      "(46/131) Installing libxrender (0.9.11-r4)\n",
      "(47/131) Installing fontconfig (2.14.2-r4)\n",
      "(48/131) Installing libxft (2.3.8-r2)\n",
      "(49/131) Installing tk (8.6.13-r2)\n",
      "(50/131) Installing python3-tkinter (3.11.14-r0)\n",
      "(51/131) Installing python3-tkinter-pyc (3.11.14-r0)\n",
      "(52/131) Installing py3-matplotlib-pyc (3.7.3-r0)\n",
      "(53/131) Installing libxext (1.3.5-r3)\n",
      "(54/131) Installing pixman (0.42.2-r2)\n",
      "(55/131) Installing cairo (1.18.4-r0)\n",
      "(56/131) Installing py3-cairo (1.25.1-r0)\n",
      "(57/131) Installing qhull (2020.2-r3)\n",
      "(58/131) Installing py3-matplotlib (3.7.3-r0)\n",
      "(59/131) Installing py3-pandas (2.0.3-r0)\n",
      "(60/131) Installing py3-pandas-pyc (2.0.3-r0)\n",
      "(61/131) Installing py3-cloudpickle (3.0.0-r0)\n",
      "(62/131) Installing py3-cloudpickle-pyc (3.0.0-r0)\n",
      "(63/131) Installing py3-click (8.1.7-r0)\n",
      "(64/131) Installing py3-click-pyc (8.1.7-r0)\n",
      "(65/131) Installing py3-fsspec (2023.12.0-r0)\n",
      "(66/131) Installing py3-fsspec-pyc (2023.12.0-r0)\n",
      "(67/131) Installing py3-zipp (3.17.0-r0)\n",
      "(68/131) Installing py3-zipp-pyc (3.17.0-r0)\n",
      "(69/131) Installing py3-importlib-metadata (7.0.0-r0)\n",
      "(70/131) Installing py3-importlib-metadata-pyc (7.0.0-r0)\n",
      "(71/131) Installing py3-locket (1.0.0-r2)\n",
      "(72/131) Installing py3-locket-pyc (1.0.0-r2)\n",
      "(73/131) Installing libsodium (1.0.19-r0)\n",
      "(74/131) Installing libzmq (4.3.5-r2)\n",
      "(75/131) Installing py3-pyzmq (23.2.1-r3)\n",
      "(76/131) Installing py3-pyzmq-pyc (23.2.1-r3)\n",
      "(77/131) Installing py3-toolz (0.12.0-r2)\n",
      "(78/131) Installing py3-toolz-pyc (0.12.0-r2)\n",
      "(79/131) Installing py3-partd (1.4.1-r0)\n",
      "(80/131) Installing py3-partd-pyc (1.4.1-r0)\n",
      "(81/131) Installing yaml (0.2.5-r2)\n",
      "(82/131) Installing py3-yaml (6.0.1-r1)\n",
      "(83/131) Installing py3-yaml-pyc (6.0.1-r1)\n",
      "(84/131) Installing py3-dask (2023.12.0-r0)\n",
      "(85/131) Installing py3-dask-pyc (2023.12.0-r0)\n",
      "(86/131) Installing py3-markupsafe (2.1.3-r0)\n",
      "(87/131) Installing py3-markupsafe-pyc (2.1.3-r0)\n",
      "(88/131) Installing py3-jinja2 (3.1.6-r0)\n",
      "(89/131) Installing py3-jinja2-pyc (3.1.6-r0)\n",
      "(90/131) Installing py3-msgpack (1.0.7-r0)\n",
      "(91/131) Installing py3-msgpack-pyc (1.0.7-r0)\n",
      "(92/131) Installing py3-psutil (5.9.6-r0)\n",
      "(93/131) Installing py3-psutil-pyc (5.9.6-r0)\n",
      "(94/131) Installing py3-sortedcontainers (2.4.0-r4)\n",
      "(95/131) Installing py3-sortedcontainers-pyc (2.4.0-r4)\n",
      "(96/131) Installing py3-tblib (2.0.0-r0)\n",
      "(97/131) Installing py3-tblib-pyc (2.0.0-r0)\n",
      "(98/131) Installing py3-tornado (6.4-r0)\n",
      "(99/131) Installing py3-tornado-pyc (6.4-r0)\n",
      "(100/131) Installing py3-urllib3 (1.26.18-r0)\n",
      "(101/131) Installing py3-urllib3-pyc (1.26.18-r0)\n",
      "(102/131) Installing py3-heapdict (1.0.1-r4)\n",
      "(103/131) Installing py3-heapdict-pyc (1.0.1-r4)\n",
      "(104/131) Installing lmdb (0.9.31-r0)\n",
      "(105/131) Installing py3-lmdb (1.2.1-r4)\n",
      "(106/131) Installing py3-lmdb-pyc (1.2.1-r4)\n",
      "(107/131) Installing py3-zict (3.0.0-r0)\n",
      "(108/131) Installing py3-zict-pyc (3.0.0-r0)\n",
      "(109/131) Installing py3-distributed (2023.11.0-r0)\n",
      "(110/131) Installing py3-distributed-pyc (2023.11.0-r0)\n",
      "(111/131) Installing py3-loky (3.4.1-r0)\n",
      "(112/131) Installing py3-loky-pyc (3.4.1-r0)\n",
      "(113/131) Installing py3-joblib (1.3.2-r0)\n",
      "(114/131) Installing py3-joblib-pyc (1.3.2-r0)\n",
      "(115/131) Installing py3-platformdirs (4.0.0-r0)\n",
      "(116/131) Installing py3-platformdirs-pyc (4.0.0-r0)\n",
      "(117/131) Installing py3-charset-normalizer (3.3.2-r0)\n",
      "(118/131) Installing py3-charset-normalizer-pyc (3.3.2-r0)\n",
      "(119/131) Installing py3-idna (3.7-r0)\n",
      "(120/131) Installing py3-idna-pyc (3.7-r0)\n",
      "(121/131) Installing py3-requests (2.32.4-r0)\n",
      "(122/131) Installing py3-requests-pyc (2.32.4-r0)\n",
      "(123/131) Installing py3-pooch (1.8.0-r0)\n",
      "(124/131) Installing py3-pooch-pyc (1.8.0-r0)\n",
      "(125/131) Installing py3-scipy (1.11.4-r0)\n",
      "(126/131) Installing py3-scipy-pyc (1.11.4-r0)\n",
      "(127/131) Installing py3-threadpoolctl (3.2.0-r0)\n",
      "(128/131) Installing py3-threadpoolctl-pyc (3.2.0-r0)\n",
      "(129/131) Installing libgomp (13.2.1_git20231014-r0)\n",
      "(130/131) Installing py3-scikit-learn (1.3.2-r0)\n",
      "(131/131) Installing py3-scikit-learn-pyc (1.3.2-r0)\n",
      "Executing busybox-1.36.1-r15.trigger\n",
      "OK: 407 MiB in 181 packages\n",
      "\n",
      "--- Dependency Installation Complete ---\n",
      "\n",
      "==================================================\n",
      "User message: Create a linear regression chart: GDP per capita vs life expectancy. Clean data, show scatter + regression line.\n",
      "==================================================\n",
      "Gravix AI is thinking...\n",
      "Generated code:\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.linear_model import LinearRegression\n",
      "import numpy as np\n",
      "import sys\n",
      "import traceback\n",
      "import base64\n",
      "\n",
      "try:\n",
      "    # Load and clean data\n",
      "    df = pd.read_csv('/home/user/data.csv')\n",
      "    print(f\"Original data shape: {df.shape}\")\n",
      "\n",
      "    # Define key columns\n",
      "    gdp_col = 'GDP per capita (current US$)'\n",
      "    life_exp_col = 'Life expectancy at birth, total (years)'\n",
      "\n",
      "    df_clean = df[[gdp_col, life_exp_col]].dropna()\n",
      "\n",
      "    # Convert to numeric, handling potential errors\n",
      "    df_clean[gdp_col] = pd.to_numeric(df_clean[gdp_col], errors='coerce')\n",
      "    df_clean[life_exp_col] = pd.to_numeric(df_clean[life_exp_col], errors='coerce')\n",
      "\n",
      "    # Drop rows that failed conversion\n",
      "    df_clean = df_clean.dropna()\n",
      "    print(f\"Clean data shape: {df_clean.shape}\")\n",
      "\n",
      "    if df_clean.empty:\n",
      "        print(\"Error: No data left after cleaning.\")\n",
      "        sys.exit(1)\n",
      "\n",
      "    # Prepare features and target\n",
      "    X = df_clean[gdp_col].values.reshape(-1, 1)\n",
      "    y = df_clean[life_exp_col].values\n",
      "\n",
      "    # Fit linear regression model\n",
      "    model = LinearRegression().fit(X, y)\n",
      "    print(\"Model fitted successfully.\")\n",
      "\n",
      "    # Create scatter plot with regression line\n",
      "    plt.figure(figsize=(10, 6))\n",
      "    plt.scatter(X, y, alpha=0.6, color='blue', label='Data points')\n",
      "\n",
      "    # Create line\n",
      "    X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
      "    plt.plot(X_line, model.predict(X_line), color='red', linewidth=2, label='Regression line')\n",
      "\n",
      "    plt.xlabel('GDP per capita (current US$)')\n",
      "    plt.ylabel('Life expectancy at birth, total (years)')\n",
      "    plt.title('GDP per capita vs Life Expectancy')\n",
      "    plt.legend()\n",
      "    plt.grid(True, alpha=0.3)\n",
      "\n",
      "    # Save the plot\n",
      "    plot_path = '/home/user/chart.png'\n",
      "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
      "    print(f\"Plot saved to {plot_path}\")\n",
      "\n",
      "    # Read the saved image, encode it, and print the base64 string\n",
      "    with open(plot_path, 'rb') as f:\n",
      "        image_bytes = f.read()\n",
      "        base64_string = base64.b64encode(image_bytes).decode('utf-8')\n",
      "        print(f\"PLOT_BASE64:{base64_string}\")\n",
      "\n",
      "except Exception as e:\n",
      "    print(f\"An error occurred: {e}\")\n",
      "    traceback.print_exc()\n",
      "\n",
      "--- Running Code in Gravix Layer Sandbox ---\n",
      "[Sandbox STDOUT]:\n",
      "Original data shape: (66, 96)\n",
      "Clean data shape: (66, 2)\n",
      "Model fitted successfully.\n",
      "Plot saved to /home/user/chart.png\n",
      "PLOT_BASE64:iVBORw0KGgoAAAANSUhEUgAACdsAAAZiC...",
      "\n",
      "--- End Sandbox Run ---\n",
      "\n",
      "--- Decoding and displaying plot ---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACdsAAAZiC...",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    with Sandbox.create() as sandbox:\n",
    "        if not upload_dataset(sandbox):\n",
    "            raise Exception(\"Dataset upload failed. Aborting.\")\n",
    "\n",
    "        # --- NEW STEP: Install dependencies ---\n",
    "        print(\"\\n--- Installing Dependencies in Sandbox via APK ---\")\n",
    "        print(\"This may take a few minutes...\")\n",
    "        \n",
    "        # Install pre-compiled Python libraries from Alpine's package manager\n",
    "        # This is much faster and more reliable than using pip to build from source\n",
    "        print(\"Running: apk add py3-pandas py3-matplotlib py3-scikit-learn\")\n",
    "        install_result = sandbox.run_command(\"apk\", [\"add\", \"py3-pandas\", \"py3-matplotlib\", \"py3-scikit-learn\"], timeout=300)\n",
    "        \n",
    "        if install_result.stdout:\n",
    "            print(\"[apk STDOUT]:\\n\", install_result.stdout)\n",
    "        if install_result.stderr:\n",
    "            print(\"[apk STDERR]:\\n\", install_result.stderr)\n",
    "            \n",
    "        if install_result.exit_code == 0:\n",
    "            print(\"--- Dependency Installation Complete ---\")\n",
    "        else:\n",
    "            print(\"[apk ERROR]:\", getattr(install_result, 'error', 'No error attribute'))\n",
    "            raise Exception(\"System library installation (apk) failed. Aborting.\")\n",
    "        # --- End New Step ---\n",
    "\n",
    "        # This prompt is clear and maps to the system prompt's example\n",
    "        user_task = \"Create a linear regression chart: GDP per capita vs life expectancy. Clean data, show scatter + regression line.\"\n",
    "        \n",
    "        plot_base64_data = chat_with_llm(\n",
    "            sandbox,\n",
    "            user_task,\n",
    "        )\n",
    "        \n",
    "        if plot_base64_data:\n",
    "            print(f\"\\n--- Decoding and displaying plot ---\")\n",
    "            try:\n",
    "                # *** FIX HERE ***\n",
    "                # Decode the base64 string (str) back into bytes\n",
    "                image_bytes = base64.b64decode(plot_base64_data)\n",
    "                # Pass the raw bytes to Image()\n",
    "                display(Image(data=image_bytes))\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError displaying base64 image: {e}\")\n",
    "        else:\n",
    "            print(\"\\n--- No plot was generated by the AI (base64 string not found in output) ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- An error occurred during the sandbox operation --- \")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please ensure your GRAVIXLAYER_API_KEY is valid and data.csv exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Congratulations!** You have successfully built a complete AI-powered data analysis system using Gravix Layer!\n",
    "\n",
    "### What you've accomplished:\n",
    "\n",
    "1. **Set up the environment** with Gravix Layer's dual SDK capabilities\n",
    "2. **Created intelligent code generation** using advanced language models\n",
    "3. **Implemented secure execution** in containerized sandbox environments\n",
    "4. **Built automatic visualization** with base64 encoding and display\n",
    "5. **Added robust error handling** and debugging capabilities\n",
    "6. **Integrated dataset management** with secure file transfer\n",
    "7. **Created a complete workflow** that transforms natural language into actionable insights\n",
    "\n",
    "### Key Features of this AI Data Analyst:\n",
    "\n",
    "- **Natural Language Processing**: Understands complex data analysis requests in plain English\n",
    "- **Intelligent Code Generation**: Creates robust, production-ready Python code automatically\n",
    "- **Secure Execution**: Runs all code in isolated sandbox environments with dependency management\n",
    "- **Professional Visualizations**: Generates publication-quality charts and statistical plots\n",
    "- **Error Recovery**: Handles exceptions gracefully with detailed debugging information\n",
    "- **Scalable Architecture**: Built on Gravix Layer's enterprise-grade infrastructure\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Expand your datasets** with different file formats and data sources\n",
    "2. **Experiment with complex analyses** like machine learning models and statistical tests\n",
    "3. **Customize the system prompts** for domain-specific analysis requirements\n",
    "4. **Add conversation memory** for multi-turn analysis sessions\n",
    "5. **Implement batch processing** for multiple datasets and automated reporting\n",
    "6. **Integrate with business systems** for real-time data analysis workflows\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [Gravix Layer Documentation](https://docs.gravixlayer.com)\n",
    "- [Sandbox Environment Guide](https://docs.gravixlayer.com/docs/sandbox)\n",
    "- [LLM Inference Best Practices](https://docs.gravixlayer.com/docs/inference)\n",
    "\n",
    "Happy analyzing! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gravix_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
