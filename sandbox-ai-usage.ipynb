{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "# GravixLayer AgentBox - Connecting to LLM\n",
        "\n",
        "This notebook:\n",
        "1. Asks you for a prompt\n",
        "2. Sends it to an AI model using GravixLayer\n",
        "3. Saves the AI response into a text file **inside a sandbox**\n",
        "4. Downloads that file back to the local environment so you can download it from the notebook UI\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. Install the GravixLayer SDK: `pip install gravixlayer`\n",
        "2. Set your API key as an environment variable: `GRAVIXLAYER_API_KEY`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gravixlayer in ./gravix_test/lib/python3.12/site-packages (0.0.50)\n",
            "Requirement already satisfied: requests>=2.25.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (2.32.5)\n",
            "Requirement already satisfied: python-dotenv>=0.19.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (1.0.0)\n",
            "Requirement already satisfied: httpx>=0.24.0 in ./gravix_test/lib/python3.12/site-packages (from gravixlayer) (0.28.1)\n",
            "Requirement already satisfied: anyio in ./gravix_test/lib/python3.12/site-packages (from httpx>=0.24.0->gravixlayer) (4.11.0)\n",
            "Requirement already satisfied: certifi in ./gravix_test/lib/python3.12/site-packages (from httpx>=0.24.0->gravixlayer) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in ./gravix_test/lib/python3.12/site-packages (from httpx>=0.24.0->gravixlayer) (1.0.9)\n",
            "Requirement already satisfied: idna in ./gravix_test/lib/python3.12/site-packages (from httpx>=0.24.0->gravixlayer) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in ./gravix_test/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.24.0->gravixlayer) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./gravix_test/lib/python3.12/site-packages (from requests>=2.25.0->gravixlayer) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in ./gravix_test/lib/python3.12/site-packages (from anyio->httpx>=0.24.0->gravixlayer) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in ./gravix_test/lib/python3.12/site-packages (from anyio->httpx>=0.24.0->gravixlayer) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Install GravixLayer SDK if not already installed\n",
        "!pip install gravixlayer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from gravixlayer import GravixLayer\n",
        "\n",
        "# Make sure GRAVIXLAYER_API_KEY is set in your environment before running this cell\n",
        "client = GravixLayer()\n",
        "\n",
        "# Choose the model you want to demo\n",
        "MODEL_NAME = \"meta-llama/llama-3.1-8b-instruct\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AI response:\n",
            "\n",
            "Here's a poem on love:\n",
            "\n",
            "Love's gentle touch ignites the flame,\n",
            "A warmth that spreads, a heart that claims,\n",
            "A feeling deep, a soul that's true,\n",
            "A connection strong, a love that shines through.\n",
            "\n",
            "In eyes that meet, a spark takes flight,\n",
            "A whispered promise, a love so bright,\n",
            "A tender caress, a gentle kiss,\n",
            "A love that grows, a heart that misses.\n",
            "\n",
            "With every breath, a love is born,\n",
            "A flame that flickers, a heart that yearns,\n",
            "For more of you, for more of me,\n",
            "A love that's pure, a love that's free.\n",
            "\n",
            "Through laughter and tears, through joy and pain,\n",
            "Love stands strong, a love that remains,\n",
            "A bond that's unbreakable, a tie that's true,\n",
            "A love that's pure, a love that shines through.\n",
            "\n",
            "In your arms, I find my home,\n",
            "A place where love resides, a place to roam,\n",
            "With you by my side, I feel complete,\n",
            "A love that's real, a love that's sweet.\n",
            "\n",
            "So let us cherish, let us adore,\n",
            "This love we share, this love we explore,\n",
            "For it's a gift, a treasure so rare,\n",
            "A love that's ours, a love that's beyond compare.\n"
          ]
        }
      ],
      "source": [
        "# 1) Get user prompt\n",
        "user_prompt = input(\"Enter your prompt for the AI: \")\n",
        "\n",
        "# 2) Call the AI model via GravixLayer\n",
        "completion = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        ")\n",
        "\n",
        "ai_response = completion.choices[0].message.content\n",
        "print(\"\\nAI response:\\n\")\n",
        "print(ai_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote AI response to sandbox file: /home/user/ai_response.txt\n",
            "Downloaded sandbox file to local file: ai_response.txt\n",
            "You can now download 'ai_response.txt' from the notebook file browser.\n",
            "Sandbox killed.\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timezone\n",
        "\n",
        "# 3) Create a sandbox and write the AI response to a file inside it\n",
        "sandbox = client.sandbox.sandboxes.create(\n",
        "    provider=\"gravix\",\n",
        "    region=\"eu-west-1\",\n",
        "    template=\"python-base-v1\",\n",
        ")\n",
        "\n",
        "try:\n",
        "    sandbox_path = \"/home/user/ai_response.txt\"\n",
        "\n",
        "    # Prepare content with some metadata (timezone-aware UTC)\n",
        "    content = (\n",
        "        \"Prompt: \" + user_prompt + \"\\n\"\n",
        "        \"Generated at: \" + datetime.now(timezone.utc).isoformat() + \"\\n\\n\"\n",
        "        \"AI Response:\\n\" + ai_response + \"\\n\"\n",
        "    )\n",
        "\n",
        "    # Write text file into the sandbox\n",
        "    client.sandbox.sandboxes.write_file(\n",
        "        sandbox.sandbox_id,\n",
        "        path=sandbox_path,\n",
        "        content=content,\n",
        "    )\n",
        "    print(f\"Wrote AI response to sandbox file: {sandbox_path}\")\n",
        "\n",
        "    # 4) Download the file from sandbox to local environment\n",
        "    file_response = client.sandbox.sandboxes.read_file(\n",
        "        sandbox.sandbox_id,   \n",
        "        path=sandbox_path,\n",
        "    )\n",
        "\n",
        "    # Unwrap FileReadResponse -> get the actual content\n",
        "    if hasattr(file_response, \"content\"):\n",
        "        downloaded_content = file_response.content\n",
        "    else:\n",
        "        downloaded_content = file_response\n",
        "\n",
        "    # If itâ€™s bytes, decode to str\n",
        "    if isinstance(downloaded_content, bytes):\n",
        "        downloaded_content = downloaded_content.decode(\"utf-8\")\n",
        "\n",
        "    local_filename = \"ai_response.txt\"\n",
        "    with open(local_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(downloaded_content)\n",
        "\n",
        "    print(f\"Downloaded sandbox file to local file: {local_filename}\")\n",
        "    print(\"You can now download 'ai_response.txt' from the notebook file browser.\")\n",
        "\n",
        "finally:\n",
        "    # Always clean up the sandbox\n",
        "    client.sandbox.sandboxes.kill(sandbox.sandbox_id)\n",
        "    print(\"Sandbox killed.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gravix_test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
